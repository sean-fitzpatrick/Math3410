<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Diagonalization of complex matrices</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="Linear Algebra">
<meta property="book:author" content="Sean Fitzpatrick">
<script src="https://sagecell.sagemath.org/static/embedded_sagecell.js"></script><script>var runestoneMathReady = new Promise((resolve) => window.rsMathReady = resolve);
window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'color', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore|ignore-math",
    processHtmlClass: "process-math",
    renderActions: {
        findScript: [10, function (doc) {
            document.querySelectorAll('script[type^="math/tex"]').forEach(function(node) {
                var display = !!node.type.match(/; *mode=display/);
                var math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                var text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = {node: text, delim: '', n: 0};
                math.end = {node: text, delim: '', n: 0};
                doc.math.push(math);
            });
        }, '']
    },
  },
  chtml: {
    scale: 0.98,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/color', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
  startup: {
    /* Mathjax typesetting operation is under the control of React */
    typeset: false,
  },
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><link href="https://webwork-dev.uleth.ca/webwork2_files/js/apps/MathView/mathview.css" rel="stylesheet">
<script src="https://pretextbook.org/js/0.3/pretext-webwork/2.17/pretext-webwork.js"></script><script src="https://webwork-dev.uleth.ca/webwork2_files/node_modules/iframe-resizer/js/iframeResizer.min.js"></script><script>// Make *any* pre with class 'sagecell-sage' an executable Sage cell
// Their results will be linked, only within language type
sagecell.makeSagecell({inputLocation: 'pre.sagecell-sage',
                       linked: true,
                       languages: ['sage'],
                       evalButtonText: 'Evaluate (Sage)'});
</script><script>js_version = 0.3</script><script type="module" defer src="https://siefkenj.github.io/pretext-react/static/js/main.js"></script><link href="https://siefkenj.github.io/pretext-react/static/css/main.css" rel="stylesheet">
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&amp;family=Noto+Serif:ital,wght@0,400;0,700;1,400;1,700&amp;family=Tinos:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" rel="stylesheet">
<link href="https://fonts.cdnfonts.com/css/dejavu-serif" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Roboto+Serif:opsz,wdth,wght@8..144,50..150,100..900&amp;display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Open+Sans:wdth,wght@75..100,300..800&amp;display=swap" rel="stylesheet">
<script type="application/json" class="js-hypothesis-config">{
    "openSidebar": false,    "showHighlights": true,}</script><script src="https://hypothes.is/embed.js" async=""></script><!--** eBookCongig is necessary to configure interactive       **-->
<!--** Runestone components to run locally in reader's browser **-->
<!--** No external communication:                              **-->
<!--**     log level is 0, Runestone Services are disabled     **-->
<script type="text/javascript">
eBookConfig = {};
eBookConfig.useRunestoneServices = false;
eBookConfig.host = 'http://127.0.0.1:8000';
eBookConfig.course = 'PTX_Course_Title_Here';
eBookConfig.basecourse = 'PTX_Base_Course';
eBookConfig.isLoggedIn = false;
eBookConfig.email = '';
eBookConfig.isInstructor = false;
eBookConfig.logLevel = 0;
eBookConfig.username = '';
eBookConfig.readings = null;
eBookConfig.activities = null;
eBookConfig.downloadsEnabled = false;
eBookConfig.allow_pairs = false;
eBookConfig.enableScratchAC = false;
eBookConfig.build_info = "";
eBookConfig.python3 = null;
eBookConfig.runestone_version = '7.0.0dev3';
eBookConfig.jobehost = '';
eBookConfig.proxyuri_runs = '';
eBookConfig.proxyuri_files = '';
eBookConfig.enable_chatcodes =  false;
</script>
<!--*** Runestone Services ***-->
<script type="text/javascript" src="https://runestone.academy/cdn/runestone/7.0.0dev3/prefix-runtime.71ffd81c0faeb38b.bundle.js"></script><script type="text/javascript" src="https://runestone.academy/cdn/runestone/7.0.0dev3/prefix-347.193e36c07abd0197.bundle.js"></script><script type="text/javascript" src="https://runestone.academy/cdn/runestone/7.0.0dev3/prefix-runestone.e543e0dd19670ae2.bundle.js"></script><link rel="stylesheet" type="text/css" href="https://runestone.academy/cdn/runestone/7.0.0dev3/prefix-347.f9add1ca35d5ad93.css">
<link rel="stylesheet" type="text/css" href="https://runestone.academy/cdn/runestone/7.0.0dev3/prefix-runestone.1f1f63d2cda36a4d.css">
</head>
<body id="Math3410" data-react-in-use="yes" class="pretext book ignore-math">
<a class="assistive" href="#ptx-content">Skip to main content</a><header id="ptx-masthead" class="ptx-masthead"><div class="ptx-banner">
<a id="logo-link" class="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="linear-algebra.html"><span class="title">Linear Algebra:</span> <span class="subtitle">A second course, featuring proofs and Python</span></a></h1>
<p class="byline">Sean Fitzpatrick</p>
</div>
<div id="searchresultsplaceholder" class="searchresultsplaceholder" style="display: none">
<button id="closesearchresults" class="closesearchresults" onclick="document.getElementById('searchresultsplaceholder').style.display = 'none'; return false;">x</button><h2>Search Results: <span id="searchterms" class="searchterms"></span>
</h2>
<div id="searchempty" class="searchempty"><span>No results.</span></div>
<ol id="searchresults" class="searchresults"></ol>
</div>
</div></header><nav id="ptx-navbar" class="ptx-navbar navbar"><button class="toc-toggle button" aria-label="Show or hide table of contents"><span class="icon">‚ò∞</span><span class="name">Contents</span></button><span class="treebuttons"><a class="previous-button button" href="sec-quadratic.html" title="Previous"><span class="icon">&lt;</span><span class="name">Prev</span></a><a class="up-button button" href="ch-diagonalization.html" title="Up"><span class="icon">^</span><span class="name">Up</span></a><a class="next-button button" href="worksheet-dynamical.html" title="Next"><span class="name">Next</span><span class="icon">&gt;</span></a></span><div class="searchbox"><div class="searchwidget">
<input id="ptxsearch" class="ptxsearch" type="text" name="terms" placeholder="Search" onchange="doSearch()"><button id="searchbutton" class="searchbutton" type="button" onclick="doSearch()">üîç</button>
</div></div></nav><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\require{boldsymbol}\newcommand{\spn}{\operatorname{span}}
\newcommand{\bbm}{\begin{bmatrix}}
\newcommand{\ebm}{\end{bmatrix}}
\newcommand{\R}{\mathbb{R}}
\ifdefined\C
\renewcommand\C{\mathbb{C}}
\else
\newcommand\C{\mathbb{C}}
\fi
\newcommand{\im}{\operatorname{im}}
\newcommand{\nll}{\operatorname{null}}
\newcommand{\csp}{\operatorname{col}}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\diag}{\operatorname{diag}}
\newcommand{\tr}{\operatorname{tr}}
\newcommand{\dotp}{\!\boldsymbol{\cdot}\!}
\newcommand{\len}[1]{\lVert #1\rVert}
\newcommand{\abs}[1]{\lvert #1\rvert}
\newcommand{\proj}[2]{\operatorname{proj}_{#1}{#2}}
\newcommand{\bz}{\overline{z}}
\newcommand{\zz}{\mathbf{z}}
\newcommand{\uu}{\mathbf{u}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\ww}{\mathbf{w}}
\newcommand{\xx}{\mathbf{x}}
\newcommand{\yy}{\mathbf{y}}
\newcommand{\zer}{\mathbf{0}}
\newcommand{\vecq}{\mathbf{q}}
\newcommand{\vecp}{\mathbf{p}}
\newcommand{\vece}{\mathbf{e}}
\newcommand{\basis}[2]{\{\mathbf{#1}_1,\mathbf{#1}_2,\ldots,\mathbf{#1}_{#2}\}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<div class="ptx-page">
<div id="ptx-sidebar" class="ptx-sidebar"><nav id="ptx-toc" class="ptx-toc depth2"><ul class="structural">
<li>
<div class="toc-item"><a href="frontmatter-1.html" class="internal"><span class="title">Front Matter</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="colophon-1.html" class="internal"><span class="title">Colophon</span></a></div></li>
<li><div class="toc-item"><a href="preface-1.html" class="internal"><span class="title">Preface</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="ch-vector-space.html" class="internal"><span class="codenumber">1</span> <span class="title">Vector spaces</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="sec-vec-sp.html" class="internal"><span class="codenumber">1.1</span> <span class="title">Definition and examples</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="sec-vec-sp.html#exercises-1" class="internal"><span class="codenumber">1.1</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
<li><div class="toc-item"><a href="sec-vsp-properties.html" class="internal"><span class="codenumber">1.2</span> <span class="title">Properties</span></a></div></li>
<li>
<div class="toc-item"><a href="sec-subspace.html" class="internal"><span class="codenumber">1.3</span> <span class="title">Subspaces</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="sec-subspace.html#exercises-2" class="internal"><span class="codenumber">1.3</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
<li>
<div class="toc-item"><a href="sec-span.html" class="internal"><span class="codenumber">1.4</span> <span class="title">Span</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="sec-span.html#exercises-3" class="internal"><span class="codenumber">1.4</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
<li><div class="toc-item"><a href="worksheet-span.html" class="internal"><span class="codenumber">1.5</span> <span class="title">Worksheet: understanding span</span></a></div></li>
<li>
<div class="toc-item"><a href="sec-independence.html" class="internal"><span class="codenumber">1.6</span> <span class="title">Linear Independence</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="sec-independence.html#exercises-4" class="internal"><span class="codenumber">1.6</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
<li>
<div class="toc-item"><a href="sec-dimension.html" class="internal"><span class="codenumber">1.7</span> <span class="title">Basis and dimension</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="sec-dimension.html#exercises-5" class="internal"><span class="codenumber">1.7</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
<li>
<div class="toc-item"><a href="sec-subspace-combine.html" class="internal"><span class="codenumber">1.8</span> <span class="title">New subspaces from old</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="sec-subspace-combine.html#exercises-6" class="internal"><span class="codenumber">1.8</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="ch-linear-trans.html" class="internal"><span class="codenumber">2</span> <span class="title">Linear Transformations</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="sec-lin-tran-intro.html" class="internal"><span class="codenumber">2.1</span> <span class="title">Definition and examples</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="sec-lin-tran-intro.html#exercises-7" class="internal"><span class="codenumber">2.1</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
<li>
<div class="toc-item"><a href="sec-kernel-image.html" class="internal"><span class="codenumber">2.2</span> <span class="title">Kernel and Image</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="sec-kernel-image.html#exercises-8" class="internal"><span class="codenumber">2.2</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
<li>
<div class="toc-item"><a href="sec-isomorphism.html" class="internal"><span class="codenumber">2.3</span> <span class="title">Isomorphisms, composition, and inverses</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-isomorphism.html#subsec-isomorphism" class="internal"><span class="codenumber">2.3.1</span> <span class="title">Isomorphisms</span></a></div></li>
<li>
<div class="toc-item"><a href="sec-isomorphism.html#subsec-composition" class="internal"><span class="codenumber">2.3.2</span> <span class="title">Composition and inverses</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="sec-isomorphism.html#exercises-9" class="internal"><span class="codenumber">2.3.2</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
</ul>
</li>
<li><div class="toc-item"><a href="worksheet-transformations.html" class="internal"><span class="codenumber">2.4</span> <span class="title">Worksheet: matrix transformations</span></a></div></li>
<li><div class="toc-item"><a href="worksheet-recurrence.html" class="internal"><span class="codenumber">2.5</span> <span class="title">Worksheet: linear recurrences</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="ch-orthogonality.html" class="internal"><span class="codenumber">3</span> <span class="title">Orthogonality and Applications</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="sec-orthogonal-sets.html" class="internal"><span class="codenumber">3.1</span> <span class="title">Orthogonal sets of vectors</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-orthogonal-sets.html#subsec-dot-basics" class="internal"><span class="codenumber">3.1.1</span> <span class="title">Basic definitions and properties</span></a></div></li>
<li><div class="toc-item"><a href="sec-orthogonal-sets.html#subsec-ortho-sets" class="internal"><span class="codenumber">3.1.2</span> <span class="title">Orthogonal sets of vectors</span></a></div></li>
<li><div class="toc-item"><a href="sec-orthogonal-sets.html#exercises-10" class="internal"><span class="codenumber">3.1.3</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-gram-schmidt.html" class="internal"><span class="codenumber">3.2</span> <span class="title">The Gram-Schmidt Procedure</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="sec-gram-schmidt.html#exercises-11" class="internal"><span class="codenumber">3.2</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
<li>
<div class="toc-item"><a href="section-projection.html" class="internal"><span class="codenumber">3.3</span> <span class="title">Orthogonal Projection</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="section-projection.html#exercises-12" class="internal"><span class="codenumber">3.3</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
<li><div class="toc-item"><a href="worksheet-dual-basis.html" class="internal"><span class="codenumber">3.4</span> <span class="title">Worksheet: dual basis.</span></a></div></li>
<li><div class="toc-item"><a href="worksheet-least-squares.html" class="internal"><span class="codenumber">3.5</span> <span class="title">Worksheet: Least squares approximation</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="ch-diagonalization.html" class="internal"><span class="codenumber">4</span> <span class="title">Diagonalization</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-eigen-basics.html" class="internal"><span class="codenumber">4.1</span> <span class="title">Eigenvalues and Eigenvectors</span></a></div></li>
<li><div class="toc-item"><a href="subsec-ortho-diag.html" class="internal"><span class="codenumber">4.2</span> <span class="title">Diagonalization of symmetric matrices</span></a></div></li>
<li><div class="toc-item"><a href="sec-quadratic.html" class="internal"><span class="codenumber">4.3</span> <span class="title">Quadratic forms</span></a></div></li>
<li class="active">
<div class="toc-item"><a href="sec-complex.html" class="internal"><span class="codenumber">4.4</span> <span class="title">Diagonalization of complex matrices</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-complex.html#subsec-complex-vector" class="internal"><span class="codenumber">4.4.1</span> <span class="title">Complex vectors</span></a></div></li>
<li><div class="toc-item"><a href="sec-complex.html#subsec-complex-matrix" class="internal"><span class="codenumber">4.4.2</span> <span class="title">Complex matrices</span></a></div></li>
</ul>
</li>
<li><div class="toc-item"><a href="worksheet-dynamical.html" class="internal"><span class="codenumber">4.5</span> <span class="title">Worksheet: linear dynamical systems</span></a></div></li>
<li>
<div class="toc-item"><a href="section-matrix-factor.html" class="internal"><span class="codenumber">4.6</span> <span class="title">Matrix Factorizations and Eigenvalues</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="section-matrix-factor.html#subsec-matrix-factorization" class="internal"><span class="codenumber">4.6.1</span> <span class="title">Matrix Factorizations</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="section-matrix-factor.html#pars-positive-ops" class="internal"><span class="codenumber">4.6.1.1</span> <span class="title">Positive Operators</span></a></div></li>
<li><div class="toc-item"><a href="section-matrix-factor.html#pars-singular-values" class="internal"><span class="codenumber">4.6.1.2</span> <span class="title">Singular Value Decomposition</span></a></div></li>
<li><div class="toc-item"><a href="section-matrix-factor.html#pars-qr-factor" class="internal"><span class="codenumber">4.6.1.3</span> <span class="title">QR Factorization</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="section-matrix-factor.html#subsec-compute-eigen" class="internal"><span class="codenumber">4.6.2</span> <span class="title">Computing Eigenvalues</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="section-matrix-factor.html#pars-power-method" class="internal"><span class="codenumber">4.6.2.1</span> <span class="title">The Power Method</span></a></div></li>
<li><div class="toc-item"><a href="section-matrix-factor.html#pars-qr-algorithm" class="internal"><span class="codenumber">4.6.2.2</span> <span class="title">The QR Algorithm</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li><div class="toc-item"><a href="worksheet-svd.html" class="internal"><span class="codenumber">4.7</span> <span class="title">Worksheet: Singular Value Decomposition</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="ch-change-basis.html" class="internal"><span class="codenumber">5</span> <span class="title">Change of Basis</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-matrix-of-transformation.html" class="internal"><span class="codenumber">5.1</span> <span class="title">The matrix of a linear transformation</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrix-operator.html" class="internal"><span class="codenumber">5.2</span> <span class="title">The matrix of a linear operator</span></a></div></li>
<li>
<div class="toc-item"><a href="sec-direct-sum.html" class="internal"><span class="codenumber">5.3</span> <span class="title">Direct Sums and Invariant Subspaces</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-direct-sum.html#subsec-invariant" class="internal"><span class="codenumber">5.3.1</span> <span class="title">Invariant subspaces</span></a></div></li>
<li><div class="toc-item"><a href="sec-direct-sum.html#subsec-eigenspace" class="internal"><span class="codenumber">5.3.2</span> <span class="title">Eigenspaces</span></a></div></li>
<li><div class="toc-item"><a href="sec-direct-sum.html#subsec-direct-sum" class="internal"><span class="codenumber">5.3.3</span> <span class="title">Direct Sums</span></a></div></li>
</ul>
</li>
<li><div class="toc-item"><a href="worksheet-gen-eigen.html" class="internal"><span class="codenumber">5.4</span> <span class="title">Worksheet: generalized eigenvectors</span></a></div></li>
<li><div class="toc-item"><a href="sec-gen-eigen.html" class="internal"><span class="codenumber">5.5</span> <span class="title">Generalized eigenspaces</span></a></div></li>
<li><div class="toc-item"><a href="sec-jordan-form.html" class="internal"><span class="codenumber">5.6</span> <span class="title">Jordan Canonical Form</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="backmatter-1.html" class="internal"><span class="title">Back Matter</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="appendix-complex-review.html" class="internal"><span class="codenumber">A</span> <span class="title">Review of complex numbers</span></a></div></li>
<li>
<div class="toc-item"><a href="ch-computation.html" class="internal"><span class="codenumber">B</span> <span class="title">Computational Tools</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="section-jupyter.html" class="internal"><span class="codenumber">B.1</span> <span class="title">Jupyter</span></a></div></li>
<li><div class="toc-item"><a href="sec-python-basics.html" class="internal"><span class="codenumber">B.2</span> <span class="title">Python basics</span></a></div></li>
<li>
<div class="toc-item"><a href="sec-sympy.html" class="internal"><span class="codenumber">B.3</span> <span class="title">SymPy for linear algebra</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-sympy.html#subsec-sympy-basics" class="internal"><span class="codenumber">B.3.1</span> <span class="title">SymPy basics</span></a></div></li>
<li><div class="toc-item"><a href="sec-sympy.html#subsec-sympy-matrix" class="internal"><span class="codenumber">B.3.2</span> <span class="title">Matrices in SymPy</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li><div class="toc-item"><a href="solutions-backmatter.html" class="internal"><span class="codenumber">C</span> <span class="title">Solutions to Selected Exercises</span></a></div></li>
</ul>
</li>
</ul></nav></div>
<main class="ptx-main"><div id="ptx-content" class="ptx-content"><section class="section" id="sec-complex"><h2 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber">4.4</span> <span class="title">Diagonalization of complex matrices</span>
</h2>
<section class="introduction" id="introduction-23"><div class="para" id="p-1709">Recall that when we first defined vector spaces, we mentioned that a vector space can be defined over any <em class="emphasis">field</em> <span class="process-math">\(\mathbb{F}\text{.}\)</span> To keep things simple, we‚Äôve mostly assumed <span class="process-math">\(\mathbb{F}=\mathbb{R}\text{.}\)</span> But most of the theorems and proofs we‚Äôve encountered go through unchanged if we work over a general field. (This is not quite true: over a <em class="emphasis">finite</em> field things can get more complicated. For example, if <span class="process-math">\(\mathbb{F}=\mathbb{Z}_2=\{0,1\}\text{,}\)</span> then we get weird results like <span class="process-math">\(\vv+\vv=\zer\text{,}\)</span> since <span class="process-math">\(1+1=0\text{.}\)</span>)</div> <div class="para" id="p-1710">In fact, if we replace <span class="process-math">\(\R\)</span> by <span class="process-math">\(\C\text{,}\)</span> about the only thing we‚Äôd have to go back and change is the definition of the dot product. The reason for this is that although the complex numbers seem computationally more complicated, (which might mostly be because you don‚Äôt use them often enough) they follow the exact same algebraic rules as the real numbers. In other words, the <em class="emphasis">arithmetic</em> might be different, but the <em class="emphasis">algebra</em> is the same. There is one key difference between the two fields: over the complex numbers, every polynomial can be factored. This is important if you‚Äôre interested in finding eigenvalues.</div> <div class="para" id="p-1711">This section is written based on the assumption that complex numbers were covered in a previous course. If this was not the case, or to review this material, see <a href="appendix-complex-review.html" class="internal" title="Appendix A: Review of complex numbers">Appendix¬†A</a> before proceeding.</div></section><section class="subsection" id="subsec-complex-vector"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.4.1</span> <span class="title">Complex vectors</span>
</h3>
<div class="para" id="p-1712">A complex vector space is simply a vector space where the scalars are elements of <span class="process-math">\(\C\)</span> rather than <span class="process-math">\(\R\text{.}\)</span> Examples include polynomials with complex coefficients, complex-valued functions, and <span class="process-math">\(\C^n\text{,}\)</span> which is defined exactly how you think it should be. In fact, one way to obtain <span class="process-math">\(\C^n\)</span> is to start with the exact same standard basis we use for <span class="process-math">\(\R^n\text{,}\)</span> and then take linear combinations using complex scalars.</div>
<div class="para logical" id="p-1713">
<div class="para">We‚Äôll write elements of <span class="process-math">\(\C^n\)</span> as <span class="process-math">\(\zz = (z_1,z_2,\ldots, z_n)\text{.}\)</span> The complex conjugate of <span class="process-math">\(\zz\)</span> is given by</div>
<div class="displaymath process-math">
\begin{equation*}
\bar{\zz} = (\bz_1,\bz_2,\ldots, \bz_n)\text{.}
\end{equation*}
</div>
</div>
<div class="para" id="p-1714">The standard inner product on <span class="process-math">\(\C^n\)</span> looks a lot like the dot product on <span class="process-math">\(\R^n\text{,}\)</span> with one important difference: we apply a complex conjugate to the second vector.</div>
<article class="definition definition-like" id="def-complex-inner"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">4.4.1</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-1715">
<div class="para">The <dfn class="terminology">standard inner product</dfn> on <span class="process-math">\(\C^n\)</span> is defined as follows: given <span class="process-math">\(\zz=(z_1,z_2,\ldots, z_n)\)</span> and <span class="process-math">\(\ww=(w_1,w_2,\ldots, w_n)\text{,}\)</span>
</div>
<div class="displaymath process-math">
\begin{equation*}
\langle \zz,\ww\rangle = \zz\dotp\bar{\ww} = z_1\bar{w}_1+z_2\bar{w}_2+\cdots + z_n\bar{w}_n\text{.}
\end{equation*}
</div>
</div></article><div class="para logical" id="p-1716">
<div class="para">If <span class="process-math">\(\zz,\ww\)</span> are real, this is just the usual dot product. The reason for using the complex conjugate is to ensure that we still have a positive-definite inner product on <span class="process-math">\(\C^n\text{:}\)</span>
</div>
<div class="displaymath process-math">
\begin{equation*}
\langle \zz,\zz\rangle = z_1\bz_1+z_2\bz_2+\cdots + z_n\bz_n = \abs{z_1}^2+\abs{z_2}^2+\cdots + \abs{z_n}^2\text{,}
\end{equation*}
</div>
<div class="para">which shows that <span class="process-math">\(\langle \zz,\zz\rangle \geq 0\text{,}\)</span> and <span class="process-math">\(\langle \zz,\zz\rangle = 0\)</span> if and only if <span class="process-math">\(\zz=\zer\text{.}\)</span>
</div>
</div>
<article class="exercise exercise-like" id="exercise-156"><h4 class="heading">
<span class="type">Exercise</span><span class="space"> </span><span class="codenumber">4.4.2</span><span class="period">.</span>
</h4>
<div class="para" id="p-1717">Compute the dot product of <span class="process-math">\(\zz = (2-i, 3i, 4+2i)\)</span> and <span class="process-math">\(\ww = (3i,4-5i,-2+2i)\text{.}\)</span>
</div></article><div class="para" id="p-1718">This isn‚Äôt hard to do by hand, but it‚Äôs useful to know how to ask the computer to do it, too. Unfortunately, the dot product in SymPy does not include the complex conjugate. One likely reason for this is that while most mathematicians take the complex conjugate of the <em class="emphasis">second</em> vector, some mathematicians, and most physicists, put the conjugate on the first vector. So they may have decided to remain agnostic about this choice. We can manually apply the conjugate, using <code class="code-inline tex2jax_ignore">Z.dot(W.H)</code>. (The <code class="code-inline tex2jax_ignore">.H</code> operation is the <dfn class="terminology">hermitian conjugate</dfn>; see <a href="" class="xref" data-knowl="./knowl/def-conjugate-transpose.html" title="Definition 4.4.6">Definition¬†4.4.6</a> below.)</div>
<pre class="ptx-sagecell sagecell-sage" id="sage-72"><script type="text/x-sage">from sympy import Matrix,init_printing
init_printing()
Z = Matrix(3,1,[2-I,3*I,4+2*I])
W = Matrix(3,1,[3*I,4-5*I,-2+2*I])
Z, W, Z.dot(W.H)
</script></pre>
<div class="para" id="p-1719">Again, you might want to wrap that last term in <code class="code-inline tex2jax_ignore">simplify()</code> (in which case you‚Äôll get <span class="process-math">\(-22-6i\)</span> for the dot product). Above, we saw that the complex inner product is designed to be positive definite, like the real inner product. The remaining properties of the complex inner product are given as follows.</div>
<article class="theorem theorem-like" id="thm-complex-inner-props"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">4.4.3</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-1720">
<div class="para">For any vectors <span class="process-math">\(\zz_1,\zz_2,\zz_3\)</span> and any complex number <span class="process-math">\(\alpha\text{,}\)</span>
</div>
<ol class="decimal">
<li id="li-319"><div class="para" id="p-1721">
<span class="process-math">\(\langle \zz_1+\zz_2,\zz_3\rangle = \langle \zz_1,\zz_3\rangle + \langle \zz_2,\zz_3\rangle\)</span> and <span class="process-math">\(\langle \zz_1,\zz_2+\zz_3\rangle = \langle \zz_1,\zz_2\rangle + \langle \zz_1,\zz_3\rangle\text{.}\)</span>
</div></li>
<li id="li-320"><div class="para" id="p-1722">
<span class="process-math">\(\langle \alpha\zz_1,\zz_2\rangle = \alpha\langle\zz_1,\zz_2\rangle\)</span> and <span class="process-math">\(\langle \zz_1,\alpha\zz_2\rangle=\bar{\alpha}\langle \zz_1,\zz_2\rangle\text{.}\)</span>
</div></li>
<li id="li-321"><div class="para" id="p-1723"><span class="process-math">\(\displaystyle \langle \zz_2,\zz_1\rangle = \overline{\langle \zz_1,\zz_2\rangle}\)</span></div></li>
<li id="li-322"><div class="para" id="p-1724">
<span class="process-math">\(\langle \zz_1,\zz_1\rangle\geq 0\text{,}\)</span> and <span class="process-math">\(\langle \zz_1,\zz_1\rangle =0\)</span> if and only if <span class="process-math">\(\zz_1=\zer\text{.}\)</span>
</div></li>
</ol>
</div></article><article class="hiddenproof" id="proof-57"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-57"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-57"><article class="hiddenproof"><div class="para logical" id="p-1725"><ol class="decimal">
<li id="li-323"><div class="para logical" id="p-1726">
<div class="para">Using the distributive properties of matrix multiplication and the transpose,</div>
<div class="displaymath process-math" id="md-65">
\begin{align*}
\langle \zz_1+\zz_2,\zz_3\rangle \amp= (\zz_1+\zz_2)^T\bar{\zz_3}\\
\amp =(\zz_1^T+\zz_2^T)\bar{\zz_3}\\
\amp =\zz_1^T\bar{\zz_3}+\zz_2^T\bar{\zz_3}\\
\amp =\langle \zz_1,\zz_3\rangle + \langle \zz_2,\zz_3\rangle\text{.}
\end{align*}
</div>
<div class="para">The proof is similar when addition is in the second component. (But not identical -- you‚Äôll need the fact that the complex conjugate is distributive, rather than the transpose.)</div>
</div></li>
<li id="li-324"><div class="para logical" id="p-1727">
<div class="para">These again follow from writing the inner product as a matrix product.</div>
<div class="displaymath process-math">
\begin{equation*}
\langle \alpha\zz_1,\zz_2\rangle = (\alpha \zz_1)^T\bar{\zz_2} = \alpha(\zz_1^T\bar{\zz_2}) = \alpha\langle\zz_1,\zz_2\rangle\text{,}
\end{equation*}
</div>
<div class="para">and</div>
<div class="displaymath process-math">
\begin{equation*}
\langle \zz_1,\alpha\zz_2\rangle = \zz_1^T\overline{\alpha \zz_2} = \zz_1^T(\bar{\alpha}\bar{\zz_2}) = \bar{\alpha}(\zz_1^T\zz_2)=\alpha\langle \zz_1,\zz_2\rangle\text{.}
\end{equation*}
</div>
</div></li>
<li id="li-325"><div class="para logical" id="p-1728">
<div class="para">Note that for any vectors <span class="process-math">\(\zz,\ww\text{,}\)</span> <span class="process-math">\(\zz^T\ww\)</span> is a number, and therefore equal to its own transpose. Thus, we have <span class="process-math">\(\zz^T\ww = (\zz^T\ww)^T=\ww^T\zz\text{,}\)</span> and</div>
<div class="displaymath process-math">
\begin{equation*}
\overline{\langle \zz_1,\zz_2\rangle} = \overline{\zz_1^T\bar{\zz_2}} = \overline{\bar{\zz_2}^T\zz_1} = \zz_2^T\overline{\zz_1}=\langle \zz_2,\zz_1\rangle\text{.}
\end{equation*}
</div>
</div></li>
<li id="li-326"><div class="para" id="p-1729">This was already demonstrated above.</div></li>
</ol></div></article></div>
<article class="definition definition-like" id="def-complex-norm"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">4.4.4</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-1730">
<div class="para">The <dfn class="terminology">norm</dfn> of a vector <span class="process-math">\(\zz = (z_1,z_2,\ldots, z_n)\)</span> in <span class="process-math">\(\C^n\)</span> is given by</div>
<div class="displaymath process-math">
\begin{equation*}
\len{\zz} = \sqrt{\langle \zz,\zz\rangle} = \sqrt{\abs{z_1}^2+\abs{z_2}^2+\cdots +\abs{z_n}^2}\text{.}
\end{equation*}
</div>
</div></article><div class="para" id="p-1731">Note that much like the real norm, the complex norm satisfies <span class="process-math">\(\len{\alpha\zz}=\abs{\alpha}\len{\zz}\)</span> for any (complex) scalar <span class="process-math">\(\alpha\text{.}\)</span>
</div>
<article class="exercise exercise-like" id="rs-tf-cnorm"><h4 class="heading">
<span class="type">Exercise</span><span class="space"> </span><span class="codenumber">4.4.5</span><span class="period">.</span>
</h4>
<div class="ptx-runestone-container"><div class="runestone"><ul data-component="multiplechoice" data-multipleanswers="false" id="rs-tf-cnorm">
<div class="para" id="p-1732">The norm of a complex vector is always a real number.</div>
<li data-component="answer" id="rs-tf-cnorm_opt_t" data-correct=""><p>True.</p></li>
<li data-component="feedback" id="rs-tf-cnorm_opt_t"><div class="para" id="p-1733">Since the norm is computed using the modulus, which is always real and non-negative, the norm will be a real number as well. If you ever get a complex number for your norm, you‚Äôve probably forgotten the complex conjugate somewhere.</div></li>
<li data-component="answer" id="rs-tf-cnorm_opt_f"><p>False.</p></li>
<li data-component="feedback" id="rs-tf-cnorm_opt_f"><div class="para" id="p-1733">Since the norm is computed using the modulus, which is always real and non-negative, the norm will be a real number as well. If you ever get a complex number for your norm, you‚Äôve probably forgotten the complex conjugate somewhere.</div></li>
</ul></div></div></article></section><section class="subsection" id="subsec-complex-matrix"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.4.2</span> <span class="title">Complex matrices</span>
</h3>
<div class="para" id="p-1734">Linear transformations are defined in exactly the same way, and a complex matrix is simply a matrix whose entries are complex numbers. There are two important operations defined on complex matrices: the conjugate, and the conjugate transpose (also known as the hermitian transpose).</div>
<article class="definition definition-like" id="def-conjugate-transpose"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">4.4.6</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-1735">
<div class="para">The <dfn class="terminology">conjugate</dfn> of a matrix <span class="process-math">\(A=[a_{ij}]\in M_{mn}(\C)\)</span> is the matrix <span class="process-math">\(\bar{A}=[\bar{a}_{ij}]\text{.}\)</span> The <dfn class="terminology">conjugate transpose</dfn> of <span class="process-math">\(A\)</span> is the matrix <span class="process-math">\(A^H\)</span> defined by</div>
<div class="displaymath process-math">
\begin{equation*}
A^H = (\bar{A})^T=\overline{(A^T)}\text{.}
\end{equation*}
</div>
</div></article><div class="para" id="p-1736">Note that many textbooks use the notation <span class="process-math">\(A^\dagger\)</span> for the conjugate transpose.</div>
<article class="definition definition-like" id="def-hermitian-unitary"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">4.4.7</span><span class="period">.</span>
</h4>
<div class="para" id="p-1737">An <span class="process-math">\(n\times n\)</span> matrix <span class="process-math">\(A\in M_{nn}(\C)\)</span> is called <dfn class="terminology">hermitian</dfn> if <span class="process-math">\(A^H = A\text{,}\)</span> and <dfn class="terminology">unitary</dfn> if <span class="process-math">\(A^H = A^{-1}\text{.}\)</span> (A matrix is <dfn class="terminology">skew-hermitian</dfn> if <span class="process-math">\(A^H=-A\text{.}\)</span>)</div></article><div class="para" id="p-1738">hermitian and unitary matrices (or more accurately, linear operators) are very important in quantum mechanics. Indeed, hermitian matrices represent ‚Äúobservable‚Äù quantities, in part because their eigenvalues are real, as we‚Äôll soon see. For us, hermitian and unitary matrices can simply be viewed as the complex counterparts of symmetric and orthogonal matrices, respectively. In fact, a real symmetric matrix <em class="emphasis">is</em> hermitian, since the conjugate has no effect on it, and similarly, a real orthogonal matrix is technically unitary. As with orthogonal matrices, a unitary matrix can also be characterized by the property that its rows and columns both form orthonormal bases.</div>
<article class="exercise exercise-like" id="exercise-158"><h4 class="heading">
<span class="type">Exercise</span><span class="space"> </span><span class="codenumber">4.4.8</span><span class="period">.</span>
</h4>
<div class="para" id="p-1739">Show that the matrix <span class="process-math">\(A = \bbm 4\amp 1-i\amp -2+3i\\1+i\amp 5 \amp 7i\\-2-3i\amp -7i\amp -4\ebm\)</span> is hermitian, and that the matrix <span class="process-math">\(B = \dfrac12\bbm 1+i\amp \sqrt{2}\\1-i\amp\sqrt{2}i\ebm\)</span> is unitary.</div></article><div class="para" id="p-1741">When using SymPy, the hermitian conjugate of a matrix <code class="code-inline tex2jax_ignore">A</code> is executed using <code class="code-inline tex2jax_ignore">A.H</code>. (There appears to also be an equivalent operation named <code class="code-inline tex2jax_ignore">Dagger</code> coming from <code class="code-inline tex2jax_ignore">sympy.physics.quantum</code>, but I‚Äôve had more success with <code class="code-inline tex2jax_ignore">.H</code>.) The complex unit is entered as <code class="code-inline tex2jax_ignore">I</code>. So for the exercise above, we can do the following.</div>
<pre class="ptx-sagecell sagecell-sage" id="sage-73"><script type="text/x-sage">A = Matrix(3,3,[4,1-I,-2+3*I,1+I,5,7*I,-2-3*I,-7*I,-4])
A == A.H
</script></pre>
<div class="para" id="p-1742">The last line verifies that <span class="process-math">\(A=A^H\text{.}\)</span> We could also replace it with <code class="code-inline tex2jax_ignore">A,A.H</code> to explicitly see the two matrices side by side. Now, let‚Äôs confirm that <span class="process-math">\(B\)</span> is unitary.</div>
<pre class="ptx-sagecell sagecell-sage" id="sage-74"><script type="text/x-sage">B = Matrix(2,2,[1/2+1/2*I, sqrt(2)/2,1/2-1/2*I,(sqrt(2)/2)*I])
B,B*B.H
</script></pre>
<div class="para" id="p-1743">Hmm... That doesn‚Äôt look like the identity on the right. Maybe try replacing <code class="code-inline tex2jax_ignore">B*B.H</code> with <code class="code-inline tex2jax_ignore">simplify(B*B.H)</code>. (You will want to add <code class="code-inline tex2jax_ignore">from sympy import simplify</code> at the top of the cell.) Or you could try <code class="code-inline tex2jax_ignore">B.H, B**-1</code> to compare results. Actually, what‚Äôs interesting is that in a Sage cell, <code class="code-inline tex2jax_ignore">B.H == B**-1</code> yields <code class="code-inline tex2jax_ignore">False</code>, but <code class="code-inline tex2jax_ignore">B.H == simplify(B**-1)</code> yields <code class="code-inline tex2jax_ignore">True</code>!</div>
<div class="para" id="p-1744">As mentioned above, hermitian matrices are the complex analogue of symmetric matrices. Recall that a key property of a symmetric matrix is its symmetry with respect to the dot product. For a symmetric matrix <span class="process-math">\(A\text{,}\)</span> we had <span class="process-math">\(\mathbf{x}\dotp (A\mathbf{y})=(A\mathbf{x})\dotp \mathbf{y}\text{.}\)</span> Hermtian matrices exhibit the same behaviour with respect to the complex inner product.</div>
<article class="theorem theorem-like" id="thm-hermitian-symmetry"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">4.4.9</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-1745">
<div class="para">An <span class="process-math">\(n\times n\)</span> complex matrix <span class="process-math">\(A\)</span> is hermitian if and only if</div>
<div class="displaymath process-math">
\begin{equation*}
\langle A\zz,\ww\rangle = \langle \zz, A\ww\rangle
\end{equation*}
</div>
<div class="para">for any <span class="process-math">\(\zz,\ww\in\C^n\)</span>
</div>
</div></article><article class="hiddenproof" id="proof-58"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-58"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-58"><article class="hiddenproof"><div class="para logical" id="p-1746">
<div class="para">Note that the property <span class="process-math">\(A^H=A\)</span> is equivalent to <span class="process-math">\(A^T=\bar{A}\text{.}\)</span> This gives us</div>
<div class="displaymath process-math">
\begin{equation*}
\langle A\zz,\ww\rangle = (A\zz)^T\bar{\ww} = (\zz^TA^T)\bar{\ww} = (\zz^T\bar{A})\bar{\ww}=\zz^T(\overline{A\ww}) = \langle \zz,\ww\rangle\text{.}
\end{equation*}
</div>
<div class="para">Conversely, suppose <span class="process-math">\(\langle A\zz,\ww\rangle = \langle \zz, A\ww\rangle\)</span> for all <span class="process-math">\(\zz,\ww\in \C^n\text{,}\)</span> and let <span class="process-math">\(\basis{e}{n}\)</span> denote the standard basis for <span class="process-math">\(\C^n\text{.}\)</span> Then</div>
<div class="displaymath process-math">
\begin{equation*}
a_{ji}=\langle A\mathbf{e}_i,\mathbf{e}_j\rangle = \langle \mathbf{e}_i,A\mathbf{e}_j\rangle = \overline{a_{ij}}\text{,}
\end{equation*}
</div>
<div class="para">which shows that <span class="process-math">\(A^T=\bar{A}\text{.}\)</span>
</div>
</div></article></div>
<div class="para" id="p-1747">Next, we‚Äôve noted that one advantage of doing linear algebra over <span class="process-math">\(\C\)</span> is that every polynomial can be completely factored, including the characteristic polynomial. This means that we can always find eigenvalues for a matrix. When that matrix is hermitian, we get a surprising result.</div>
<article class="theorem theorem-like" id="thm-hermitian-eigen-real"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">4.4.10</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-1748">
<div class="para">For any hermitian matrix <span class="process-math">\(A\text{,}\)</span>
</div>
<ol class="decimal">
<li id="li-327"><div class="para" id="p-1749">The eigenvalues of <span class="process-math">\(A\)</span> are real.</div></li>
<li id="li-328"><div class="para" id="p-1750">Eigenvectors corresponding to distinct eigenvalues are orthogonal.</div></li>
</ol>
</div></article><article class="hiddenproof" id="proof-59"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-59"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-59"><article class="hiddenproof"><div class="para logical" id="p-1751"><ol class="decimal">
<li id="li-329"><div class="para logical" id="p-1752">
<div class="para">Suppose <span class="process-math">\(A\zz = \lambda\zz\)</span> for some <span class="process-math">\(\lambda\in\C\)</span> and <span class="process-math">\(\zz\neq \zer\text{.}\)</span> Then</div>
<div class="displaymath process-math">
\begin{equation*}
\lambda \langle \zz,\zz\rangle  = \langle \lambda\zz,\zz\rangle = \langle A\zz,\zz \rangle = \langle \zz, A\zz\rangle = \langle \zz,\lambda\zz\rangle = \bar{\lambda}\langle \zz,\zz\rangle\text{.}
\end{equation*}
</div>
<div class="para">Thus, <span class="process-math">\((\lambda-\bar{\lambda})\len{\zz}^2=0\text{,}\)</span> and since <span class="process-math">\(\len{z}\neq 0\text{,}\)</span> we must have <span class="process-math">\(\bar{\lambda}=\lambda\text{,}\)</span> which means <span class="process-math">\(\lambda\in\R\text{.}\)</span>
</div>
</div></li>
<li id="li-330"><div class="para logical" id="p-1753">
<div class="para">Similarly, suppose <span class="process-math">\(\lambda_1,\lambda_2\)</span> are eigenvalues of <span class="process-math">\(A\text{,}\)</span> with corresponding eigenvectors <span class="process-math">\(\zz,\ww\text{.}\)</span> Then</div>
<div class="displaymath process-math">
\begin{equation*}
\lambda_1\langle \zz,\ww\rangle = \langle \lambda_1\zz,\ww\rangle = \langle A\zz,\ww\rangle =\langle \zz,A\ww\rangle = \langle \zz,\lambda_2\ww\rangle = \bar{\lambda_2}\langle\zz,\ww\rangle\text{.}
\end{equation*}
</div>
<div class="para">This gives us <span class="process-math">\((\lambda_1-\bar{\lambda_2})\langle \zz,\ww\rangle=0\text{.}\)</span> And since we already know <span class="process-math">\(\lambda_2\)</span> must be real, and <span class="process-math">\(\lambda_1\neq \lambda_2\text{,}\)</span> we must have <span class="process-math">\(\langle \zz,\ww\rangle = 0\text{.}\)</span>
</div>
</div></li>
</ol></div></article></div>
<div class="para" id="p-1754">In light of <a href="" class="xref" data-knowl="./knowl/thm-hermitian-eigen-real.html" title="Theorem 4.4.10">Theorem¬†4.4.10</a>, we realize that diagonalization of hermitian matrices will follow the same script as for symmetric matrices. Indeed, <a href="" class="xref" data-knowl="./knowl/thm-gram-schmidt.html" title="Theorem 3.2.4: Gram-Schmidt Orthonormalization Algorithm">Gram-Schmidt Orthonormalization Algorithm</a> applies equally well in <span class="process-math">\(\C^n\text{,}\)</span> as long as we replace the dot product with the complex inner product. This suggests the following.</div>
<article class="theorem theorem-like" id="thm-complex-spectral"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">4.4.11</span><span class="period">.</span><span class="space"> </span><span class="title">Spectral Theorem.</span>
</h4>
<div class="para" id="p-1755">If <span class="process-math">\(A\)</span> is an <span class="process-math">\(n\times n\)</span> hermitian matrix, then there exists an orthonormal basis of <span class="process-math">\(\C^n\)</span> consisting of eigenvectors of <span class="process-math">\(A\text{.}\)</span> Moreover, the matrix <span class="process-math">\(U\)</span> whose columns consist of those eigenvectors is unitary, and the matrix <span class="process-math">\(U^HAU\)</span> is diagonal.</div></article><article class="exercise exercise-like" id="exercise-159"><h4 class="heading">
<span class="type">Exercise</span><span class="space"> </span><span class="codenumber">4.4.12</span><span class="period">.</span>
</h4>
<div class="para" id="p-1756">Confirm that the matrix <span class="process-math">\(A = \bbm 4 \amp 3-i\\3+i\amp 1\ebm\)</span> is hermitian. Then, find the eigenvalues of <span class="process-math">\(A\text{,}\)</span> and a unitary matrix <span class="process-math">\(U\)</span> such that <span class="process-math">\(U^HAU\)</span> is diagonal.</div></article><div class="para" id="p-1763">To do the above exercise using SymPy, we first define <span class="process-math">\(A\)</span> and ask for the eigenvectors.</div>
<pre class="ptx-sagecell sagecell-sage" id="sage-75"><script type="text/x-sage">A = Matrix(2,2,[4,3-I,3+I,1])
A.eigenvects()
</script></pre>
<div class="para" id="p-1764">We can now manually determine the matrix <span class="process-math">\(U\text{,}\)</span> as we did above, and input it:</div>
<pre class="ptx-sagecell sagecell-sage" id="sage-76"><script type="text/x-sage">U = Matrix([[(3-I)/sqrt(35),(3-I)/sqrt(14)],
            [-5/sqrt(35),2/sqrt(14)]])
</script></pre>
<div class="para" id="p-1765">To confirm it‚Äôs unitary, add the line <code class="code-inline tex2jax_ignore">U*U.H</code> to the above, and confirm that you get the identity matrix as output. You might need to use <code class="code-inline tex2jax_ignore">simplify(U*U.H)</code> if the result is not clear. Now, to confirm that <span class="process-math">\(U^HAU\)</span> really is diagonal, go back to the cell above, and enter it. Try <code class="code-inline tex2jax_ignore">(U.H)*A*U</code>, just to remind yourself that adding the <code class="code-inline tex2jax_ignore">simplify</code> command is often a good idea.</div>
<div class="para" id="p-1766">If you want to cut down on the manual labour involved, we can make use of some of the other tools SymPy provides. In the next cell, we‚Äôre going to assign the output of <code class="code-inline tex2jax_ignore">A.eigenvects()</code> to a list. The only trouble is that the output of the eigenvector command is a list of lists. Each list item is a list <code class="code-inline tex2jax_ignore">(eigenvalue, multiplicity, [eigenvectors])</code>.</div>
<pre class="ptx-sagecell sagecell-sage" id="sage-77"><script type="text/x-sage">L = A.eigenvects()
L
</script></pre>
<div class="para logical" id="p-1767">
<div class="para">Try the above modifications, in sequence. First, replacing the second line by <code class="code-inline tex2jax_ignore">L[0]</code> will give the first list item, which is another list:</div>
<div class="displaymath process-math">
\begin{equation*}
\left(-1,1,\left[\bbm -\frac35+\frac{i}{5}\ebm\right]\right)\text{.}
\end{equation*}
</div>
<div class="para">We want the third item in the list, so try <code class="code-inline tex2jax_ignore">(L[0])[2]</code>. But note the extra set of brackets! There could (in theory) be more than one eigenvector, so this is a list with one item. To finally get the vector out, try <code class="code-inline tex2jax_ignore">((L[0])[2])[0]</code>. (There is probably a better way to do this. Someone who is more fluent in Python is welcome to advise.)</div>
</div>
<div class="para" id="p-1768">Now that we know how to extract the eigenvectors, we can normalize them, and join them to make a matrix. The norm of a vector is simnply <code class="code-inline tex2jax_ignore">v.norm()</code>, and to join column vectors <code class="code-inline tex2jax_ignore">u1</code> and <code class="code-inline tex2jax_ignore">u2</code> to make a matrix, we can use the command <code class="code-inline tex2jax_ignore">u1.row_join(u2)</code>. We already defined the matrix <code class="code-inline tex2jax_ignore">A</code> and list <code class="code-inline tex2jax_ignore">L</code> above, but here is the whole routine in one cell, in case you didn‚Äôt run all the cells above.</div>
<pre class="ptx-sagecell sagecell-sage" id="sage-78"><script type="text/x-sage">from sympy import Matrix, init_printing, simplify
init_printing()
A = Matrix(2,2,[4,3-I,3+I,1])
L = A.eigenvects()
v = ((L[0])[2])[0]
w = ((L[1])[2])[0]
u1 = (1/v.norm())*v
u2 = (1/w.norm())*w
U = u1.row_join(u2)
u1, u2, U, simplify(U.H*A*U)
</script></pre>
<div class="para" id="p-1769">Believe me, you want the simplify command on that last matrix.</div>
<div class="para" id="p-1770">While <a href="" class="xref" data-knowl="./knowl/thm-complex-spectral.html" title="Theorem 4.4.11: Spectral Theorem">Theorem¬†4.4.11</a> guarantees that any hermitian matrix can be ‚Äúunitarily diagonalized‚Äù, there are also non-hermitian matrices for which this can be done as well. A classic example of this is the rotation matrix <span class="process-math">\(\bbm 0\amp 1\\-1\amp 0\ebm\text{.}\)</span> This is a real matrix with complex eigenvalues <span class="process-math">\(\pm i\text{,}\)</span> and while it is neither symmetric nor hermitian, it can be orthogonally diagonalized. This should be contrasted with the real spectral theorem, where any matrix that can be orthogonally diagonalized is necessarily symmetric.</div>
<div class="para" id="p-1771">This suggests that perhaps hermitian matrices are not quite the correct class of matrix for which the spectral theorem should be stated. Indeed, it turns out there is a somewhat more general class of matrix: the <em class="emphasis">normal</em> matrices.</div>
<article class="definition definition-like" id="def-normal-matrix"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">4.4.13</span><span class="period">.</span>
</h4>
<div class="para" id="p-1772">An <span class="process-math">\(n\times n\)</span> matrix <span class="process-math">\(A\)</span> is <dfn class="terminology">normal</dfn> if <span class="process-math">\(A^HA = AA^H\text{.}\)</span>
</div></article><article class="exercise exercise-like" id="rs-mc-normal"><h4 class="heading">
<span class="type">Exercise</span><span class="space"> </span><span class="codenumber">4.4.14</span><span class="period">.</span>
</h4>
<div class="ptx-runestone-container"><div class="runestone"><ul data-component="multiplechoice" id="rs-mc-normal" data-multipleanswers="true" data-random="">Select all matrices below that are normal.<li data-component="answer" id="rs-mc-normal_opt_a" data-correct=""><div class="para" id="p-1773"><span class="process-math">\(\begin{bmatrix} 3\amp 1-3i\\ 1+3i\amp -4\end{bmatrix}\)</span></div></li>
<li data-component="feedback" id="rs-mc-normal_opt_a"><div class="para" id="p-1774">This matrix is hermitian, and we know that every hermitian matrix is normal.</div></li>
<li data-component="answer" id="rs-mc-normal_opt_b"><div class="para" id="p-1775"><span class="process-math">\(\begin{bmatrix} 1\amp 3\\ 0 \amp 2\end{bmatrix}\)</span></div></li>
<li data-component="feedback" id="rs-mc-normal_opt_b"><div class="para" id="p-1776">This matrix is not normal; this can be confirmed by direct computation, or by noting that it cannot be diagonalized.</div></li>
<li data-component="answer" id="rs-mc-normal_opt_c" data-correct=""><div class="para" id="p-1777"><span class="process-math">\(\frac{1}{\sqrt{2}}\begin{bmatrix} 1\amp 1\\ i \amp -i\end{bmatrix} \)</span></div></li>
<li data-component="feedback" id="rs-mc-normal_opt_c"><div class="para" id="p-1778">This matrix is unitary, and every unitary matrix is normal.</div></li>
<li data-component="answer" id="rs-mc-normal_opt_d" data-correct=""><div class="para" id="p-1779"><span class="process-math">\(\begin{bmatrix} i \amp 2i\\ 2i \amp 3i\end{bmatrix}\)</span></div></li>
<li data-component="feedback" id="rs-mc-normal_opt_d"><div class="para" id="p-1780">This matrix is neither hermitian nor unitary, but it is normal, which can be verified by direct computation.</div></li>
</ul></div></div></article><div class="para" id="p-1781">It turns out that a matrix <span class="process-math">\(A\)</span> is normal if and only if <span class="process-math">\(A=UDU^H\)</span> for some unitary matrix <span class="process-math">\(U\)</span> and diagonal matrix <span class="process-math">\(D\text{.}\)</span> A further generalization is known as <em class="emphasis">Schur‚Äôs Theorem</em>.</div>
<article class="theorem theorem-like" id="thm-schurr"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">4.4.15</span><span class="period">.</span>
</h4>
<div class="para" id="p-1782">For <em class="emphasis">any</em> complex <span class="process-math">\(n\times n\)</span> matrix <span class="process-math">\(A\text{,}\)</span> there exists a unitary matrix <span class="process-math">\(U\)</span> such that <span class="process-math">\(U^HAU = T\)</span> is upper-triangular, and such that the diagonal entries of <span class="process-math">\(T\)</span> are the eigenvalues of <span class="process-math">\(A\text{.}\)</span>
</div></article><div class="para" id="p-1783">Using Schur‚Äôs Theorem, we can obtain a famous result, known as the Cayley-Hamilton Theorem, for the case of complex matrices. (It is true for real matrices as well, but we don‚Äôt yet have the tools to prove it.) The Cayley-Hamilton Theorem states that substituting any matrix into its characteristic polynomial results in the zero matrix. To understand this result, we should first explain how to define a polynomial of a matrix.</div>
<div class="para logical" id="p-1784">
<div class="para">Given a polynomial <span class="process-math">\(p(x) = a_0+a_1x+\cdots + a_nx_n\text{,}\)</span> we define <span class="process-math">\(p(A)\)</span> as</div>
<div class="displaymath process-math">
\begin{equation*}
p(A) = a_0I+a_1A+\cdots + a_nA^n\text{.}
\end{equation*}
</div>
<div class="para">(Note the presence of the identity matrix in the first term, since it does not make sense to add a scalar to a matrix.) Note further that since <span class="process-math">\((P^{-1}AP)^n = P^{-1}A^nP\)</span> for any invertible matrix <span class="process-math">\(P\)</span> and positive integer <span class="process-math">\(n\text{,}\)</span> we have <span class="process-math">\(p(U^HAU)=U^Hp(A)U\)</span> for any polynomial <span class="process-math">\(p\)</span> and unitary matrix <span class="process-math">\(U\text{.}\)</span>
</div>
</div>
<article class="theorem theorem-like" id="thm-cayley-hamilton-c"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">4.4.16</span><span class="period">.</span>
</h4>
<div class="para" id="p-1785">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n\times n\)</span> complex matrix, and let <span class="process-math">\(c_A(x)\)</span> denote the characteristic polynomial of <span class="process-math">\(A\text{.}\)</span> Then we have <span class="process-math">\(c_A(A)=0\text{.}\)</span>
</div></article><article class="hiddenproof" id="proof-60"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-60"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-60"><article class="hiddenproof"><div class="para logical" id="p-1786">
<div class="para">By <a href="" class="xref" data-knowl="./knowl/thm-schurr.html" title="Theorem 4.4.15">Theorem¬†4.4.15</a>, there exists a unitary matrix <span class="process-math">\(U\)</span> such that <span class="process-math">\(A = UTU^H\text{,}\)</span> where <span class="process-math">\(T\)</span> is upper triangular, and has the eigenvalues of <span class="process-math">\(A\)</span> as diagonal entries. Since <span class="process-math">\(c_A(A)=c_A(UTU^H)=Uc_A(T)U^H\text{,}\)</span> and <span class="process-math">\(c_A(x)=c_T(x)\)</span> (since <span class="process-math">\(A\)</span> and <span class="process-math">\(T\)</span> are similar) it suffices to show that <span class="process-math">\(c_A(A)=0\)</span> when <span class="process-math">\(A\)</span> is upper-triangular. (If you like, we are showing that <span class="process-math">\(C_T(T)=0\text{,}\)</span> and deducing that <span class="process-math">\(c_A(A)=0\text{.}\)</span>) But if <span class="process-math">\(A\)</span> is upper-triangular, so is <span class="process-math">\(xI_A\text{,}\)</span> and therefore, <span class="process-math">\(\det(xI-A)\)</span> is just the product of the diagonal entries. That is,</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/thm-schurr.html">
\begin{equation*}
c_A(x) = (x-\lambda_1)(x-\lambda_2)\cdots (x-\lambda_n)\text{,}
\end{equation*}
</div>
<div class="para">so</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/thm-schurr.html">
\begin{equation*}
c_A(A) = (A-\lambda_1I)(A-\lambda_2I)\cdots (A-\lambda_nI)\text{.}
\end{equation*}
</div>
</div> <div class="para" id="p-1787">Since the first column of <span class="process-math">\(A\)</span> is <span class="process-math">\(\bbm \lambda_1\amp 0 \amp \cdots \amp 0\ebm^T\text{,}\)</span> the first column of <span class="process-math">\(A-\lambda_1I\)</span> is identically zero. The second column of <span class="process-math">\(A-\lambda_2I\)</span> similarly has the form <span class="process-math">\(\bbm k\amp 0\amp\cdots\amp 0\ebm\)</span> for some number <span class="process-math">\(k\text{.}\)</span>
</div> <div class="para" id="p-1788">It follows that the first two columns of <span class="process-math">\((A-\lambda_1I)(A-\lambda_2I)\)</span> are identically zero. Since only the first two entries in the third column of <span class="process-math">\((A-\lambda_3I)\)</span> can be nonzero, we find that the first three columns of <span class="process-math">\((A-\lambda_1I)(A-\lambda_2I)(A-\lambda_3I)\)</span> are zero, and so on.</div></article></div></section></section></div>
<div class="ptx-content-footer">
<a class="previous-button button" href="sec-quadratic.html" title="Previous"><span class="icon">&lt;</span><span class="name">Prev</span></a><a class="top-button button" href="#" title="Top"><span class="icon">^</span><span class="name">Top</span></a><a class="next-button button" href="worksheet-dynamical.html" title="Next"><span class="name">Next</span><span class="icon">&gt;</span></a>
</div></main>
</div>
<div id="ptx-page-footer" class="ptx-page-footer">
<a class="pretext-link" href="https://pretextbook.org" title="PreTeXt"><div class="logo"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="338 3000 8772 6866"><g style="stroke-width:.025in; stroke:black; fill:none"><polyline points="472,3590 472,9732 " style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round; "></polyline><path style="stroke:#000000;stroke-width:126;stroke-linecap:butt;" d="M 4724,9448 A 4660 4660  0  0  1  8598  9259"></path><path style="stroke:#000000;stroke-width:174;stroke-linecap:butt;" d="M 4488,9685 A 4228 4228  0  0  0   472  9732"></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:butt;" d="M 4724,3590 A 4241 4241  0  0  1  8598  3496"></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:round;" d="M 850,3496  A 4241 4241  0  0  1  4724  3590"></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:round;" d="M 850,9259  A 4507 4507  0  0  1  4724  9448"></path><polyline points="5385,4299 4062,8125" style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="8598,3496 8598,9259" style="stroke:#000000;stroke-width:126; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="850,3496 850,9259" style="stroke:#000000;stroke-width:126; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="4960,9685 4488,9685" style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="3070,4582 1889,6141 3070,7700" style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="6418,4582 7600,6141 6418,7700" style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="8976,3590 8976,9732" style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round;"></polyline><path style="stroke:#000000;stroke-width:174;stroke-linecap:butt;" d="M 4960,9685 A 4228 4228  0  0  1  8976  9732"></path></g></svg></div></a><a class="runestone-link" href="https://runestone.academy" title="Runestone Academy"><img class="logo" src="https://runestone.academy/runestone/static/images/RAIcon_cropped.png"></a><a class="mathjax-link" href="https://www.mathjax.org" title="MathJax"><img class="logo" src="https://www.mathjax.org/badge/badge-square-2.png"></a>
</div>
</body>
</html>
