<?xml version="1.0" encoding="UTF-8" ?>

<section xml:id="sec-vec-sp">
  <title>Abstract vector spaces</title>

  <introduction>
    <p>
      Let's recall what we know about vectors in <m>\R^2</m>.
      Writing <m>\vv = \langle x,y\rangle</m> for the vector pointing from <m>(0,0)</m> to <m>(x,y)</m>,
      we define:
      <ol>
        <li>
          <p>
            Addition: <m>\langle x_1,y_1\rangle + \langle x_2,y_2\rangle = \langle x_1+y_1, x_2+y_2\rangle</m>
          </p>
        </li>
        <li>
          <p>
            Scalar multiplication: <m>c\langle x, y\rangle = \langle cx, cy\rangle</m>,
            where <m>c</m> is a real number, or <em>scalar</em>.
          </p>
        </li>
      </ol>
    </p>

    <p>
      We can then observe a number of properties enjoyed by these operations.
      In your first course, you may have observed some of these properties geometrically,
      using the <q>tip-to-tail</q> rule for vector addition.
    </p>

    <p>
      <ol>
        <li>
          <p>
            Vector addition is <em>commutative</em>.
            That is, for any vectors <m>\vv = \langle a, b\rangle</m> and <m>\ww = \langle c,d\rangle</m>,
            we have <m>\vv+\ww = \ww+\vv</m>.
          </p>
          <p>
            This is true because addition is commutative for the real numbers:
            <me>
              \vv+\ww = \langle a+c, b+d\rangle = \langle c+a, d+b\rangle = \ww+\vv
            </me>.
          </p>
        </li>

        <li>
          <p>
            Vector addition is <em>associative</em>.
            That is, for any vectors <m>\uu = \langle a, b\rangle, \vv = \langle c, d\rangle</m>
            and <m>\ww = \langle p, q\rangle</m>, we have
            <me>
              \uu+(\vv+\ww) = (\uu+\vv)+\ww
            </me>.
            This tells us that placement of parentheses doesn't matter,
            which is essential for extending addition (which is defined as an operation on <em>two</em> vectors)
            to sums of three or more vectors.
          </p>
          <p>
            Again, this property is true because it is true for real numbers:
            <md>
              <mrow>\uu + (\vv+\ww) \amp = \langle a,b\rangle + \langle c+p,d+q\rangle </mrow>
              <mrow> \amp = \langle a+(c+p), b+(d+q)\rangle</mrow>
              <mrow> \amp = \langle (a+c)+p, (b+d)+q\rangle</mrow>
              <mrow> \amp = \langle a+c, b+d\rangle + \langle p,q\rangle</mrow>
              <mrow> \amp = (\uu+\vv)+\ww</mrow>
            </md>.
          </p>
        </li>
        <li>
          <p>
            Vector addition has an <em>identity element</em>.
            This is a vector that has no effect when added to another vector,
            or in other words, the zero vector.
            Again, it inherits its property from the behaviour of the real number 0.
          </p>
          <p>
            For any <m>\vv=\langle a,b\rangle</m>, the vector <m>\zer = \langle 0,0\rangle</m>
            satisfies <m>\vv+\zer = \zer+\vv=\vv</m>:
            <me>
              \langle a+0,b+0\rangle = \langle 0+a,0+b\rangle = \langle a,b\rangle
            </me>.
          </p>
        </li>
        <li>
          <p>
            Every vector has an <em>inverse</em> with respect to addition,
            or, in other words, a <em>negative</em>.
            Given a vector <m>\vv = \langle a, b\rangle</m>,
            the vector <m>-\vv = \langle -a, -b\rangle</m> satisfies
            <me>
              \vv+(-\vv) = -\vv + \vv = \zer
            </me>.
            (We will leave this one for you to check.)
          </p>
        </li>
        <li>
          <p>
            Scalar multiplication is compatible with addition in two different ways.
            First, it is <em>distributive</em> over vector addition:
            for any scalar <m>k</m> and vectors <m>\vv=\langle a, b\rangle, \ww = \langle c,d\rangle</m>,
            we have <m>k(\vv+\ww)=k\vv+k\ww</m>.
          </p>

          <p>
            Unsurprisingly, this property is inherited from the distributive property of the real numbers:
            <md>
              <mrow>k(\vv+ww) \amp = k\langle a+c,b+d\rangle</mrow>
              <mrow> \amp = \langle k(a+c),k(b+d)\rangle </mrow>
              <mrow> \amp = \langle ka+kc,kb+kd\rangle</mrow>
              <mrow> \amp = \langle ka, kb\rangle+\langle kc, kd\rangle</mrow>
              <mrow> \amp k\langle a,b\rangle + k\langle c,d\rangle = k\vv+k\ww</mrow>
            </md>.
          </p>
        </li>
        <li>
          <p>
            Second, scalar multiplication is also distributive with respect to <em>scalar</em>
            addition: for any scalars <m>c</m> and <m>d</m> and vector <m>\vv</m>,
            we have <m>(c+d)\vv=c\vv+d\vv</m>.
          </p>
          <p>
            Again, this is because real number addition is distributive:
            <md>
              <mrow>(c+d)\langle a, b\rangle \amp = \langle (c+d)a,(c+d)b\rangle</mrow>
              <mrow> \amp = \langle ca+da, cb+db\rangle </mrow>
              <mrow> \amp = \langle ca, cb\rangle + \langle da, db\rangle</mrow>
              <mrow> \amp c\langle a, b\rangle + d\langle a, b\rangle</mrow>
            </md>.
          </p>
        </li>
        <li>
          <p>
            Scalar multiplication is also <em>associative</em>.
            Given scalars <m>c,d</m> and a vector <m>\vv=\langle a,b\rangle</m>,
            we have <m>c(d\vv) = (cd)\vv</m>.
          </p>
          <p>
            This is inherited from the associativity of real number multiplication:
            <me>
              c(d\vv) = c\langle da, db\rangle =\langle c(da),c(db)\rangle = \langle (cd)a,(cd)b\rangle = (cd)\langle a,b\rangle
            </me>.
          </p>
        </li>

        <li>
          <p>
            Finally, there is a <q>normalization</q> result for scalar multiplication.
            For any vector <m>\vv</m>, we have <m>1\vv = \vv</m>.
            That is, the real number <m>1</m> acts as an identity element with respect to scalar multiplication.
            (You can check this one yourself.)
          </p>
        </li>
      </ol>
    </p>

    <p>
      You might be wondering why we bother to list the last property above.
      It's true, but why do we need it?
      One reason comes from basic algebra, and solving equations.
      Suppose we have the equation <m>c\vv = \ww</m>, where <m>c</m> is some nonzero scalar,
      and we want to solve for <m>\vv</m>.
      Very early in our algebra careers, we learn that to solve, we <q>divide by <m>c</m></q>.
    </p>

    <p>
      Division doesn't quite make sense in this context,
      but it certainly does make sense to multiply both sides by <m>1/c</m>,
      the multiplicative inverse of <m>c</m>.
      We then have <m>(1/c)(c\vv)=(1/c)\ww</m>, and since scalar multiplication is associative,
      <m>(1/c\cdot c)\vv = (1/c)\ww</m>.
      We know that <m>1/c \cdot c = 1</m>, so this boils down to <m>1\vv=(1/c)\ww</m>.
      It appears that we've solved the equation, but <em>only if we know</em> that <m>1\vv = \vv</m>.
    </p>

    <p>
      For an example where this fails, take our vectors as above,
      but redefine the scalar multiplication as <m>c\langle a, b\rangle = \langle ca, 0\rangle</m>.
      The distributive and associative properties for scalar multiplication will still hold,
      but the normalization property fails.
      Algebra becomes very strange with this version of scalar multiplication.
      In particular, we can no longer conclude that if <m>2\vv=2\ww</m>, then <m>\vv=\ww</m>!
    </p>
  </introduction>

  <subsection xml:id="subsec-vsp-def-examples">
    <title>Definition and examples</title>

    <p>
      In a first course in linear algebra,
      these algebraic properties of vector addition and scalar multiplication are presented as a <em>theorem</em>.
      (After all, we have just demonstrated the truth of these results.)
      A second course in linear algebra (and in particular, <em>abstract</em> linear algebra),
      begins by taking that theorem and turning it into a <em>definition</em>.
      We will then do some exploration, to see if we can come up with some other examples that fit the definition;
      the significance of this is that we can expect the algebra in these examples
      to behave in essentially the same way as the vectors we're familiar with.
    </p>

    <definition xml:id="def-vector-space">
      <statement>
        <p>
          A <term>real vector space</term> (or vector space over <m>\R</m>) is a nonempty set <m>V</m>, whose objects are called <term>vectors</term>,
          equipped with two operations:
          <ol>
            <li>
              <p>
                <term>Addition</term>, which is a map from <m>V\times V</m> to <m>V</m>
                that associates each ordered pair of vectors <m>(\vv,\ww)</m> to a vector <m>\vv+\ww</m>,
                called the <term>sum</term> of <m>\vv</m> and <m>\ww</m>.
              </p>
            </li>

            <li>
              <p>
                <term>Scalar multiplication</term>, which is a map from <m>\R\times V</m> to <m>V</m>
                that associates each real number <m>c</m> and vector <m>\vv</m> to a vector <m>c\vv</m>.
              </p>
            </li>
          </ol>
        </p>

        <p>
          The operations of addition and scalar multiplication are required to satisfy the following <em>axioms</em>:
          <dl>
            <li>
              <title>A1.</title>
              <p>
                If <m>\uu,\vv\in V</m>, then <m>\uu+\vv\in V</m>. (Closure under addition)
              </p>
            </li>
            <li>
              <title>A2.</title>
              <p>
                For all <m>\uu,\vv\in V</m>, <m>\uu+\vv=\vv+\uu</m>. (Commutativity of addition)
              </p>
            </li>
            <li>
              <title>A3.</title>
              <p>
                For all <m>\uu,\vv,\ww\in V</m>, <m>\uu+(\vv+\ww)=(\uu+\vv)+\ww</m>. (Associativity of addition)
              </p>
            </li>
            <li>
              <title>A4.</title>
              <p>
                There exists an element <m>\zer\in V</m> such that <m>\vv+\zer=\vv</m> for each <m>\vv\in V</m>. (Existence of a zero vector)
              </p>
            </li>
            <li>
              <title>A5.</title>
              <p>
                For each <m>\vv\in V</m>, there exists a vector <m>-\vv\in V</m> such that <m>\vv+(-\vv)=\zer</m>. (Existence of negatives)
              </p>
            </li>
            <li>
              <title>S1.</title>
              <p>
                If <m>\vv\in V</m>, then <m>c\vv\in V</m> for all <m>c\in\R</m>. (Closure under scalar multiplication)
              </p>
            </li>
            <li>
              <title>S2.</title>
              <p>
                For all <m>c\in \R</m> and <m>\vv,\ww\in V</m>, <m>c(\vv+\ww)=c\vv+c\ww</m>. (Distribution over vector addition)
              </p>
            </li>
            <li>
              <title>S3.</title>
              <p>
                For all <m>a,b\in\R</m> and <m>\vv\in V</m>, <m>(a+b)\vv=a\vv+b\vv</m>. (Distribution over scalar addition)
              </p>
            </li>
            <li>
              <title>S4.</title>
              <p>
                For all <m>a,b\in \R</m> and <m>\vv\in V</m>, <m>a(b\vv)=(ab)\vv</m>. (Associativity of scalar multiplication)
              </p>
            </li>
            <li>
              <title>S5.</title>
              <p>
                For all <m>\vv\in V</m>, <m>1\vv=\vv</m>. (Normalization of scalar multiplication)
              </p>
            </li>
          </dl>
        </p>
      </statement>
    </definition>

    <p>
      Note that a zero vector must exist in every vector space.
      This simple observation is a key component of many proofs and counterexamples in linear algebra.
      In general, we may define a vector space whose scalars belong to a <em>field</em> <m>\mathbb{F}</m>.
      A field is a set of objects whose algebraic properties are modelled after those of the real numbers.
    </p>

    <p>
      The axioms for a field are not all that different than those for a vector space.
      The main difference is that in a field, multiplication is defined between elements of the field
      (and produces another element of the field),
      while scalar multiplication combines elements of two different sets.
    </p>

    <definition xml:id="def-field">
      <statement>
        <p>
          A <term>field</term> is a set <m>\mathbb{F}</m>,
          equipped with two binary operations <m>\mathbb{F}\times\mathbb{F} \amp \to \mathbb{F}</m>:
          <md>
            <mrow> (a,b)\amp \mapsto a+b \quad \text{ usually called <term>addition</term>}</mrow>
            <mrow> (a,b)\amp \mapsto a\cdot b \text{ usually called <term>multiplication</term>}</mrow>
          </md>,
          such that the following axioms are satisfied:
          <ol>
            <li>
              <p>
                A1: for all <m>a,b\in \mathbb{F}, a+b=b+a</m>.
              </p>
            </li>
            <li>
              <p>
                A2: for all <m>a,b,c\in\mathbb{F}, a+(b+c)=(a+b)+c</m>
              </p>
            </li>
            <li>
              <p>
                A3: there exists an element <m>0\in\mathbb{F}</m> such that <m>0+a=a</m> for all <m>a\in\mathbb{F}</m>.
              </p>
            </li>
            <li>
              <p>
                A4: for each <m>a\in\mathbb{F}</m>, there exists an element <m>-a\in\mathbb{F}</m> such that <m>-a+a=0</m>.
              </p>
            </li>
            <li>
              <p>
                M1: for all <m>a,b\in\mathbb{F}</m>, <m>a\cdot b=b\cdot a</m>.
              </p>
            </li>
            <li>
              <p>
                M2: for all <m>a,b,c\in\mathbb{F}</m>, <m>a\cdot (b\cdot c)=(a\cdot b)\cdot c</m>.
              </p>
            </li>
            <li>
              <p>
                M3: there exists an element <m>1\in\mathff{F}</m> such that <m>1\cdot a=a</m> for all <m>a\in \mathbb{F}</m>.
              </p>
            </li>
            <li>
              <p>
                M4: for each <m>a\in\mathbb{F}</m> with <m>a\neq 0</m>, there exists an element <m>1/a\in\mathbb{F}</m> such that <m>1/a\cdot a = 1</m>.
              </p>
            </li>
            <li>
              <p>
                D: for all <m>a,b,c\in \mathbb{F}</m>, <m>a\cdot (b+c) = a\cdot b+a\cdot c</m>.
              </p>
            </li>
          </ol>
        </p>
      </statement>
    </definition>

    <p>
      Note how the axioms for multiplication in a field mirror the addition axioms much more closely than in a vector space.
      The only difference is the fact that there is one element without a multiplicative inverse; namely, the zero element.
    </p>

    <p>
      While it is possible to study linear algebra over <em>finite fields</em> (like the integers modulo a prime number)
      we will only consider two fields: the real numbers <m>\R</m>, and the complex numbers <m>\C</m>.
    </p>

    <p>
      A vector space whose scalars are complex numbers will be called a <em>complex vector space</em>.
      While many students are initially intimidated by the complex numbers,
      most results in linear algebra work exactly the same over <m>\C</m> as they do over <m>\R</m>.
      And where the results differ, things are usually <em>easier</em> with complex numbers,
      owing in part to the fact that all complex polynomials can be completely factored.
    </p>

    <p>
      To help us gain familiarity with the abstract nature of <xref ref="def-vector-space"/>,
      let us consider some basic examples.
    </p>

    <example xml:id="ex-vector-spaces">
      <statement>
        <p>
          The following are examples of vector spaces. We leave verification of axioms as an exercise.
          (Verification will follow a process very similar to the discussion at the beginning of this section.)
          <ol>
            <li>
              <p>
                The set <m>\R^n</m> of <m>n</m>-tuples <m>(x_1,x_2,\ldots, x_n)</m> of real numbers,
                where we define
                <md>
                  <mrow>(x_1,x_2,\ldots, x_n)+(y_1,y_2,\ldots, y_n) \amp = (x_1+y_1,x_2+y_2,\ldots, x_n+y_n) </mrow>
                  <mrow> c(x_1,x_2,\ldots, x_n)\amp = (cx_1,cx_2,\ldots, cx_n)</mrow>
                </md>.
                We will also often use <m>\R^n</m> to refer to the vector space of <m>1\times n</m> column matrices <m>\bbm x_1\\x_2\\\vdots\\x_n\ebm</m>,
                where addition and scalar multiplication are defined as for matrices
                (and the same as the above, with the only difference being the way in which we choose to write our vectors).
                If the distinction between <m>n</m>-tuples and column matrices is ever important, it will be made clear.
              </p>
            </li>

            <li>
              <p>
                The set <m>\mathbf{M}_{mn}</m> of <m>m\times n</m> matrices, equipped with the usual matrix addition and scalar multiplication.
              </p>
            </li>

            <li>
              <p>
                The set <m>\mathbf{P}_n</m> of all polynomials
                <me>
                  p(x) = a_0+a_1x+\cdots + a_nx^n
                </me>
                of degree less than or equal to <m>n</m>, where, for
                <md>
                  <mrow>p(x) \amp = a_0+a_1x+\cdots + a_nx^n </mrow>
                  <mrow>q(x) \amp = b_0+b_1x+\cdots +b_nx^n</mrow>
                </md>
                we define
                <me>
                  p(x)+q(x)=(a_0+b_0)+(a_1+b_1)x+\cdots + (a_n+b_n)x^n
                </me>
                and
                <me>
                  cp(x) = ca_0+(ca_1)x+\cdots + (ca_n)x^n
                </me>.
                The zero vector is the polynomial <m>0=0+0x+\cdots + 0x^n</m>.
              </p>

              <p>
                Notice that although this feels like a very different example,
                the vector space <m>\mathbf{P}_n</m> is in fact very similar to <m>\R^n</m>
                (or rather, <m>\R^{n+1}</m>, to be precise).
                If we associate the polynomial <m>a_0+a_1x+\cdots + a_nx^n</m>
                with the vector <m>\langle a_0,a_1,\ldots, a_n\rangle</m>,
                the addition and scalar multiplication for either space behaves in exactly the same way.
                We will make this observation precise in <xref ref="sec-isomorphism"/>.
              </p>
            </li>

            <li>
              <p>
                The set <m>\mathbf{P}</m> of all polynomials of <em>any</em> degree.
                The algebra works the same as it does in <m>\mathbf{P}_n</m>,
                but there is an important difference:
                in both <m>\mathbf{P}_n</m> and <m>\R^n</m>,
                every element in the set can be generated by setting values for a finite collection of coefficients.
                (In <m>\mathbf{P}_n</m>, every polynomial <m>a_0+a_1x+\cdots =a_nx^n</m>
                can be obtained by choosing values for the <m>n+1</m> coefficients <m>a_0,a_1\ldots, a_n</m>.)
                But if we remove the restriction on the degree of our polynomials,
                there is then no limit on the number of coefficients we might need.
                (Even if any <em>individual</em> polynomial has a finite number of coefficients!)
              </p>
            </li>

            <li>
              <p>
                The set <m>\mathbf{F}[a,b]</m> of all functions <m>f:[a,b]\to \R</m>,
                where we define <m>(f+g)(x)=f(x)+g(x)</m> and <m>(cf)(x)=c(f(x))</m>.
                The zero function is the function satisfying <m>0(x)=0</m> for all <m>x\in [a,b]</m>,
                and the negative of a function <m>f</m> is given by <m>(-f)(x)=-f(x)</m> for all <m>x\in [a,b]</m>.
              </p>

              <p>
                Note that while the vector space <m>\mathbf{P}</m> has an infinite nature that <m>\mathbf{P}_n</m> does not,
                the vector space <m>\mathbf{F}[a,b]</m> is somehow <em>more</em> infinite!
                Using the language of <xref ref="sec-dimension"/>, we can say that <m>\mathbf{P}_n</m> is <term>finite dimensional</term>,
                while <m>\mathbf{P}</m> and <m>\mathbf{F}[a,b]</m> are <term>infinite dimensional</term>.
                In a more advanced course, one might make a further distinction:
                the dimension of <m>\mathbf{P}</m> is countably infinite,
                while the dimension of <m>\mathbf{F}[a,b]</m> is <term>uncountable</term>.
              </p>
            </li>
          </ol>
        </p>
      </statement>
    </example>

    <p>
      Other common examples of vector spaces can be found online;
      for example, <url href="https://en.wikipedia.org/wiki/Examples_of_vector_spaces" visual="en.wikipedia.org/wiki/Examples_of_vector_spaces">on Wikipedia</url>.
      It is also interesting to try to think of less common examples.
    </p>

    <exercise>
      <introduction>
        Can you think of a way to define a vector space structure on the set
        <m>(0,\infty)</m> of all positive real numbers?
      </introduction>
      <task>
        <statement>
          <p>
            How should we define addition and scalar multiplication?
          </p>
        </statement>
        <hint>
          <p>
            Note that the function <m>f(x)=e^x</m> has domain <m>(-\infty, \infty)</m>
            and range <m>(0,\infty)</m>. What does it do to a sum? To a product?
          </p>
        </hint>
        <solution>
          <p>
            To get a vector space structure on <m>V=(0,\infty)</m>,
            we will define an addition <m>\oplus</m> on <m>V</m> by
            <me>
              x\oplus y = xy
            </me>,
            where the right hand side is the usual product of real numbers,
            and for <m>c\in\R</m> and <m>x\in V</m>, we will define a scalar multiplication <m>\odot</m> by
            <me>
              c\odot x = x^c
            </me>.
          </p>
        </solution>
      </task>
      <task>
        <statement>
          <p>
            Show that the addition you defined satisfies the commutative and associative properties.
          </p>
        </statement>
        <hint>
          <p>
            You can assume that these properties are true for real number multiplication.
          </p>
        </hint>
        <solution>
          <p>
            For any <m>x,y,z\in V</m>, we have:
            <md>
              <mrow>x\oplus y \amp = xy = yx = y\oplus x</mrow>
              <mrow>x\oplus(y\oplus z)\amp = x\oplus yz = x(yz) = (xy)z = xy\oplus z = (x\oplus y)\oplus z</mrow>
            </md>.
          </p>
        </solution>
      </task>
      <task>
        <statement>
          <p>
            Which of the following is the identity element in <m>V</m>?
          </p>
        </statement>
        <choices>
          <choice>
            <statement>
              <p>
                <m>0</m>
              </p>
            </statement>
            <feedback>
              <p>
                Remember that the identity needs to be an element of the set!
              </p>
            </feedback>
          </choice>
          <choice correct="yes">
            <statement>
              <p>
                <m>1</m>
              </p>
            </statement>
            <feedback>
              <p>
                Correct! Since nothing happens when we multiply by 1, we get <m>1\oplus x=x</m> for any <m>x\in V</m>.
              </p>
            </feedback>
          </choice>
        </choices>
        <hint>
          <p>
            Remember that an identity element <m>e</m> must satisfy <m>e\oplus x</m> for any <m>x\in V</m>.
          </p>
        </hint>
      </task>
      <task>
        <statement>
          <p>
            What is the inverse of an element <m>x\in V</m>?
          </p>
        </statement>
        <hint>
          <p>
            Remember that an inverse <m>-x</m> must satisfy <m>x\oplus (-x)=e</m>,
            where <m>e</m> is the identity element. What is <m>e</m>, and how is <q>addition</q> defined?
          </p>
        </hint>
        <solution>
          <p>
            Let <m>x</m> be any element fo <m>V</m>. Since <m>x\gt 0</m>,
            we know in particular that <m>x\neq 0</m>, so we can define <m>-x = 1/x</m>,
            where <m>1/x</m> denotes the usual reciprocal of a real number.
            We then have
            <me>
              x\oplus (-x) = x(1/x) = 1
            </me>,
            and we saw above that <m>1</m> is the identity element of <m>e</m>.
          </p>
        </solution>
      </task>
      <task>
        <statement>
          <p>
            Show that, for any <m>c\in \R</m> and <m>x,y\in V</m>,
            <me>
              c\odot(x\oplus y) = c\odot x\oplus c\odot y
            </me>.
          </p>
        </statement>
        <solution>
          <p>
            We assume some properties of exponents from high school algebra:
            <me>
              c\odot(x\oplus y) = (xy)^c = x^c y^c = c\odot x \oplus c\odot y
            </me>.
          </p>
        </solution>
      </task>
      <task>
        <statement>
          <p>
            Show that for any <m>c,d\in \R</m> and <m>x\in V</m>,
            <me>
              (c+d)\odot x = c\odot x\oplus d\odot x
            </me>.
          </p>
        </statement>
        <solution>
          <p>
            This again follows from properties of exponents:
            <me>
              (c+d)\odot x = x^{c+d} = x^c x^d = c\odot x\oplus d\odot x
            </me>.
          </p>
        </solution>
      </task>
      <task>
        <statement>
          <p>
            Show that for any <m>c,d\in\R</m> and <m>x\in V</m>, <m>c\odot (d\odot x)=(cd)\odot x</m>.
          </p>
        </statement>
        <solution>
          <p>
            We have
            <me>
              c\odot (d\odot x) = c\odot (x^d) = (x^d)^c = x^{dc} = x^{cd} = (cd)\odot x
            </me>.
          </p>
        </solution>
      </task>
      <task>
        <statement>
          <p>
            Show that <m>1\odot x=x</m> for any <m>x\in V</m>.
          </p>
        </statement>
        <solution>
          <p>
            The last one is possibly the easiest: <m>1\odot x = x^1 = x</m>.
          </p>
        </solution>
      </task>
    </exercise>

    <exercise>
      <statement correct="yes">
        <p>
          The set of all polynomials with real number coefficients and degree less than or equal to three is a vector space,
          using the usual polynomial addition and scalar multiplication.
        </p>
      </statement>
      <feedback>
        <p>
          This is the vector space <m>\mathbf{P}_3</m> from <xref ref="ex-vector-spaces"/>.
        </p>
    </exercise>

    <exercise>
      <statement correct="no">
        <p>
          The set of all polynomials with real number coefficients and degree greater than or equal to three,
          together with the zero polynomial, is a vector space, using the usual polynomial addition and scalar multiplication.
        </p>
      </statement>
      <feedback>
        <p>
          The set is not closed under addition. What happens if you add the polynomials
          <m>x^3+x</m> and <m>-x^3+x</m>?
        </p>
      </feedback>
      <hint>
        <p>
          Remember that a vector space must be closed under the operations of addition and scalar multiplication.
        </p>
      </hint>
    </exercise>

    <exercise>
      <statement correct="no">
        <p>
          The set of all vectors <m>\vv = \langle a, b\rangle</m> of unit length
          (that is, such that <m>\sqrt{a^2+b^2}=1</m>) is a vector space
          with respect to the usual addition and scalar multiplication in <m>\R^2</m>.
        </p>
      </statement>
      <feedback>
        <p>
          The zero vector does not have unit length.
          Also, the sum of two unit vectors will usually not be a unit vector.
        </p>
      </feedback>
      <solution>
        <p>

        </p>
      </solution>
    </exercise>
  </subsection>

  <subsection xml:id="subsec-vsp-properties">
    <title>Properties</title>

    <p>
      There are a number of other algebraic properties that are common to all vector spaces;
      for example, it is true that <m>0\vv = \zer</m> for all vectors <m>\vv</m> in any vector space <m>V</m>.
      The reason these are not included is that the ten axioms in <xref ref="def-vector-space"/>
      are the ones deemed <q>essential</q> <ndash /> all other properties can be deduced from the axioms.
      To demonstrate, we next give the proof that <m>0\vv = \zer</m>.
    </p>

    <p>
      The focus on proofs may be one place where your second course in linear algebra differs from your first.
      Learning to write proofs (and to know when a proof you have written is valid)
      is a difficult skill that takes time to develop.
      Some of the proofs in this section are <q>clever</q>,
      in the sense that they require you to apply vector space axioms in ways that may not seem obvious.
      Proofs in later sections will more often be more straightforward <q>direct</q> proofs of conditional (if <ellipsis/> then) statements,
      although they may not feel straightforward on your first encounter.
    </p>

    <theorem xml:id="thm-zero-mult">
      <statement>
        <p>
          In any vector space <m>V</m>, we have <m>0\vv = \zer</m> for all <m>\vv\in V</m>
        </p>
      </statement>
      <proof>
        <title>Strategy</title>
        <p>
          The goal is to show that multiplying by the scalar <m>0</m> produces the vector <m>\zer</m>.
          We all learn early on that <q>anything times zero is zero</q>, but why is this true?
          A few strategies that show up frequently when working with the axioms are:
          <ol>
            <li>
              <p>
                Adding zero (the scalar, or the vector) does nothing, including when you add it to itself.
              </p>
            </li>
            <li>
              <p>
                We can always add the same thing to both sides of an equation.
              </p>
            </li>
            <li>
              <p>
                Liberal use of the distributive property!
              </p>
            </li>
          </ol>
        </p>

        <p>
          What we do here is to start with a very simple statement: <m>0+0=0</m>.
          The reason for doing so is that when we multiply by <m>0+0</m>,
          we have an opportunity to use the distributive property.
        </p>
      </proof>

      <proof>
        <title>Execution</title>
        <p>
          Since <m>0+0=0</m>, we have <m>0\vv=(0+0)\vv</m>.
          Using the distributive axiom S3, this becomes
          <me>
            0\vv + 0\vv = 0\vv
          </me>.
           By axiom A5, there is an element <m>-0\vv\in V</m> such that <m>0\vv+(-0\vv)=\zer</m>.
           Adding this to both sides of the equation above, we get:
           <me>
             (0\vv+0\vv)+(-0\vv) = 0\vv+(-0\vv)
           </me>.
           Now, apply the associative property (A3) on the left, and A5 on the right, to get
           <me>
             0\vv + (0\vv+(-0\vv)) = \zer
           </me>.
           Using A5 again on the left, we get <m>0\vv+\zer = \zer</m>.
           Finally, axiom A4 guarantees <m>0\vv = 0\vv+\zer = \zer</m>.
        </p>
      </proof>

    </theorem>

    <exercise xml:id="ex-more-props">
      <introduction>
        <p>
          Tactics similar to the ones used in <xref ref="thm-zero-mult"/> can be used to establish the following results,
          which we leave as an exercise.
          Solutions are included, but it will be worth your while in the long run to wrestle with these.
        </p>
        <p>
          Show that the following properties are valid in any vector space <m>V</m>:
        </p>
      </introduction>
      <task>
        <statement>
          <p>
            If <m>\uu+\vv=\uu+\ww</m>, then <m>\vv=\ww</m>.
          </p>
        </statement>
        <hint>
          <p>
            Remember that every vector <m>\uu</m> in a vector space has an additive inverse <m>-\uu</m>.
          </p>
        </hint>
        <solution>
          <p>
            Suppose <m>\uu+\vv=\uu+\ww</m>. By adding <m>-\uu</m> on the left of each side, we obtain:
            <md>
              <mrow>-\uu+(\uu+\vv) \amp =-\uu+(\uu+\ww)</mrow>
              <mrow>(-\uu+\uu)+\vv \amp =(-\uu+\uu)+\ww \quad \text{ by A3}</mrow>
              <mrow> \zer+\vv \amp =\zer+\ww \quad \text{ by A5}</mrow>
              <mrow> \vv \amp =\ww \quad \text{ by A4}</mrow>
            </md>,
            which is what we needed to show.
          </p>
        </solution>
      </task>

      <task>
        <statement>
          <p>
            For any scalar <m>c</m>, <m>c\zer=\zer</m>.
          </p>
        </statement>
        <hint>
          <p>
            Your approach should be quite similar to the one used in <xref ref="thm-zero-mult"/>.
          </p>
        </hint>
        <solution>
          <p>
            We have <m>c\zer = c(\zer+\zer) = c\zer +c\zer</m>, by A4 and S2, respectively.
            Adding <m>-c\zer</m> to both sides gives us
            <me>
              -c\zer+c\zer = -c\zer+(c\zer+c\zer)
            </me>.
            Using associativity (A3), this becomes
            <me>
              -c\zer+c\zer = (-c\zer+c\zer)+c\zer
            </me>,
            and since <m>-c\zer+c\zer=\zer</m> by A5, we get <m>\zer =\zer+c\zer</m>.
            Finally, we apply A4 on the right hand side to get <m>\zer=c\zer</m>,
            as required.
          </p>
        </solution>
      </task>

      <task>
        <statement>
          <p>
            If <m>c\vv=\zer</m>, then either <m>c=0</m> or <m>\vv=\zer</m>.
          </p>
        </statement>
        <hint>
          <p>
            Consider a proof by cases: either <m>c=0</m> or <m>c\neq 0</m>.
            In the first case, there is nothing to prove (why?).
            In the second case, use the fact (see <xref ref="def-field"/>) that for any nonzero scalar <m>c</m>,
            there exists a scalar <m>1/c</m> such that <m>c\cdot 1/c=1</m>.
          </p>
        </hint>
        <solution>
          <p>
            The main difficulty with this problem is getting the logic of the statement correct,
            and making sure you know what it is you're trying to prove.
            The desired conclusion is an <em>or</em> statement, which means it suffices to establish one part or the other.
            Typically, the way to proceed in these cases is to argue that if the first part is false,
            then the second must be true. This is how we proceed here.
          </p>

          <p>
            Suppose that <m>c\vv=\zer</m>. If <m>c=0</m>,
            then it's true that <m>c=0</m> or <m>\vv=\zer</m>,
            so there's nothing to prove.
            Suppose then that <m>c\neq 0</m>. Then there exists a real number <m>\frac1c</m> such that <m>c\bigl(\frac1c\bigr)=1</m>.
            Multiplying both sides of <m>c\vv=\zer</m> by <m>\frac1c</m>, we get
            <me>
              \frac1c(c\vv)=\frac1c\zer
            </me>.
            By the previous problem, we know that <m>\frac1c\zer = \zer</m>,
            and by axioms S4 and S5, we have
            <me>
              \frac1c(c\vv)=\bigl(\frac1c\cdot c\bigr)\vv = 1\vv = \vv
            </me>,
            showing that <m>\vv=\zer</m>, and thus <m>c=0</m> or <m>\vv=\zer</m>.
            (This is a proof by cases, relying on the tautology <m>c=0</m> or <m>c\neq 0</m>.)
          </p>
        </solution>
      </task>

      <task>
        <statement>
          <p>
            The zero vector is the unique vector such that <m>\vv+\zer=\vv</m> for all <m>\vv\in V</m>.
          </p>
        </statement>
        <hint>
          <p>
            If you want to prove something is unique, try assuming that you have more than one!
            If any two different elements with the same property have to be equal,
            then all such elements must, in fact, be the same element.
          </p>
        </hint>
        <solution>
          <p>
            Suppose there are two vectors <m>\zer_1,\zer_2</m> that act as additive identities.
            Then
            <md>
              <mrow>\zer_1 \amp = \zer_1+\zer_2 \quad \text{ since } \vv+\zer_2=\vv \text{ for any } \vv</mrow>
              <mrow>  \amp =\zer_2+\zer_1 \quad \text{ by axiom A2}</mrow>
              <mrow>  \amp \zer_2 \quad \text{ since } \vv+\zer_1=\vv \text{ for any } \vv</mrow>
            </md>
            So any two vectors satisfying the property in A4 must, in fact, be the same.
          </p>
        </solution>
      </task>

      <task>
        <statement>
          <p>
            The negative <m>-\vv</m> of any vector <m>\vv</m> is unique.
          </p>
        </statement>
        <solution>
          <p>
            Let <m>\vv\in V</m>, and suppose there are vectors <m>\ww_1,\ww_2\in V</m>
            such that <m>\vv+\ww_1=\zer</m> and <m>\vv+\ww_2=\zer</m>. Then
            <md>
              <mrow>\ww_1 \amp = \ww_1+\zer \quad  \text{ by A4}</mrow>
              <mrow> \amp = \ww_1+(\vv+\ww_2) \quad \text{ by assumption}</mrow>
              <mrow> \amp = (\ww_1+\vv)+\ww_2 \quad \text{ by A3}</mrow>
              <mrow> \amp = (\vv+\ww_1)+\ww_2 \quad \text{ by A2}</mrow>
              <mrow> \amp = \zer+\ww_2 \quad \text{ by assumption}</mrow>
              <mrow> \amp \ww_2 \quad \text{ by A4}</mrow>
            </md>.
          </p>
        </solution>
      </task>
    </exercise>

    <exercise>
      <statement>
        <p>
          By rearranging the blocks below, create a proof of the statement
          <q>Let <m>V</m> be a vector space. For any <m>\vv\in V</m>, <m>(-1)\vv=-\vv</m>.</q>
          Note that it's possible that not all blocks will be needed.
        </p>
      </statement>
      <blocks>
        <block order="6">
          <p>
            Let <m>\vv</m> be any vector in <m>V</m>.
          </p>
        </block>
        <block order="3">
          <p>
            Since <m>-1+1=0</m>, <m>(-1+1)\vv=0\vv</m>.
          </p>
        </block>
        <block order="9">
          <p>
            From <xref ref="ex-more-props"/> we know <m>0\vv=\zer</m>,
            and by axiom S3, <m>(-1+1)\vv=-1\vv+1\vv</m>.
          </p>
        </block>
        <block order="2">
          <p>
            By axiom S5, <m>1\vv=\vv</m>.
          </p>
        </block>
        <block order="1">
          <p>
            Therefore, we have <m>-1\vv+\vv=\zer</m>.
          </p>
        </block>
        <block order="7">
          <p>
            Adding <m>-\vv</m> to both sides, we get
            <me>
              (-1\vv+\vv)+(-\vv)=\zer+(-\vv)
            </me>.
          </p>
        </block>
        <block order="5">
          <p>
            Using A3 and A4, this becomes <m>-1\vv+(\vv+(-vv))=-\vv</m>.
          </p>
        </block>
        <block order="8">
          <p>
            By A5, we then have <m>-1\vv+\zer=-\vv</m>.
          </p>
        </block>
        <block order="4">
          <p>
            Finally, by A4, we get <m>-1\vv=-\vv</m>.
          </p>
        </block>
      </blocks>
    </exercise>

    <p>
      Note that in the above exercise, we could have shortened the proof:
      In <xref ref="ex-more-props"/> we showed that additive inverses are unique.
      So once we reach the step where <m>-1\vv+\vv=\zer</m>,
      we can conclude that <m>-1\vv=-\vv</m>,
      since <m>-\vv</m> is the unique vector that satisfies this equation.
    </p>
  </subsection>
</section>
