<?xml version="1.0" encoding="UTF-8" ?>

<section xml:id="project-dynamical">
  <title>Project: linear dynamical systems</title>
  <introduction>
    <p>
      Suppose we have a sequence <m>(x_n)</m> defined by a linear recurrence of length <m>k</m>,
      as in <xref ref="project-recurrence"/>:
      <me>
        x_{n+k} = a_0x_k + a_1x_{k+1}+\cdots + a_{k-1}x_{n-k+1}
      </me>.
    </p>

    <p>
      We would like to represent this as a matrix equation,
      and then use eigenvalues to analyze,
      replacing the recurrence formula with a matrix equation of the form <m>\vv_{k+1}=A\vv_k</m>.
      A sequence of vectors generated in this way is called a <term>linear dynamical system</term>.
      It is a good model for systems with discrete time evolution (where changes occur in steps, rather than continuously).
    </p>

    <p>
      To determine the long term evolution of the system, we would like to be able to compute
      <me>
        \vv_n  = A^n \vv_0
      </me>
      without first finding all the intermediate states,
      so this is a situation where we would like to be able to efficiently compute powers of a matrix.
      Fortunately, we know how to do this when <m>A</m> is diagonalizable:
      <m>A^n = PD^nP^{-1}</m>, where <m>D</m> is a diagonal matrix whose entries are the eigenvalues of <m>A</m>,
      and <m>P</m> is the matrix of corresponding eigenvectors of <m>A</m>.
    </p>
  </introduction>

  <exercise label="ex-dynamical-recurrence-2">
    <introduction>
      <p>
        Consider a recurrence of length 2, of the form
        <me>
          x_{k+2} = ax_k+bx_{k+1}
        </me>.
      </p>
    </introduction>

    <task label="ex-dynamical-recurrence-2a">
      <statement>
        <p>
          According to <xref ref="project-recurrence"/>, what is the polynomial associated to this recurrence?
        </p>
      </statement>
      <solution>
        <p>
          The polynomial is given by <m>p(x)=x^2-bx-a</m>.
        </p>
      </solution>
    </task>

    <task label="ex-dynamical-recurrence-2b">
      <statement>
        <p>
          Let <m>\vv_k = \begin{bmatrix}x_k\\ x_{k+1}\end{bmatrix}</m>, for each <m>k\geq 0</m>,
          and let <m>A=\begin{bmatrix}0\amp 1\\ a \amp b\end{bmatrix}</m>. Show that
          <me>
            \vv_{k+1}=A\vv_k, \text{ for each } k\geq 0
          </me>.
        </p>
      </statement>
      <solution>
        <p>
          Computing the right-hand side, we find
          <me>
            A\vv_k = \bbm 0\amp 1\\ a\amp b\ebm\bbm x_k\\ x_{k+1}\ebm = \bbm x_{k+1}\\ ax_k + bx_{k+1}\ebm = \bbm x_{k+1}\\ x_{k+2}\ebm = \vv_{k+1}
          </me>,
          since <m>ax_k+bx_{k+1} = x_{k+2}</m>.
        </p>
      </solution>
    </task>

    <task label="ex-dynamical-recurrence-2c">
      <statement>
        <p>
          Compute the characteristic polynomial of <m>A</m>. What do you observe?
        </p>
      </statement>
      <solution>
        <p>
          We find
          <me>
            c_A(x) = \det\bbm x\amp -1 \\ -a \amp x-b\ebm = x^2-bx-a
          </me>.
          This is the same as the polynomial found in part (a).
        </p>
      </solution>
    </task>
  </exercise>

  <exercise label="ex-dynamical-recurrence-3">
    <introduction>
      <p>
        For a recurrence of length 3, given by
        <me>
          x_{k+3} = ax_k+bx_{k+1}+cx_{k+2}
        </me>:
      </p>
    </introduction>

    <task label="ex-dynamical-recurrence-3a">
      <statement>
        <p>
          Determine a matrix <m>A</m> such that <m>\vv_{k+1}=A\vv_k</m>,
          where <m>\vv_k = \begin{bmatrix}x_k\\x_{k+1}\\x_{k+2}\end{bmatrix}</m>.
        </p>
      </statement>
      <solution>
        <p>
          We want <m>A\bbm x_k\\ x_{k+1}\\ x_{k+2}\ebm = \bbm x_{k+1}\\ x_{k+2}\\ x_{k+3}\ebm</m>,
          where <m>x_{k+3} = ax_k + bx_{k+1} + cx_{k+2}</m>.
        </p>

        <p>
          This suggests that we take <m>A = \bbm 0 \amp 1\amp 0\\ 0\amp 0\amp 1\\ a\amp b\amp c\ebm</m>.
        </p>
      </solution>
    </task>

    <task label="ex-dynamical-recurrence-3b">
      <statement>
        <p>
          Compute the characteristic polynomial of <m>A</m>,
          and compare it to the associated polynomial of the recurrence.
        </p>
      </statement>
      <solution>
        <p>
          We find
          <md>
            <mrow>c_A(x) \amp = \det\bbm x \amp -1\amp 0\\ 0\amp x\amp -1\\ -a\amp -b\amp x-c\ebm</mrow>
            <mrow> \amp = x\bvm x\amp -1\\ -b\amp x-c\evm + 1\bvm 0\amp -1\\-a\amp x-c\evm</mrow>
            <mrow> \amp x(x^2-cx-b) - a = x^3-cx^2-ba-a</mrow>
          </md>.
          This is the same as the associated polynomial of the linear recurrence.
        </p>
      </solution>
    </task>

    <task label="ex-dynamical-recurrence-3c">
      <statement>
        <p>
          Show that if <m>\lambda</m> is an eigenvalue of <m>A</m>,
          then <m>\xx = \begin{bmatrix}1\\ \lambda\\ \lambda^2\end{bmatrix}</m> is an associated eigenvector.
        </p>
      </statement>
      <solution>
        <p>
          By direct computation, we find
          <me>
            A\xx = \bbm 0 \amp 1\amp 0\\ 0\amp 0\amp 1\\ a\amp b\amp c\ebm\bbm 1\\ \lambda\\ \lambda^2\ebm = \bbm \lambda\\ \lambda^2\\ a+b\lambda+c\lambda^2\ebm
          </me>.
          But <m>\lambda</m> is an eigenvalue of <m>A</m>, so <m>c_A(\lambda) = \lambda^3-c\lambda^2-b\lambda -a = 0</m>.
          Therefore, <m>a+b\lambda+c\lambda^2=\lambda^3</m>, and <m>A\xx = \bbm \lambda\\ \lambda^2\\ \lambda^3\ebm = \lambda\xx</m>.
        </p>
      </solution>
    </task>
  </exercise>

  <exercise label="ex-dynamical-fibonacci">
    <introduction>
      <p>
        Consider the Fibonacci sequence, defined by <m>x_0=1, x_1=1</m>,
        and <m>x_{k+2}=x_k+x_{k+1}</m>. Let <m>A</m> be the matrix associated to this sequence.
      </p>
    </introduction>

    <task label="ex-dynamical-fibonacci-a">
      <statement>
        <p>
          State the matrix <m>A</m>, and show that <m>A</m> has eigenvalues <m>\lambda_\pm = \frac{1}{2}(1\pm \sqrt{5})</m>,
          with associated eigenvectors <m>\xx_\pm = \begin{bmatrix}1\\ \lambda_\pm\end{bmatrix}</m>.
        </p>
      </statement>
      <solution>
        <p>
          We use the matrix from question 1(b), with <m>a=b=1</m>, giving <m>A = \bbm 0\amp 1\\ 1\amp 1\ebm</m>.
          The characteristic polynomial is <m>c_A(x) = x^2-x-1</m> (the same as the associated polynomial of the recurrence),
          and by the quadratic formula, <m>c_A(x)=0</m> if
          <me>
            x = \dfrac{-(-1)\pm\sqrt{1^2-4(1)(-1)}}{2(1)} = \dfrac{1\pm\sqrt{5}}{2}
          </me>.          
        </p>

        <p>
          We can then check that
          <me>
            A\xx_+ = \bbm 0\amp 1\\1\amp 1\ebm\bbm 1\\ \lambda_+\ebm = \bbm \lambda_+\\1+\lambda_+\ebm
          </me>,
          and
          <me>
            \lambda_+^2 = \frac14 + \frac{\sqrt{5}}{2} + \frac54 = \frac32+\frac{\sqrt{5}}{2} = 1+\lambda_+
          </me>,
          so that <m>A\xx_+ = \bbm \lambda_+\\ \lambda_+^2\ebm = \lambda_+\xx_+</m>.
        </p>

        <p>
          A similar calculation shows that <m>A\xx_- = \lambda_-\xx_-</m>.
        </p>
      </solution>
    </task>

    <task xml:id="part-dynamical"  label="ex-dynamical-fibonacci-b">
      <statement>
        <p>
          Let <m>P = \begin{bmatrix}1\amp 1\\ \lambda_+ \amp \lambda_-\end{bmatrix}</m>,
          let <m>D = \begin{bmatrix}\lambda_+ \amp 0\\ 0 \amp \lambda_-\end{bmatrix}</m>,
          and let <m>\mathbf{a_0}=\begin{bmatrix}a_0\\a_1\end{bmatrix}=P^{-1}\vv_0</m>,
          where <m>\vv_0=\begin{bmatrix}1\\1\end{bmatrix}</m> gives the initial values of the sequence.
        </p>

        <p>
          Show that
          <md>
            <mrow>\vv_n \amp = PD^nP^{-1}\vv_0</mrow>
            <mrow> \amp = a_0\lambda_+^n\xx_+ + a_1\lambda_-^n\xx_-</mrow>
          </md>.
        </p>
      </statement>
      <solution>
        <p>
          Letting <m>P^{-1}\vv_0 = \bbm a_0\\ a_1\ebm</m>, we have
          <md>
            <mrow>PD^nP^{-1}\vv_0 \amp = \bbm 1\amp 1\\ \lambda_+\amp \lambda_-\ebm\bbm \lambda_+^n\amp 0\\ 0\amp \lambda_-^n\ebm\bbm a_0\\a_1\ebm</mrow>
            <mrow> \amp = \bbm 1\amp 1\\ \lambda_+\amp \lambda_-\ebm\bbm a_0\lambda_+^n\\ a_1\lambda_-^n\ebm</mrow>
            <mrow> \amp = \bbm a_0\lambda_+^n + a_1\lambda_-^n\\ a_0\lambda_+^{n+1}+a_1\lambda_-^{n+1}</mrow>
            <mrow> \amp = a_0\lambda_+^n\xx_+ + a_1 \lambda_-^n\xx_-</mrow>
          </md>.
          
        </p>
      </solution>
    </task>

    <task label="ex-dynamical-fibonacci-c">
      <statement>
        <p>
          Note that <xref ref="part-dynamical"/> tells us that although the Fibonacci sequence is not a geometric sequence,
          it is the <em>sum</em> of two geometric sequences!
        </p>

        <p>
          By considering the numerical values of the eigenvalues <m>\lambda_+</m> and <m>\lambda_-</m>,
          explain why we can nonetheless treat the Fibonacci sequence as <em>approximately</em> geometric when <m>n</m> is large.
        </p>

        <p>
          (This is true more generally:
          if a matrix <m>A</m> has one eigenvalue that is larger in absolute value than all the others,
          this eigenvalue is called the <term>dominant eigenvalue</term>.
          If <m>A</m> is the matrix of some linear recurrence, and <m>A</m> is diagonalizable,
          then we can consider the sequence as a sum of geometric sequences that will become approximately geometric in the long run.)
        </p>
      </statement>
      <solution>
        <p>
          We find that <m>\lambda_+ \approx 1.618</m>, while <m>\lambda_- \approx -0.618</m>.
          Since <m>\abs{\lambda_+}\gt 1</m>, the value of <m>\lambda_+^n</m> will grow arbitrarily large as <m>n</m> gets large,
          while the value of <m>\lambda_-^n</m> will get closer and closer to 0, since <m>\abs{\lambda_-}\lt 1</m>.
        </p>
      </solution>
    </task>
  </exercise>


  <exercise label="ex-dynamical-predator">
    <title>Predator-Prey Systems</title>
    <introduction>
      <p>
        As a more practical example, consider the following (over-simplified) predator-prey system.
        It is based on an example in <url href="https://personal.math.ubc.ca/~tbjw/ila/dds.html" visual="personal.math.ubc.ca/~tbjw/ila/dds.html">Interactive Linear Algebra</url>,
        by Margalit, Rabinoff, and Williams, but adapted to the wildlife here in Lethbridge.
        An ecosystem contains both coyotes and deer.
        Initially, there is a population of <m>20</m> coyotes, and <m>500</m> deer.
      </p>

      <p>
        We assume the following:
        <ul>
          <li>
            <p>
              the share of the deer population eaten by a typical coyote in a year is <m>10</m> deer
            </p>
          </li>
          <li>
            <p>
              in the absence of the coyotes, the deer population would increase by <m>50</m>% per year
            </p>
          </li>
          <li>
            <p>
              <m>20</m>% of the coyote population dies each year of natural causes
            </p>
          </li>
          <li>
            <p>
              the growth rate of the coyote population depends on the number of deer:
              for each 100 deer, <m>10</m> coyote pups will survive to adulthood.
            </p>
          </li>
        </ul>
      </p>

      <p>
        If we let <m>d_t</m> denote the number of deer after <m>t</m> years,
        and <m>c_t</m> the number of coyotes, then we have
        <md>
          <mrow>d_{t+1} \amp = 1.5d_t - 10c_t</mrow>
          <mrow>c_{t+1} \amp = 0.1d_t + 0.8c_t</mrow>
        </md>,
        or, in matrix form,
        <me>
          \mathbf{p}_{t+1} = A\mathbf{p}_t
        </me>,
        where <m>\mathbf{p}_t=\bbm d_t\\c_t\ebm</m> and <m>A = \bbm 1.5 \amp -10\\0.1 \amp 0.8\ebm</m>.
      </p>

      <p>
        After <m>t</m> years, the two populations will be given by <m>\mathbf{p}_t=A^t\mathbf{p}_0</m>,
        where <m>\mathbf{p}_0=\bbm 500\\20\ebm</m> gives the initial populations of the two species.
        If possible, we would like to be able to find a closed-form formula for <m>\mathbf{p}_t</m>,
        which would allow us to analyze the long-term predictions of our model.
      </p>
    </introduction>

    <task label="ex-dynamical-predator-a">
      <statement>
        <p>
          Analyze the eigenvalues of this matrix, and diagonalize.
          The <c>sympy</c> library won't be up to the task.
          Instead, some combination of <c>numpy</c> and <c>scipy</c>,
          as described by <url href="https://patrickwalls.github.io/mathematicalpython/linear-algebra/eigenvalues-eigenvectors/" visual="patrickwalls.github.io/mathematicalpython/linear-algebra/eigenvalues-eigenvectors/">Patrick Walls on his website</url>,
          will be needed.
        </p>
      </statement>
    </task>

    <task xml:id="part-pred-prey" label="ex-dynamical-predator-b">
      <statement>
        <p>
          The eigenvalues turn out to be complex! What does that tell you about the nature of the system?
          What is the long-term behaviour of this system?
        </p>
      </statement>
      <hint>
        <p>
          Remember that those complex terms can be combined using sine and cosine functions:
          since <m>A</m> is a real matrix, the eigenvalues will have the form
          <me>
            \lambda_\pm = a\pm bi
          </me>,
          where <m>a</m> and <m>b</m> are real. In polar form, <m>\lambda_\pm = re^{\pm i\theta}</m>
          for some <m>r</m> and <m>\theta</m>, and by de Moivre's Theorem,
          <me>
            \lambda_\pm^n = r^n e^{\pm in\theta} = r^n(\cos(n\theta)+i\sin(n\theta))
          </me>.
        </p>
      </hint>
    </task>

    <task label="ex-dynamical-predator-c">
      <statement>
        <p>
          What if you adjust the parameters? Can you come up with a system where both species flourish?
          Or one where they both disappear? Or one where the populations oscillate regularly?
        </p>
      </statement>
      <hint>
        <p>
          Referring to the hint from <xref ref="part-pred-prey"/>,
          note that the size of the populations will depend on the modulus <m>r</m>
          of the eigenvalues.
          For what values of <m>r</m> will the populations decline/increase/remain steady?
        </p>
      </hint>
    </task>

    <task label="ex-dynamical-predator-d">
      <statement>
        <p>
          You may have read this while wondering,
          <q>Does Sean actually know anything about ecology and population dynamics?
          Did he just make up those numbers?</q>
        </p>

        <p>
          The answers are, respectively, no, and yes.
          Can you come up with numbers that are based on a realistic example?
          What does our model predict in that case? Is it accurate?
        </p>
      </statement>
    </task>
  </exercise>
  
  
  <exercise label="ex-dynamical-markov">
    <title>Markov Chains</title>
    <introduction>
      <p>
        A special type of linear dynamical system occurs when the matrix <m>A</m>
        is <term>stochastic</term>.
        A stochastic matrix is one where each entry of the matrix is between <m>0</m> and <m>1</m>,
        and all of the columns of the matrix sum to <m>1</m>.
      </p>

      <p>
        The reason for these conditions is that the entries of a stochastic matrix represent probabilities;
        in particular, they are <term>transition probabilities</term>.
        That is, each number represents the probability of one state changing to another.
      </p>

      <p>
        If a system can be in one of <m>n</m> possible states,
        we represent the system by an <m>n\times 1</m> vector <m>\vv_t</m>,
        whose entries indicate the probability that the system is in a given state at time <m>t</m>.
        If we know that the system starts out in a particular state,
        then <m>\vv_0</m> will have a <m>1</m> in one of its entries, and <m>0</m> everywhere else.
      </p>

      <p>
        A Markov chain is given by such an initial vector, and a stochastic matrix.
        As an example, we will consider the following scenario,
        described in the book <em>Shape</em>, by Jordan Ellenberg:
      </p>

      <p>
        A mosquito is born in a swamp, which we will call Swamp A.
        There is another nearby swamp, called Swamp B.
        Observational data suggests that when a mosquito is at Swamp A,
        there is a 40% chance that it will remain there,
        and a 60% chance that it will move to Swamp B.
        When the mosquito is at Swamp B, there is a 70% chance that it will remain,
        and a 30% chance that it will return to Swamp A.
      </p>
    </introduction>

    <task label="ex-dynamical-markov-a">
      <statement>
        <p>
          Give a stochastic matrix <m>M</m> and a vector <m>\vv_0</m>
          that represent the transition probabilities and initial state given above.
        </p>
      </statement>
      <solution>
        <p>
          The matrix is <m>M = \bbm 0.4\amp 0.3\\0.6\amp 0.7\ebm</m>, and the initial state is <m>\vv_0 = \bbm 1\amp 0\ebm</m>.
        </p>
      </solution>
    </task>

    <task label="ex-dynamical-markov-b">
      <statement>
        <p>
          By diagonalizing the matrix <m>M</m>,
          find a formula for <m>\vv_n = M^n\vv_0</m>. 
          Use this to determine the long-term probability that the mosquito will be found in either swamp.
        </p>
      </statement>
      <solution>
        <p>
          We find 
          <me>
            c_A(x) = \bvm x-0.4 \amp -0.3\\ -0.6 \amp x-0.7\evm = x^2-1.1x+0.1 = (x-1)(x-0.1)
          </me>,
          so the eigenvalues are <m>\lambda_1 = 1</m> and <m>\lambda_2 = 0.1</m>.
        </p>

        <p>
          An eigenvector associated to <m>\lambda_1</m> is <m>\xx_1 = \bbm 1\\2\ebm</m>,
          and an eigenvector associated to <m>\lambda_2</m> is <m>\xx_2 = \bbm 1\\-1\ebm</m>.
          If we let <m>P = \bbm 1\amp 1\\ 2\amp -1\ebm</m>, then we find
          <md>
            <mrow>\vv_n \amp = M^n\vv_0</mrow>
            <mrow> \amp = \bbm 1\amp 1\\ 2\amp -1\ebm\bbm 1\amp 0\\0\amp (0.1)^n\ebm\bbm 1/3\amp 1/3\\ 2/3\amp -1/3\ebm\bbm 1\\ 0\ebm</mrow>
            <mrow> \amp \bbm 1\amp 1\\ 2\amp -1\ebm\bbm 1\amp 0\\0\amp (0.1)^n\ebm\bbm 1/3\\2/3\ebm</mrow>
            <mrow> \amp \bbm 1\amp 1\\ 2\amp -1\ebm\bbm 1/3\\(0.1)^n(2/3)\ebm</mrow>
            <mrow> \amp \bbm 1/3 + 2/3(0.1)^n\\ 2/3-(0.1)^n\ebm</mrow>
          </md>
        </p>

        <p>
          Based on this, we see that as <m>n\to \infty</m>, <m>\vv_n</m> approaches the vector <m>\bbm 1/3\\2/3\ebm</m>.
          So there is a 1 in 3 chance of finding the mosquito in swamp A, and a 2 in 3 chance of finding it in swamp B.
        </p>
      </solution>
    </task>

    <task label="ex-dynamical-markov-c">
      <statement>
        <p>
          You should have found that one of the eigenvalues of <m>M</m> was <m>\lambda=1</m>.
          The corresponding eigenvector <m>\vv</m> satisfies <m>M\vv=\vv</m>.
          When we normalize so that the entires of <m>\vv</m> sum to 1,
          we call <m>\vv</m> a <term>steady-state vector</term>: if our system begins with state <m>\vv</m>,
          it will remain there forever.
        </p>

        <p>
          Confirm that if the eigenvector <m>\vv</m> is rescaled so that its entries sum to 1,
          the resulting values agree with the long-term probabilities found in the previous part.
          (The system tends toward the steady-state solution, even if it begins in another state.)
        </p>
      </statement>
      <solution>
        <p>
          We found that this vector is <m>\vv = \bbm 1\\2\ebm</m>. If we divide by <m>1+2=3</m>,
          we get <m>\bbm 1/3\\2/\3\ebm</m>, which is the same as before.
        </p>
      </solution>
    </task>

  </exercise>

  <exercise label="ex-dynamical-stochastic">
    <title>Properties of stochastic matrices</title>
    <introduction>
      <p>
        A stochastic matrix <m>M</m> is called <term>regular</term>
        some power <m>M^k</m> has all positive entries.
        It is a theorem that every regular stochastic matrix has a unique steady-state vector.
        That is, there is a unique vector <m>\vv</m> whose entries are positive, and sum to 1,
        such that <m>M\vv = \vv</m>.
      </p>
    </introduction>
    
    <task label="ex-dynamical-stochastic-a">
      <statement>
        <p>
          Prove that every stochastic matrix has 1 as an eigenvalue.
          (It is also possible to show that 1 is the dominant eigenvalue, but we will not attempt to do so.)
        </p>
      </statement>
      <hint>
        <p>
          The eigenvalues of <m>M</m> are the same as the eigenvalues of <m>M^T</m>.
          Since the columns of <m>M</m> sum to 1, the rows of <m>M^T</m> sum to 1.
          Does this suggest a possible eigenvector for <m>M^T</m>?
        </p>
      </hint>
      <solution>
        <p>
          Since the rows of <m>M^T</m> sum to 1, if <m>\xx = \bbm 1\\1\\ \vdots \\ 1\ebm</m>,
          we find that <m>M^T\xx = \xx</m>. Therefore, 1 is an eigenvalue of <m>M^T</m>, and therefore of <m>M</m>.
        </p>
      </solution>
    </task>

    <task label="ex-dynamical-stochastic-b">
      <statement>
        <p>
          Prove that if <m>M</m> is a stochastic matrix and <m>\lambda</m> is any eigenvalue of <m>M</m>,
          then <m>\abs{\lambda}\leq 1</m>.
        </p>
      </statement>
      <hint>
        <p>
          Suppose <m>M\xx = \lambda \xx</m> for <m>\lambda\neq 1</m> and  some <m>\xx\neq \mathbf{0}</m>.
          The entries of <m>\xx</m> are not all equal (or <m>\xx</m> is the eigenvector for <m>\lambda =1</m>).
          Let <m>x_j</m> be the <em>largest</em> entry in <m>\xx</m>.
        </p>

        <p>
          Show that <m>\abs{\lambda}\abs{x_j} \leq 1\abs{x_j}</m>.
        </p>

        <p>
          (Note that the <m>j</m>th entry of the eigenvalue equation <m>M\xx = \lambda \xx</m> is <m>\lambda x_j = \sum_{k=1}^n m_{jk}x_k</m>.)
        </p>
      </hint>
      <solution>
        <p>
          Suppose that <m>M\xx = \lambda \xx</m> for some <m>\lambda\neq 1</m> and some <m>\xx\neq \mathbf{0}</m>.
          Let <m>x_j</m> be the largest entry of <m>\xx</m>.
          (We know that the entries of <m>\xx</m> are not all the same, since <m>\lambda\neq 1</m>.)
          Then we have
          <me>
            \abs{\lambda}\abs{x_j} = \abs{\lambda x_j} = \abs{\sum_{k=1}^n m_{jk} x_k} \leq \abs{\sum_{k=1}^n m_{jk}x_j} = \abs{1\cdot x_j}
          </me>.
          Therefore, <m>\abs{\lambda}\leq 1</m>.
        </p>
      </solution>
    </task>

    <task label="ex-dynamical-stochastic-c">
      <statement>
        <p>
          Prove that the product of two <m>2\times 2</m> stochastic matrices is stochastic.
          Conclude that if <m>M</m> is stochastic, so is <m>M^k</m> for each <m>k=1,2,3,\ldots</m>.
        </p>
      </statement>
      <solution>
        <p>
          Let <m>M_i = \bbm a_i\amp b_i\\c_i\amp d_i\ebm</m>, where <m>a_i+c_i=1</m> and <m>b_i+d_i=1</m>, for <m>i=1,2</m>.
          Then
          <md>
            <mrow>M_1M_2  \amp = \bbm a_1\amp b_1\\ c_1\amp d_1\ebm\bbm a_2\amp b_2\\ c_2\amp d_2\ebm</mrow>
            <mrow> \amp = \bbm a_1a_2+b_1c_2 \amp a_1b_2+b_1d_2\\c_1a_2+d_1c_2\amp c_1b_2+d_1d_2\ebm</mrow>
          </md>.
          Now we check:
          <me>
            (a_1a_2+b_1c_2)+(c_1a_2+d_1c_2) = (a_1+c_1)a_2+(b_1+d_1)c_2 = a_2+c_2 = 1
          </me>,
          and
          <me>
            (a_1b_2+b_1d_2)+(c_1b_2+d_1d_2) = (a_1+c_1)b_2+(b_1+d_2)d_2 = b_2+d_1 = 1
          </me>,
          so <m>M_1M_2</m> is stochastic.
        </p>
      </solution>
    </task>

    <task label="ex-dynamical-stochastic-d">
      <statement>
        <p>
          Prove that if <m>M</m> is a regular stochastic matrix,
          then the eigenvector <m>\vv</m> with eigenvalue 1 is unique.
        </p>
      </statement>
      <hint>
        <p>
          You may assume that the entries of <m>M</m> are positive,
          since <m>M\vv = \vv</m> implies <m>M^k\vv = \vv</m> for any <m>k\in\mathbb{N}</m>.
        </p>
        
        <p>
          We know that 1 is an eigenvalue of <m>M^T</m>, with eigenvector <m>\xx= \bbm 1/n\\ 1/n\\\vdots \\ 1/n\ebm</m>
          (rescaled so that its entries sum to 1). We want to that the dimension of the 1-eigenspace of <m>M^T</m> is 1. 
          That is, any <m>\yy</m> whose entries are not all equal cannot satisfy <m>M^T\yy = \yy</m>.
        </p>
        
        <p>
          To show this, let <m>y_i</m> be respectively, the smallest entry in <m>\yy</m>.
          Since the entries of <m>\yy</m> are not all equal, <m>y_i\lt y_k</m> for some <m>k</m>.
        </p>
        <p>
          Show that if <m>M^T\yy = \yy</m>, then you obtain the contradition <m>y_j\gt y_j</m>.
        </p>
      </hint>
      <solution>
        <p>
          Suppose <m>\yy</m> is an eigenvector of <m>M^T</m> corresponding to the eigenvalue 1,
          such that <m>\yy</m> is not a multiple of <m>\vv</m>.
          Then the entries of <m>\yy</m> cannot all be equal. Let <m>y_i</m> be the smallest entry of <m>y_i</m>,
          and note that we must have <m>y_i \lt y_k</m> for some <m>k</m>.
        </p>

        <p>
          If <m>M^T\yy = \yy</m>, then the <m>i</m> entry of this equation is
          <me>
            y_i = \sum_{j=1}^n m_{ji}y_j \gt \sum_{j=i}^n m_{ji}y_i = y_i \sum_{j=1}^n m_{ji} = y_i(1)
          </me>,
          which is a contradiction. Thus, <m>\vv</m> must span the <m>\lambda=1</m> eigenspace.
        </p>        
      </solution>
    </task>

    <task label="ex-dynamical-stochastic-e">
      <statement>
        <p>
          Let <m>M</m> be a regular stochastic matrix.
          Prove that for any initial state <m>\vv_0</m> whose entries sum to 1,
          the Markov chain <m>\vv_n = M^n\vv_0</m> satisfies <m>\lim_{n\to\infty}\vv_n = \vv</m>.
          (You may assume that <m>\vv_0</m> is a linear combination of eigenvectors of <m>M</m>,
          and that <m>\abs{\lambda}\lt 1</m> for each eigenvalue <m>\lambda \neq 1</m>.)
        </p>
      </statement>
      <hint>
        <p>
          We want to show that <m>\lim_{n\to\infty}M^n\vv_0 = \vv</m>, where <m>\vv</m> is the steady-state solution.
        </p>
        <p>
          We are told that we can write <m>\vv_0</m> as a linear combination of eigenvectors.
          To that end, write
          <me>
            \vv_0 = c\vv + a_1\xx_1+\cdots + a_k\xx_k
          </me>,
          and apply <m>M^n</m> to both sides of the equation. Then, use what you know about the size of the eigenvalues.
        </p>
      </hint>
    </task>

    <task label="ex-dynamical-stochastic-f">
      <statement>
        <p>
          Explain why the stochastic matrix <m>M = \bbm 0\amp 1\\1\amp 0\ebm</m> is not regular,
          and why it does not reach a steady-state solution.
        </p>
      </statement>
      <solution>
        <p>
          The eigenvalues of <m>M</m> are <m>\pm 1</m>, and we have <m>M^n = \bbm 1\amp 0\\ 0\amp 1\ebm</m> when <m>M</m> is even,
          while <m>M^n = M</m> when <m>n</m> is odd.
        </p>

        <p>
          For any initial condition <m>\vv_0 = \bbm a\\b\ebm \neq \bbm 0.5\\0.5\ebm</m>,
          we find that <m>M^n\vv_0</m> is either <m>\bbm a\\b\ebm</m> or <m>\bbm b\\a\ebm</m>,
          depending on whether <m>n</m> is even or odd.
        </p>
      </solution>
    </task>
  </exercise>
</section>
