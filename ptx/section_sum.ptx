<?xml version="1.0" encoding="UTF-8" ?>

<section xml:id="sec-subspace-combine">
  <title>New subspaces from old</title>
  <p>
    Let <m>V</m> be a finite-dimensional vector space, and let <m>U,W</m> be subspaces of <m>V</m>.
    In what ways can we combine <m>U</m> and <m>W</m> to obtain new subspaces?
  </p>

  <p>
    At first, we might try set operations: union, intersection, and difference.
    The set difference we can rule out right away: since <m>U</m> and <m>W</m> must both contain the zero vector,
    <m>U\setminus W</m> cannot.
  </p>

  <p>
    What about the union, <m>U\cup W</m>? Before trying to understand this in general,
    let's try a concrete example: take <m>V=\R^2</m>, and let <m>U=\{(x,0)\,|,x\in \R\}</m> (the <m>x</m> axis, essentially),
    and <m>W=\{(0,y)\,|\,y\in\R\}</m> (the <m>y</m> axis). Is their union a subspace?
  </p>

  <exercise>
    <statement correct="no">
      <p>
        The union of the <q><m>x</m> axis</q> and <q><m>y</m> axis</q> in <m>\R^2</m> is a subspace of <m>\R^2</m>.
      </p>
    </statement>
    <feedback>
      <p>
        Any subspace has to be closed under addition.
        If we add the vector <m>(1,0)</m> (which lies along the <m>x</m> axis)
        to the vector <m>(0,1)</m> (which lies along the <m>y</m> axis),
        we get the vector <m>(1,1)</m>, which does not lie along either axis.
      </p>
    </feedback>
  </exercise>

  <p>
    With a motivating example under our belts, we can try to tackle the general result.
    (Note that this result remains true even if <m>V</m> is infinite-dimensional!)
  </p>

  <theorem xml:id="thm-subspace-union">
    <statement>
      <p>
        Let <m>U</m> and <m>W</m> be subspaces of a vector space <m>V</m>.
        Then <m>U\cup W</m> is a subspace of <m>V</m> if and only if <m>U\subseteq W</m> or <m>W\subseteq U</m>.
      </p>
    </statement>
    <proof>
      <title>Strategy</title>
      <p>
        We have an <q>if and only</q> if statement, which means we have to prove two directions:
        <ol>
          <li>
            <p>
              If <m>U\subseteq W</m> or <m>W\subseteq U</m>, then <m>U\cup W</m> is a subspace.
            </p>
          </li>
          <li>
            <p>
              If <m>U\cup W</m> is a subspace, then <m>U\subseteq W</m> or <m>W\subseteq U</m>.
            </p>
          </li>
        </ol>
      </p>

      <p>
        The first direction is the easy one: if <m>U\subseteq W</m>, what can you say about <m>U\cup W</m>?
      </p>
      <p>
        For the other direction, it's not clear how to get started with our hypothesis.
        When a direct proof seems difficult, remember that we can also try proving the contrapositive:
        If <m>U\not\subseteq W</m> and <m>W\not\subseteq U</m>, then <m>U\cup W</m> is not a subspace.
      </p>

      <p>
        Now we have more to work with: negation turns the <q>or</q> into an <q>and</q>,
        and proving that something is not a subspace is easier: we just have to show that one part of the subspace test fails.
        As our motivating example suggests, we should expect closure under addition to be the condition that fails.
      </p>

      <p>
        To get started, we need to answer one more question:
        if <m>U</m> is not a subset of <m>W</m>, what does that tell us?
      </p>

      <p>
        An important point to keep in mind with this proof:
        closure under addition means that if a subspace contains <m>\uu</m> and <m>\ww</m>, then it must contain <m>\uu+\ww</m>.
        But if a subspace contains <m>\uu+\ww</m>, that does <em>not</em> mean it has to contain <m>\uu</m> and <m>\ww</m>.
        As an example, consider the subspace <m>\{(x,x)\,|\,x\in\R\}</m> of <m>\R^2</m>.
        It contains the vector <m>(1,1)=(1,0)+(0,1)</m>, but it does not contain <m>(1,0)</m> or <m>(0,1)</m>.
      </p>
    </proof>
    <proof>
      <p>
        Suppose <m>U\subseteq W</m> or <m>W\subseteq U</m>. In the first case,
        <m>U\cup W=W</m>, and in the second case, <m>U\cup W=U</m>.
        Since both <m>U</m> and <m>W</m> are subspaces, <m>U\cup W</m> is a subspace.
      </p>

      <p>
        Now, suppose that <m>U\not\subseteq W</m>, and <m>W\not\subseteq U</m>.
        Since <m>U\not\subseteq W</m>, there must be some element <m>\uu\in U</m> such that <m>\uu\notin W</m>.
        Since <m>W\not\subseteq U</m>, there must be some element <m>\ww\in W</m> such that <m>\ww\notin U</m>.
        We know that <m>\uu,\ww\in U\cup W</m>, so we consider the sum, <m>\uu+\ww</m>.
      </p>

      <p>
        If <m>\uu+\ww\in U\cup W</m>, then <m>\uu+\ww\in U</m>, or <m>\uu+\ww\in W</m>.
        Suppose <m>\uu+\ww\in U</m>. Since <m>\uu \in U</m> and <m>U</m> is a subspace, <m>-\uu\in U</m>.
        Since <m>-\uu, \uu+\ww\in U</m> and <m>U</m> is a subspace,
        <me>
          -\uu+(\uu+\ww)=(-\uu+\uu)+\ww=\zer+\ww=\ww \in U
        </me>.
        But we assumed that <m>\ww\notin U</m>, so it must be that <m>\uu+\ww\notin U</m>.
      </p>

      <p>
        By a similar argument, if <m>\uu+\ww\in W</m>, we can conclude that <m>\uu\in W</m>,
        contradicting the assumption that <m>\uu\notin W</m>.
        So <m>\uu+\ww</m> does not belong to <m>U</m> or <m>W</m>, so it cannot belong to <m>U\cup W</m>.
        Since <m>U\cup W</m> is not closed under addition, it is not a subspace.
      </p>
    </proof>
  </theorem>

  <p>
    This leaves us with intersection. Will it fail as well?
    Fortunately, the answer is no: this operation actually gives us a subspace.
  </p>

  <theorem xml:id="thm-subspace-intersection">
    <statement>
      <p>
        If <m>U</m> and <m>W</m> are subspaces of a vector space <m>V</m>,
        then <m>U\cap W</m> is a subspace.
      </p>
    </statement>
    <proof>
      <title>Strategy</title>
      <p>
        The key here is that the intersection contains only those vectors that belong to <em>both</em> subspaces.
        So any operation (addition, scalar multiplication) that we do in <m>U\cap W</m>
        can be viewed as taking place in either <m>U</m> or <m>W</m>,
        and we know that these are subspaces. After this observation, the rest is the <xref ref="thm-subspace-test" text="title"/>.
      </p>
    </proof>
    <proof>
      <p>
        Let <m>U</m> and <m>W</m> be subspaces of <m>V</m>.
        Since <m>\zer\in U</m> and <m>\zer \in W</m>, we have <m>\zer\in U\cap W</m>.
        Now, suppose <m>\xx,\yy\in U\cap W</m>.
        Then <m>\xx,\yy\in U</m>, and <m>\xx,\yy\in W</m>.
        Since <m>\xx,\yy\in U</m> and <m>U</m> is a subspace, <m>\xx+\yy\in U</m>.
        Similarly, <m>\xx+\yy\in W</m>, so <m>\xx+\yy\in U\cap W</m>.
        If <m>c</m> is any scalar, then <m>c\xx</m> is in both <m>U</m> and <m>W</m>,
        since both sets are subspaces, and therefore, <m>c\xx\in U\cap W</m>.
        By the <xref ref="thm-subspace-test" text="title"/>, <m>U\cap W</m> is a subspace.
      </p>
    </proof>
  </theorem>


  <p>
    The intersection of two subspaces gives us a subspace,
    but it is a smaller subspace, contained in the two subspaces we're intersecting.
    Given subspaces <m>U</m> and <m>W</m>, is there a way to construct a <em>larger</em> subspace that contains them?
    We know that <m>U\cup W</m> doesn't work, because it isn't closed under addition.
    But what if we started with <m>U\cup W</m>, and threw in all the missing sums? This leads to a definition:
  </p>

  <definition xml:id="def-subspace-sum">
    <statement>
      <p>
        Let <m>U</m> and <m>W</m> be subspaces of a vector space <m>V</m>.
        We define the sum <m>U+W</m> of these subspaces by
        <me>
          U+W = \{\uu+\ww \,|\, \uu\in U \text{ and } \ww\in W\}
        </me>.
      </p>
    </statement>
  </definition>

  <p>
    It turns out that this works! Not only is <m>U+W</m> a subspace of <m>V</m>,
    it is the <em>smallest</em> subspace containing both <m>U</m> and <m>W</m>.
  </p>

  <theorem xml:id="thm-subspace-sum">
    <statement>
      <p>
        Let <m>U</m> and <m>W</m> be subspaces of a vector space <m>V</m>.
        Then the sum <m>U+W</m> is a subspace of <m>V</m>,
        and if <m>X</m> is any subspace of <m>V</m> that contains <m>U</m> and <m>W</m>,
        then <m>U+W\subseteq X</m>.
      </p>
    </statement>
    <proof>
      <title>Strategy</title>
      <p>
        The key to working with <m>U+W</m> is to understand how to work with the definition.
        If we say that <m>\xx\in U+W</m>, then we are saying there exist vectors
        <m>\uu\in U</m> and <m>\ww\in W</m> such that <m>\uu+\ww=\xx</m>.
      </p>

      <p>
        We prove that <m>U+W</m> is a subspace using this observation and the subspace test.
      </p>

      <p>
        To prove the second part, we assume that <m>U\subseteq X</m> and <m>W\subseteq X</m>.
        We then choose an element <m>\xx\in U+W</m>, and using the idea above, show that <m>\xx\in X</m>.
      </p>
    </proof>
    <proof>
      <p>
        Let <m>U,W</m> be subspaces. Since <m>\zer=\zer+\zer</m>, with <m>\zer\in U</m> and <m>\zer \in W</m>,
        we see that <m>\zer\in U+W</m>.
      </p>

      <p>
        Suppose that <m>\xx,\yy\in U+W</m>. Then there exist <m>\uu_1,\uu_2\in U</m>,
        and <m>\ww_1,\ww_2\in W</m>, with <m>\uu_1+\ww_1=\xx</m>, and <m>\uu_2+\ww_2=\yy</m>.
        Then
        <me>
          \xx+\yy = (\uu_1+\ww_1)+(\uu_2+\ww_2)=(\uu_1+\uu_2)+(\ww_1+\ww_2)
        </me>,
        and we know that <m>\uu_1+\uu_2\in U</m>, and <m>\ww_1+\ww_2\in W</m>,
        since <m>U</m> and <m>W</m> are subspaces.
        Since <m>\xx+\yy</m> can be written as the sum of an element of <m>U</m>
        and an element of <m>W</m>, we have <m>\xx+\yy\in U+W</m>.
      </p>

      <p>
        If <m>c</m> is any scalar, then
        <me>
          c\xx=c(\uu_1+\ww_1)=c\uu_1+c\ww_1\in U+W
        </me>,
        since <m>c\uu_1\in U</m> and <m>c\ww_1\in W</m>.
      </p>

      <p>
        Since <m>U+W</m> contains <m>\zer</m>, and is closed under both addition and scalar multiplication,
        it is a subspace.
      </p>

      <p>
        Now, suppose <m>X</m> is a subspace of <m>V</m> such that <m>U\subseteq X</m> and <m>W\subseteq X</m>.
        Let <m>\xx\in U+W</m>. Then <m>\xx=\uu+\ww</m> for some <m>\uu\in U</m> and <m>\ww\in W</m>.
        Since <m>\uu\in U</m> and <m>U\subseteq X</m>, <m>\uu\in X</m>.
        Similarly, <m>\ww\in X</m>. Since <m>X</m> is a subspace, it is closed under addition,
        so <m>\uu+\ww=\xx\in X</m>. Therefore, <m>U+W\subseteq X</m>.
      </p>
    </proof>

  </theorem>


  <p>
    If <m>U\cap W = \{\mathbf{0}\}</m>, we say that the sum is a <term>direct sum</term>,
    and write it as <m>U\oplus W</m>.
    The following theorem might help us understand why direct sums are singled out for special attention:
  </p>

  <theorem xml:id="thm-sum-dimension">
    <statement>
      <p>
        Let <m>U</m> and <m>W</m> be subspaces of a finite-dimensional vector space <m>V</m>.
        Then <m>U+W</m> is finite-dimensional, and
        <me>
          \dim(U+W)=\dim U + \dim W - \dim(U\cap W)
        </me>.
      </p>
    </statement>
    <proof>
      <title>Strategy</title>
      <p>
        This is a proof that would be difficult (if not impossible) without using a basis.
        Your first thought might be to choose bases for the subspaces <m>U</m> and <m>W</m>,
        but this runs into trouble: some of the basis vectors for <m>U</m> might be in <m>W</m>,
        and vice-versa.
      </p>
      <p>
        Of course, those vectors will be in <m>U\cap W</m>, but it gets hard to keep track:
        without more information (and we have none, since we want to be completely general),
        how do we tell which basis vectors are in the intersection, and how many?
      </p>
      <p>
        Instead, we <em>start</em> with a basis for <m>U\cap W</m>.
        This is useful, because <m>U\cap W</m> is a subspace of both <m>U</m> and <m>W</m>.
        So any basis for <m>U\cap W</m> can be extended to a basis of <m>U</m>,
        and it can also be extended to a basis of <m>W</m>.
      </p>
      <p>
        The rest of the proof relies on making sure that neither of these extensions have any vectors in common,
        and that putting everything together gives a basis for <m>U+W</m>.
        (This amounts to going back to the definition of a basis:
        we need to show that it's linearly independent, and that it spans <m>U+W</m>.)
      </p>
    </proof>
    <proof>
      <p>
        Let <m>B_1 = \{\xx_1,\ldots, \xx_k\}</m> be a basis for <m>U\cap W</m>.
        Extend <m>B_1</m> to a basis <m>B_2=\{\xx_1,\ldots, \xx_k,\uu_1,\ldots,\uu_m\}</m> of <m>U</m>,
        and to a basis <m>B_3=\{\xx_1,\ldots, \xx_k,\ww_1,\ldots, \ww_n\}</m> of <m>W</m>.
        Note that we have <m>\dim (U\cap W)=k</m>, <m>\dim U = k+m</m>, and <m>\dim W=k+n</m>.
      </p>
      <p>
        Now, consider the set <m>B=\{\xx_1,\ldots, \xx_k,\uu_1,\ldots, \uu_m,\ww_1,\ldots, \ww_n\}</m>.
        We claim that <m>B</m> is a basis for <m>U+W</m>.
        We know that <m>B_2</m> is linearly independent, since it's a basis for <m>U</m>,
        and that <m>B=B_2\cup\{\ww_1,\ldots, \ww_n\}</m>.
        It remains to show that none of the <m>\ww_i</m> are in the span of <m>B_2</m>;
        if so, then <m>B</m> is independent by <xref ref="lemma-independent"/>.
      </p>
      <p>
        Since <m>\spn B_2=U</m>, it suffices to show that none of the <m>\ww_i</m> belong to <m>U</m>.
        But we know that <m>\ww_i\in W</m>, so if <m>\ww_i\in U</m>, then <m>\ww_i\in U\cap W</m>.
        But if <m>\ww_i\in U\cap W</m>, then <m>\ww_i\in \spn B_1</m>,
        which would imply that <m>B_3</m> is linearly dependent,
        and since <m>B_3</m> is a basis, this is impossible.
      </p>
      <p>
        Next, we need to show that <m>\spn B = U+W</m>.
        Let <m>\vv\in U+W</m>; then <m>\vv=\uu+\ww</m> for some <m>\uu\in U</m> and <m>\ww\in W</m>.
        Since <m>\uu\in U</m>, there exist scalars <m>a_1,\ldots, a_k, b_1,\ldots, b_m</m> such that
        <me>
          \uu=a_1\xx_1+\cdots + a_k\xx_k+b_1\uu_1+\cdots+b_m\uu_m
        </me>,
        and since <m>\ww\in W</m>, there exist scalars <m>c_1,\ldots, c_k,d_1,\ldots, d_n</m> such that
        <me>
          \ww=c_1\xx_1+\cdots +c_k\xx_k+d_1\ww_1+\cdots +d_n\ww_n
        </me>.
        Thus,
        <me>
          \vv = \uu+\ww = (a_1+c_1)\xx_1+\cdots+(a_k+c_k)\xx_k+b_1\uu_1+\cdots +b_m\uu_m+d_1\ww_1+\cdots + d_n\ww_n
        </me>,
        which shows that <m>\vv\in \spn B</m>.
      </p>
      <p>
        Finally, we check that this gives the dimension as claimed. We have
        <me>
          \dim U + \dim W - \dim (U\cap W) = (k+m)+(k+n)-k=k+m+n=\dim(U+W)
        </me>,
        since there are <m>k</m> vectors in <m>B_1</m>, <m>k+m</m> vectors in <m>B_2</m>,
        <m>k+n</m> vectors in <m>B_3</m>, and <m>k+m+n</m> vectors in <m>B</m>.
      </p>
    </proof>
  </theorem>

  <p>
    Notice how a vector <m>\vv\in U+W</m> can be written as a sum of a vector in <m>U</m> and a vector <m>W</m>,
    but <em>not uniquely</em>, in general: in the above proof,
    we can change the values of the coefficients <m>a_i</m> and <m>c_i</m>,
    as long as the sum <m>a_i+c_i</m> remains unchanged.
    Note that these are the coefficients of the basis vectors for <m>U\cap W</m>.
  </p>

  <p>
    If the sum is direct, then we have simply <m>\dim(U\oplus W) = \dim U + \dim W</m>.
    The other reason why direct sums are preferable, is that any <m>\vv\in U\oplus W</m>
    can be written <em>uniquely</em> as <m>\vv=\uu+\ww</m>
    where <m>\uu\in U</m> and <m>\ww\in W</m>, since we no longer have the ambiguity resulting from the basis vectors in <m>U\cap W</m>.
  </p>

  <theorem xml:id="thm-direct-sum">
    <statement>
      <p>
        For any subspaces <m>U,W</m> of a vector space <m>V</m>,
        <m>U\cap W = \{\mathbf{0}\}</m> if and only if for every <m>\vv\in U+W</m>
        there exist unique <m>\uu\in U, \ww\in W</m> such that <m>\vv=\uu+\ww</m>.
      </p>
    </statement>
    <proof>
      <p>
        Suppose that <m>U\cap W = \{\mathbf{0}\}</m>, and suppose that we have
        <m>\vv = \uu_1+\ww_1 = \uu_2+\ww_2</m>,
        for <m>\uu_1,\uu_2\in U,\ww_1,\ww_2\in W</m>.
        Then <m>\mathbf{0}=(\uu_1-\uu_2)+(\ww_1-\ww_2)</m>,
        which implies that
        <me>
          \ww_1-\ww_2 = -(\uu_1-\uu_2)
        </me>.
        Now, <m>\uu=\uu_1-\uu_2\in U</m>,
        since <m>U</m> is a subspace, and similarly,
        <m>\ww=\ww_1-\ww_2\in W</m>.
        But we also have <m>\ww=-\uu</m>, which implies that <m>\ww\in U</m>.
        (Since <m>-\uu</m> is in <m>U</m>, and this is the same vector as <m>\ww</m>.)
        Therefore, <m>\ww\in U\cap W</m>, which implies that <m>\ww=\mathbf{0}</m>,
        so <m>\ww_1=\ww_2</m>.
        But we must also then have <m>\uu=\mathbf{0}</m>, so <m>\uu_1=\uu_2</m>.
      </p>

      <p>
        Conversely, suppose that every <m>\vv\in U+W</m> can be written uniquely as <m>\vv=\vec{u}+\ww</m>,
        with <m>\uu\in U</m> and <m>\ww\in W</m>. Suppose that <m>\mathbf{a}\in U\cap W</m>.
        Then <m>\mathbf{a}\in U</m> and <m>\mathbf{a}\in W</m>, so we also have <m>-\mathbf{a}\in W</m>,
        since <m>W</m> is a subspace.
        But then <m>\mathbf{0}=\mathbf{a}+(-\mathbf{a})</m>, where <m>\mathbf{a}\in U</m> and <m>-\mathbf{a}\in W</m>.
        On the other hand, <m>\mathbf{0}=\mathbf{0}+\mathbf{0}</m>,
        and <m>\mathbf{0}</m> belongs to both <m>U</m> and <m>W</m>. It follows that <m>\mathbf{a}=\mathbf{0}</m>.
        Since <m>\mathbf{a}</m> was arbitrary, <m>U\cap W = \{\mathbf{0}\}</m>.
      </p>
    </proof>

  </theorem>

  <p>
    We end with one last application of the theory we've developed on the existence of a basis for a finite-dimensional vector space.
    As we continue on to later topics, we'll find that it is often useful to be able to decompose a vector space into a direct sum of subspaces.
    Using bases, we can show that this is always possible.
  </p>

  <theorem xml:id="thm-construct-complement">
    <statement>
      <p>
        Let <m>V</m> be a finite-dimensional vector space, and let <m>U</m> be any subspace of <m>V</m>.
        Then there exists a subspace <m>W\subseteq V</m> such that <m>U\oplus W = V</m>.
      </p>
    </statement>
    <proof>
      <p>
        Let <m>\{\uu_1,\ldots, \uu_m\}</m> be a basis of <m>U</m>.
        Since <m>U\subseteq V</m>, the set <m>\{\uu_1,\ldots, \uu_m\}</m>
        is a linearly independent subset of <m>V</m>.
        Since any linearly independent set can be extended to a basis of <m>V</m>,
        there exist vectors <m>\ww_1,\ldots,\ww_n</m> such that
        <me>
          \{\uu_1,\ldots, \uu_m,\ww_1,\ldots, \ww_n\}
        </me>
        is a basis of <m>V</m>.
      </p>

      <p>
        Now, let <m>W = \spn\{\ww_1,\ldots, \ww_n\}</m>.
        Then <m>W</m> is a subspace, and <m>\{\ww_1,\ldots, \ww_n\}</m>
        is a basis for <m>W</m>. (It spans, and must be independent since it's a subset of an independent set.)
      </p>

      <p>
        Clearly, <m>U+W=V</m>, since <m>U+W</m> contains the basis for <m>V</m> we've constructed.
        To show the sum is direct, it suffices to show that <m>U\cap W = \{\mathbf{0}\}</m>.
        To that end, suppose that <m>\vv\in U\cap W</m>.
        Since <m>\vv\in U</m>, we have
        <me>
          \vv=a_1\uu_1+\cdots +a_m\uu_m
        </me>
        for scalars <m>a_1,\ldots, a_m</m>. Since <m>\vv\in W</m>, we can write
        <me>
          \vv=b_1\ww_1+\cdots + b_n\ww_n
        </me>
        for scalars <m>b_1,\ldots, b_n</m>. But then
        <me>
          \mathbf{0}=\vv-\vv=a_1\uu_1+\cdots a_m\uu_m-b_1\ww_1-\cdots -b_n\ww_n.
        </me>
        Since <m>\{\uu_1,\ldots, \uu_m,\ww_1,\ldots, \ww_n\}</m> is a basis for <m>V</m>,
        it's independent, and therefore, all of the <m>a_i,b_j</m> must be zero, and therefore, <m>\vv=\mathbf{0}</m>.

      </p>
    </proof>


  </theorem>

  <p>
    The subspace <m>W</m> constructed in the theorem above is called a <term>complement</term> of <m>U</m>.
    It is not unique; indeed, it depends on the choice of basis vectors.
    For example, if <m>U</m> is a one-dimensional subspace of <m>\R^2</m>; that is, a line,
    then any other non-parallel line through the origin provides a complement of <m>U</m>.
    Later we will see that an especially useful choice of complement is the <term>orthogonal complement</term>.
  </p>
</section>
