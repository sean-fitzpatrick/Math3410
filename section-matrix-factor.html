<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Matrix Factorizations and Eigenvalues</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="Linear Algebra">
<meta property="book:author" content="Sean Fitzpatrick">
<script src="https://sagecell.sagemath.org/static/embedded_sagecell.js"></script><script>var runestoneMathReady = new Promise((resolve) => window.rsMathReady = resolve);
window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'color', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore|ignore-math",
    processHtmlClass: "process-math",
    renderActions: {
        findScript: [10, function (doc) {
            document.querySelectorAll('script[type^="math/tex"]').forEach(function(node) {
                var display = !!node.type.match(/; *mode=display/);
                var math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                var text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = {node: text, delim: '', n: 0};
                math.end = {node: text, delim: '', n: 0};
                doc.math.push(math);
            });
        }, '']
    },
  },
  chtml: {
    scale: 0.98,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/color', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
  startup: {
    /* Mathjax typesetting operation is under the control of React */
    typeset: false,
  },
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><link href="https://webwork-dev.uleth.ca/webwork2_files/js/apps/MathView/mathview.css" rel="stylesheet">
<script src="https://pretextbook.org/js/0.3/pretext-webwork/2.17/pretext-webwork.js"></script><script src="https://webwork-dev.uleth.ca/webwork2_files/node_modules/iframe-resizer/js/iframeResizer.min.js"></script><script>// Make *any* pre with class 'sagecell-sage' an executable Sage cell
// Their results will be linked, only within language type
sagecell.makeSagecell({inputLocation: 'pre.sagecell-sage',
                       linked: true,
                       languages: ['sage'],
                       evalButtonText: 'Evaluate (Sage)'});
</script><script>js_version = 0.3</script><script type="module" defer src="https://siefkenj.github.io/pretext-react/static/js/main.js"></script><link href="https://siefkenj.github.io/pretext-react/static/css/main.css" rel="stylesheet">
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&amp;family=Noto+Serif:ital,wght@0,400;0,700;1,400;1,700&amp;family=Tinos:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" rel="stylesheet">
<link href="https://fonts.cdnfonts.com/css/dejavu-serif" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Roboto+Serif:opsz,wdth,wght@8..144,50..150,100..900&amp;display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Open+Sans:wdth,wght@75..100,300..800&amp;display=swap" rel="stylesheet">
<script type="application/json" class="js-hypothesis-config">{
    "openSidebar": false,    "showHighlights": true,}</script><script src="https://hypothes.is/embed.js" async=""></script><!--** eBookCongig is necessary to configure interactive       **-->
<!--** Runestone components to run locally in reader's browser **-->
<!--** No external communication:                              **-->
<!--**     log level is 0, Runestone Services are disabled     **-->
<script type="text/javascript">
eBookConfig = {};
eBookConfig.useRunestoneServices = false;
eBookConfig.host = 'http://127.0.0.1:8000';
eBookConfig.course = 'PTX_Course_Title_Here';
eBookConfig.basecourse = 'PTX_Base_Course';
eBookConfig.isLoggedIn = false;
eBookConfig.email = '';
eBookConfig.isInstructor = false;
eBookConfig.logLevel = 0;
eBookConfig.username = '';
eBookConfig.readings = null;
eBookConfig.activities = null;
eBookConfig.downloadsEnabled = false;
eBookConfig.allow_pairs = false;
eBookConfig.enableScratchAC = false;
eBookConfig.build_info = "";
eBookConfig.python3 = null;
eBookConfig.runestone_version = '7.0.0dev3';
eBookConfig.jobehost = '';
eBookConfig.proxyuri_runs = '';
eBookConfig.proxyuri_files = '';
eBookConfig.enable_chatcodes =  false;
</script>
<!--*** Runestone Services ***-->
<script type="text/javascript" src="https://runestone.academy/cdn/runestone/7.0.0dev3/prefix-runtime.71ffd81c0faeb38b.bundle.js"></script><script type="text/javascript" src="https://runestone.academy/cdn/runestone/7.0.0dev3/prefix-347.193e36c07abd0197.bundle.js"></script><script type="text/javascript" src="https://runestone.academy/cdn/runestone/7.0.0dev3/prefix-runestone.e543e0dd19670ae2.bundle.js"></script><link rel="stylesheet" type="text/css" href="https://runestone.academy/cdn/runestone/7.0.0dev3/prefix-347.f9add1ca35d5ad93.css">
<link rel="stylesheet" type="text/css" href="https://runestone.academy/cdn/runestone/7.0.0dev3/prefix-runestone.1f1f63d2cda36a4d.css">
</head>
<body id="Math3410" data-react-in-use="yes" class="pretext book ignore-math">
<a class="assistive" href="#ptx-content">Skip to main content</a><header id="ptx-masthead" class="ptx-masthead"><div class="ptx-banner">
<a id="logo-link" class="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="linear-algebra.html"><span class="title">Linear Algebra:</span> <span class="subtitle">A second course, featuring proofs and Python</span></a></h1>
<p class="byline">Sean Fitzpatrick</p>
</div>
<div id="searchresultsplaceholder" class="searchresultsplaceholder" style="display: none">
<button id="closesearchresults" class="closesearchresults" onclick="document.getElementById('searchresultsplaceholder').style.display = 'none'; return false;">x</button><h2>Search Results: <span id="searchterms" class="searchterms"></span>
</h2>
<div id="searchempty" class="searchempty"><span>No results.</span></div>
<ol id="searchresults" class="searchresults"></ol>
</div>
</div></header><nav id="ptx-navbar" class="ptx-navbar navbar"><button class="toc-toggle button" aria-label="Show or hide table of contents"><span class="icon">‚ò∞</span><span class="name">Contents</span></button><span class="treebuttons"><a class="previous-button button" href="worksheet-dynamical.html" title="Previous"><span class="icon">&lt;</span><span class="name">Prev</span></a><a class="up-button button" href="ch-diagonalization.html" title="Up"><span class="icon">^</span><span class="name">Up</span></a><a class="next-button button" href="worksheet-svd.html" title="Next"><span class="name">Next</span><span class="icon">&gt;</span></a></span><div class="searchbox"><div class="searchwidget">
<input id="ptxsearch" class="ptxsearch" type="text" name="terms" placeholder="Search" onchange="doSearch()"><button id="searchbutton" class="searchbutton" type="button" onclick="doSearch()">üîç</button>
</div></div></nav><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\require{boldsymbol}\newcommand{\spn}{\operatorname{span}}
\newcommand{\bbm}{\begin{bmatrix}}
\newcommand{\ebm}{\end{bmatrix}}
\newcommand{\R}{\mathbb{R}}
\ifdefined\C
\renewcommand\C{\mathbb{C}}
\else
\newcommand\C{\mathbb{C}}
\fi
\newcommand{\im}{\operatorname{im}}
\newcommand{\nll}{\operatorname{null}}
\newcommand{\csp}{\operatorname{col}}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\diag}{\operatorname{diag}}
\newcommand{\tr}{\operatorname{tr}}
\newcommand{\dotp}{\!\boldsymbol{\cdot}\!}
\newcommand{\len}[1]{\lVert #1\rVert}
\newcommand{\abs}[1]{\lvert #1\rvert}
\newcommand{\proj}[2]{\operatorname{proj}_{#1}{#2}}
\newcommand{\bz}{\overline{z}}
\newcommand{\zz}{\mathbf{z}}
\newcommand{\uu}{\mathbf{u}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\ww}{\mathbf{w}}
\newcommand{\xx}{\mathbf{x}}
\newcommand{\yy}{\mathbf{y}}
\newcommand{\zer}{\mathbf{0}}
\newcommand{\vecq}{\mathbf{q}}
\newcommand{\vecp}{\mathbf{p}}
\newcommand{\vece}{\mathbf{e}}
\newcommand{\basis}[2]{\{\mathbf{#1}_1,\mathbf{#1}_2,\ldots,\mathbf{#1}_{#2}\}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<div class="ptx-page">
<div id="ptx-sidebar" class="ptx-sidebar"><nav id="ptx-toc" class="ptx-toc depth2"><ul class="structural">
<li>
<div class="toc-item"><a href="frontmatter-1.html" class="internal"><span class="title">Front Matter</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="colophon-1.html" class="internal"><span class="title">Colophon</span></a></div></li>
<li><div class="toc-item"><a href="preface-1.html" class="internal"><span class="title">Preface</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="ch-vector-space.html" class="internal"><span class="codenumber">1</span> <span class="title">Vector spaces</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="sec-vec-sp.html" class="internal"><span class="codenumber">1.1</span> <span class="title">Definition and examples</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="sec-vec-sp.html#exercises-1" class="internal"><span class="codenumber">1.1</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
<li><div class="toc-item"><a href="sec-vsp-properties.html" class="internal"><span class="codenumber">1.2</span> <span class="title">Properties</span></a></div></li>
<li>
<div class="toc-item"><a href="sec-subspace.html" class="internal"><span class="codenumber">1.3</span> <span class="title">Subspaces</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="sec-subspace.html#exercises-2" class="internal"><span class="codenumber">1.3</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
<li>
<div class="toc-item"><a href="sec-span.html" class="internal"><span class="codenumber">1.4</span> <span class="title">Span</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="sec-span.html#exercises-3" class="internal"><span class="codenumber">1.4</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
<li><div class="toc-item"><a href="worksheet-span.html" class="internal"><span class="codenumber">1.5</span> <span class="title">Worksheet: understanding span</span></a></div></li>
<li>
<div class="toc-item"><a href="sec-independence.html" class="internal"><span class="codenumber">1.6</span> <span class="title">Linear Independence</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="sec-independence.html#exercises-4" class="internal"><span class="codenumber">1.6</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
<li>
<div class="toc-item"><a href="sec-dimension.html" class="internal"><span class="codenumber">1.7</span> <span class="title">Basis and dimension</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="sec-dimension.html#exercises-5" class="internal"><span class="codenumber">1.7</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
<li>
<div class="toc-item"><a href="sec-subspace-combine.html" class="internal"><span class="codenumber">1.8</span> <span class="title">New subspaces from old</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="sec-subspace-combine.html#exercises-6" class="internal"><span class="codenumber">1.8</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="ch-linear-trans.html" class="internal"><span class="codenumber">2</span> <span class="title">Linear Transformations</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="sec-lin-tran-intro.html" class="internal"><span class="codenumber">2.1</span> <span class="title">Definition and examples</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="sec-lin-tran-intro.html#exercises-7" class="internal"><span class="codenumber">2.1</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
<li>
<div class="toc-item"><a href="sec-kernel-image.html" class="internal"><span class="codenumber">2.2</span> <span class="title">Kernel and Image</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="sec-kernel-image.html#exercises-8" class="internal"><span class="codenumber">2.2</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
<li>
<div class="toc-item"><a href="sec-isomorphism.html" class="internal"><span class="codenumber">2.3</span> <span class="title">Isomorphisms, composition, and inverses</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-isomorphism.html#subsec-isomorphism" class="internal"><span class="codenumber">2.3.1</span> <span class="title">Isomorphisms</span></a></div></li>
<li>
<div class="toc-item"><a href="sec-isomorphism.html#subsec-composition" class="internal"><span class="codenumber">2.3.2</span> <span class="title">Composition and inverses</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="sec-isomorphism.html#exercises-9" class="internal"><span class="codenumber">2.3.2</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
</ul>
</li>
<li><div class="toc-item"><a href="worksheet-transformations.html" class="internal"><span class="codenumber">2.4</span> <span class="title">Worksheet: matrix transformations</span></a></div></li>
<li><div class="toc-item"><a href="worksheet-recurrence.html" class="internal"><span class="codenumber">2.5</span> <span class="title">Worksheet: linear recurrences</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="ch-orthogonality.html" class="internal"><span class="codenumber">3</span> <span class="title">Orthogonality and Applications</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="sec-orthogonal-sets.html" class="internal"><span class="codenumber">3.1</span> <span class="title">Orthogonal sets of vectors</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-orthogonal-sets.html#subsec-dot-basics" class="internal"><span class="codenumber">3.1.1</span> <span class="title">Basic definitions and properties</span></a></div></li>
<li><div class="toc-item"><a href="sec-orthogonal-sets.html#subsec-ortho-sets" class="internal"><span class="codenumber">3.1.2</span> <span class="title">Orthogonal sets of vectors</span></a></div></li>
<li><div class="toc-item"><a href="sec-orthogonal-sets.html#exercises-10" class="internal"><span class="codenumber">3.1.3</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="sec-gram-schmidt.html" class="internal"><span class="codenumber">3.2</span> <span class="title">The Gram-Schmidt Procedure</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="sec-gram-schmidt.html#exercises-11" class="internal"><span class="codenumber">3.2</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
<li>
<div class="toc-item"><a href="section-projection.html" class="internal"><span class="codenumber">3.3</span> <span class="title">Orthogonal Projection</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="section-projection.html#exercises-12" class="internal"><span class="codenumber">3.3</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
<li><div class="toc-item"><a href="worksheet-dual-basis.html" class="internal"><span class="codenumber">3.4</span> <span class="title">Worksheet: dual basis.</span></a></div></li>
<li><div class="toc-item"><a href="worksheet-least-squares.html" class="internal"><span class="codenumber">3.5</span> <span class="title">Worksheet: Least squares approximation</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="ch-diagonalization.html" class="internal"><span class="codenumber">4</span> <span class="title">Diagonalization</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-eigen-basics.html" class="internal"><span class="codenumber">4.1</span> <span class="title">Eigenvalues and Eigenvectors</span></a></div></li>
<li><div class="toc-item"><a href="subsec-ortho-diag.html" class="internal"><span class="codenumber">4.2</span> <span class="title">Diagonalization of symmetric matrices</span></a></div></li>
<li><div class="toc-item"><a href="sec-quadratic.html" class="internal"><span class="codenumber">4.3</span> <span class="title">Quadratic forms</span></a></div></li>
<li>
<div class="toc-item"><a href="sec-complex.html" class="internal"><span class="codenumber">4.4</span> <span class="title">Diagonalization of complex matrices</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-complex.html#subsec-complex-vector" class="internal"><span class="codenumber">4.4.1</span> <span class="title">Complex vectors</span></a></div></li>
<li><div class="toc-item"><a href="sec-complex.html#subsec-complex-matrix" class="internal"><span class="codenumber">4.4.2</span> <span class="title">Complex matrices</span></a></div></li>
</ul>
</li>
<li><div class="toc-item"><a href="worksheet-dynamical.html" class="internal"><span class="codenumber">4.5</span> <span class="title">Worksheet: linear dynamical systems</span></a></div></li>
<li class="active">
<div class="toc-item"><a href="section-matrix-factor.html" class="internal"><span class="codenumber">4.6</span> <span class="title">Matrix Factorizations and Eigenvalues</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="section-matrix-factor.html#subsec-matrix-factorization" class="internal"><span class="codenumber">4.6.1</span> <span class="title">Matrix Factorizations</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="section-matrix-factor.html#pars-positive-ops" class="internal"><span class="codenumber">4.6.1.1</span> <span class="title">Positive Operators</span></a></div></li>
<li><div class="toc-item"><a href="section-matrix-factor.html#pars-singular-values" class="internal"><span class="codenumber">4.6.1.2</span> <span class="title">Singular Value Decomposition</span></a></div></li>
<li><div class="toc-item"><a href="section-matrix-factor.html#pars-qr-factor" class="internal"><span class="codenumber">4.6.1.3</span> <span class="title">QR Factorization</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="section-matrix-factor.html#subsec-compute-eigen" class="internal"><span class="codenumber">4.6.2</span> <span class="title">Computing Eigenvalues</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="section-matrix-factor.html#pars-power-method" class="internal"><span class="codenumber">4.6.2.1</span> <span class="title">The Power Method</span></a></div></li>
<li><div class="toc-item"><a href="section-matrix-factor.html#pars-qr-algorithm" class="internal"><span class="codenumber">4.6.2.2</span> <span class="title">The QR Algorithm</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li><div class="toc-item"><a href="worksheet-svd.html" class="internal"><span class="codenumber">4.7</span> <span class="title">Worksheet: Singular Value Decomposition</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="ch-change-basis.html" class="internal"><span class="codenumber">5</span> <span class="title">Change of Basis</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-matrix-of-transformation.html" class="internal"><span class="codenumber">5.1</span> <span class="title">The matrix of a linear transformation</span></a></div></li>
<li><div class="toc-item"><a href="sec-matrix-operator.html" class="internal"><span class="codenumber">5.2</span> <span class="title">The matrix of a linear operator</span></a></div></li>
<li>
<div class="toc-item"><a href="sec-direct-sum.html" class="internal"><span class="codenumber">5.3</span> <span class="title">Direct Sums and Invariant Subspaces</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-direct-sum.html#subsec-invariant" class="internal"><span class="codenumber">5.3.1</span> <span class="title">Invariant subspaces</span></a></div></li>
<li><div class="toc-item"><a href="sec-direct-sum.html#subsec-eigenspace" class="internal"><span class="codenumber">5.3.2</span> <span class="title">Eigenspaces</span></a></div></li>
<li><div class="toc-item"><a href="sec-direct-sum.html#subsec-direct-sum" class="internal"><span class="codenumber">5.3.3</span> <span class="title">Direct Sums</span></a></div></li>
</ul>
</li>
<li><div class="toc-item"><a href="worksheet-gen-eigen.html" class="internal"><span class="codenumber">5.4</span> <span class="title">Worksheet: generalized eigenvectors</span></a></div></li>
<li><div class="toc-item"><a href="sec-gen-eigen.html" class="internal"><span class="codenumber">5.5</span> <span class="title">Generalized eigenspaces</span></a></div></li>
<li><div class="toc-item"><a href="sec-jordan-form.html" class="internal"><span class="codenumber">5.6</span> <span class="title">Jordan Canonical Form</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="backmatter-1.html" class="internal"><span class="title">Back Matter</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="appendix-complex-review.html" class="internal"><span class="codenumber">A</span> <span class="title">Review of complex numbers</span></a></div></li>
<li>
<div class="toc-item"><a href="ch-computation.html" class="internal"><span class="codenumber">B</span> <span class="title">Computational Tools</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="section-jupyter.html" class="internal"><span class="codenumber">B.1</span> <span class="title">Jupyter</span></a></div></li>
<li><div class="toc-item"><a href="sec-python-basics.html" class="internal"><span class="codenumber">B.2</span> <span class="title">Python basics</span></a></div></li>
<li>
<div class="toc-item"><a href="sec-sympy.html" class="internal"><span class="codenumber">B.3</span> <span class="title">SymPy for linear algebra</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="sec-sympy.html#subsec-sympy-basics" class="internal"><span class="codenumber">B.3.1</span> <span class="title">SymPy basics</span></a></div></li>
<li><div class="toc-item"><a href="sec-sympy.html#subsec-sympy-matrix" class="internal"><span class="codenumber">B.3.2</span> <span class="title">Matrices in SymPy</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li><div class="toc-item"><a href="solutions-backmatter.html" class="internal"><span class="codenumber">C</span> <span class="title">Solutions to Selected Exercises</span></a></div></li>
</ul>
</li>
</ul></nav></div>
<main class="ptx-main"><div id="ptx-content" class="ptx-content">
<section class="section" id="section-matrix-factor"><h2 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber">4.6</span> <span class="title">Matrix Factorizations and Eigenvalues</span>
</h2>
<section class="introduction" id="introduction-31"><div class="para" id="p-1837">This section is a rather rapid tour of some cool ideas that get a lot of use in applied linear algebra. We are rather light on details here. The interested reader can consult sections 8.3‚Äì8.6 in the Nicholson textbook.</div></section><section class="subsection" id="subsec-matrix-factorization"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.6.1</span> <span class="title">Matrix Factorizations</span>
</h3>
<section class="subsubsection" id="pars-positive-ops"><h4 class="heading hide-type">
<span class="type">Subsubsection</span> <span class="codenumber">4.6.1.1</span> <span class="title">Positive Operators</span>
</h4>
<div class="para" id="p-1838">Let <span class="process-math">\(T\)</span> be a linear operator defined by a matrix <span class="process-math">\(A\text{.}\)</span> If <span class="process-math">\(A\)</span> is symmetric (for the case of <span class="process-math">\(\R^n\)</span>) or hermitian (for the case of <span class="process-math">\(\C^n\)</span>), we say that the operator <span class="process-math">\(T\)</span> is <dfn class="terminology">self-adjoint</dfn>.</div>
<article class="definition definition-like" id="def-positive-op"><h5 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">4.6.1</span><span class="period">.</span>
</h5>
<div class="para" id="p-1839">A self-adjoint operator <span class="process-math">\(T\)</span> is <dfn class="terminology">positive</dfn> if <span class="process-math">\(\xx^H T\xx\geq 0\)</span> for all vectors <span class="process-math">\(\xx\neq \zer\text{.}\)</span> It is <dfn class="terminology">positive-definite</dfn> if <span class="process-math">\(\xx^H T\xx\gt 0\)</span> for all nonzero <span class="process-math">\(\xx\text{.}\)</span> If <span class="process-math">\(T=T_A\)</span> for some matrix <span class="process-math">\(A\text{,}\)</span> we also refer to <span class="process-math">\(A\)</span> as a positive(-definite) matrix.</div></article><aside class="aside aside-like" id="aside-10"><div class="para" id="p-1840">Some books will define positive-definite operators by the condition <span class="process-math">\(\xx^H T\xx\geq 0\)</span> without the requirement that <span class="process-math">\(T\)</span> is self-adjoint. However, we will stick to the simpler definition.</div></aside><div class="para logical" id="p-1841">
<div class="para">The definition of a positive matrix is equivalent to requiring that all its eigenvalues are non-negative. Every positive matrix <span class="process-math">\(A\)</span> has a unique positive square root: a matrix <span class="process-math">\(R\)</span> such that <span class="process-math">\(R^2=A\text{.}\)</span> Since <span class="process-math">\(A\)</span> is symmetric/hermitian, it can be diagonalized. Writing <span class="process-math">\(A = PDP^{-1}\)</span> where <span class="process-math">\(P\)</span> is orthogonal/unitary and</div>
<div class="displaymath process-math">
\begin{equation*}
D = \bbm \lambda_1 \amp 0\amp \cdots \amp 0\\0\amp \lambda_2 \amp \cdots \amp 0\\ \vdots \amp \vdots \amp \ddots \amp \vdots\\ 0\amp 0\amp \cdots \amp \lambda_n\ebm\text{,}
\end{equation*}
</div>
<div class="para">we have <span class="process-math">\(R=PEP^{-1}\text{,}\)</span> where</div>
<div class="displaymath process-math">
\begin{equation*}
D = \bbm \sqrt{\lambda_1} \amp 0\amp \cdots \amp 0\\0\amp \sqrt{\lambda_2} \amp \cdots \amp 0\\ \vdots \amp \vdots \amp \ddots \amp \vdots\\ 0\amp 0\amp \cdots \amp \sqrt{\lambda_n}\ebm\text{.}
\end{equation*}
</div>
</div>
<div class="para" id="p-1842">The following theorem gives us a simple way of generating positive matrices.</div>
<article class="theorem theorem-like" id="thm-positive-prod"><h5 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">4.6.2</span><span class="period">.</span>
</h5>
<div class="para" id="p-1843">For any <span class="process-math">\(n\times n\)</span> matrix <span class="process-math">\(U\text{,}\)</span> the matrix <span class="process-math">\(A=U^TU\)</span> is positive. Moreover, if <span class="process-math">\(U\)</span> is invertible, then <span class="process-math">\(A\)</span> is positive-definite.</div></article><article class="hiddenproof" id="proof-61"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-61"><h5 class="heading"><span class="type">Proof<span class="period">.</span></span></h5></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-61"><article class="hiddenproof"><div class="para logical" id="p-1844">
<div class="para">For any <span class="process-math">\(\xx\neq \zer\)</span> in <span class="process-math">\(\R^n\text{,}\)</span>
</div>
<div class="displaymath process-math">
\begin{equation*}
\xx^T A\xx = \xx^TU^T U\xx = (U\xx)^T(U\xx) = \len{U\xx}^2\geq 0\text{.}
\end{equation*}
</div>
</div></article></div>
<div class="para" id="p-1845">What is interesting is that the converse to the above statement is also true. The <dfn class="terminology">Cholesky factorization</dfn> of a positive-definite matrix <span class="process-math">\(A\)</span> is given by <span class="process-math">\(A=U^TU\text{,}\)</span> where <span class="process-math">\(U\)</span> is upper-triangular, with positive diagonal entries. (See Nicholson for details.)</div>
<div class="para" id="p-1846">Even better is that there is a very simple algorithm for obtaining the factorization: Carry the matrix <span class="process-math">\(A\)</span> to triangular form, using only row operations of the type <span class="process-math">\(R_i+kR_j\to R_i\text{.}\)</span> Then divide each row by the square root of the diagonal entry.</div>
<div class="para" id="p-1847">The SymPy library contains the <code class="code-inline tex2jax_ignore">cholesky()</code> algorithm. Note however that it produces a lower triangular matrix, rather than upper triangular. (That is, the output gives <span class="process-math">\(L=U^T\)</span> rather than <span class="process-math">\(U\text{,}\)</span> so you will have <span class="process-math">\(A=LL^T\text{.}\)</span>) Let‚Äôs give it a try. First, let‚Äôs create a positive-definite matrix.</div>
<pre class="ptx-sagecell sagecell-sage" id="sage-79"><script type="text/x-sage">from sympy import Matrix,init_printing
init_printing()
B = Matrix([[3,7,-4],[5,-9,2],[-3,0,6]])
A = B*B.T
A
</script></pre>
<div class="para" id="p-1848">Next, find the Cholesky factorization:</div>
<pre class="ptx-sagecell sagecell-sage" id="sage-80"><script type="text/x-sage">L = A.cholesky()
L, L*L.T
</script></pre>
<pre class="ptx-sagecell sagecell-sage" id="sage-81"><script type="text/x-sage">L*L.T == A
</script></pre>
<div class="para" id="p-1849">Note that <span class="process-math">\(L\)</span> is <em class="emphasis">not</em> the same as the matrix <span class="process-math">\(B\text{!}\)</span>
</div></section><section class="subsubsection" id="pars-singular-values"><h4 class="heading hide-type">
<span class="type">Subsubsection</span> <span class="codenumber">4.6.1.2</span> <span class="title">Singular Value Decomposition</span>
</h4>
<div class="para" id="p-1850">For any <span class="process-math">\(n\times n\)</span> matrix <span class="process-math">\(A\text{,}\)</span> the matrices <span class="process-math">\(A^TA\)</span> and <span class="process-math">\(AA^T\)</span> are both positive. (Exercise!) This means that we can define <span class="process-math">\(\sqrt{A^TA}\text{,}\)</span> even if <span class="process-math">\(A\)</span> itself is not symmetric or positive.</div>
<div class="para logical" id="p-1851"><ul class="disc">
<li id="li-335"><div class="para" id="p-1852">Since <span class="process-math">\(A^TA\)</span> is symmetric, we know that it can be diagonalized.</div></li>
<li id="li-336"><div class="para" id="p-1853">Since <span class="process-math">\(A^TA\)</span> is positive, we know its eigenvalues are non-negative.</div></li>
<li id="li-337"><div class="para" id="p-1854">This means we can define the <dfn class="terminology">singular values</dfn> <span class="process-math">\(\sigma_i = \sqrt{\lambda_i}\)</span> for each <span class="process-math">\(i=1,\ldots, n\text{.}\)</span>
</div></li>
<li id="li-338"><div class="para" id="p-1855">
<em class="alert">Note:</em> it‚Äôs possible to do this even if <span class="process-math">\(A\)</span> is not a square matrix!</div></li>
</ul></div>
<div class="para" id="p-1856">The SymPy library has a function for computing the singular values of a matrix. Given a matrix <code class="code-inline tex2jax_ignore">A</code>, the command <code class="code-inline tex2jax_ignore">A.singular_values()</code> will return its singular values. Try this for a few different matrices below:</div>
<pre class="ptx-sagecell sagecell-sage" id="sage-82"><script type="text/x-sage">A = Matrix([[1,2,3],[4,5,6]])
A.singular_values()
</script></pre>
<div class="para" id="p-1857">In fact, SymPy can even return singular values for a matrix with variable entries! Try the following example from the <a class="external" href="https://docs.sympy.org/latest/modules/matrices/matrices.html#sympy.matrices.matrices.MatrixEigen.singular_values" target="_blank">SymPy documentation</a><a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-13" id="fn-13"><sup>‚Äâ1‚Äâ</sup></a>.</div>
<pre class="ptx-sagecell sagecell-sage" id="sage-83"><script type="text/x-sage">from sympy import Symbol
x = Symbol('x', real=True)
M = Matrix([[0,1,0],[0,x,0],[-1,0,0]])
M,M.singular_values()
</script></pre>
<div class="para logical" id="p-1858">
<div class="para">For an <span class="process-math">\(n\times n\)</span> matrix <span class="process-math">\(A\text{,}\)</span> we might not be able to diagonalize <span class="process-math">\(A\)</span> (with a single orthonormal basis). However, it turns out that it‚Äôs <em class="emphasis">always</em> possible to find a pair of orthonormal bases <span class="process-math">\(\{e_1,\ldots, e_n\}, \{f_1,\ldots, f_n\}\)</span> such that</div>
<div class="displaymath process-math">
\begin{equation*}
Ax = \sigma_1(x\cdot e_1)f_1+\cdots + \sigma_n(x\cdot e_n)f_n\text{.}
\end{equation*}
</div>
<div class="para">In matrix form, <span class="process-math">\(A = P\Sigma_A Q^T\)</span> for orthogonal matrices <span class="process-math">\(P,Q\text{.}\)</span>
</div>
</div>
<div class="para" id="p-1859">In fact, this can be done even if <span class="process-math">\(A\)</span> is not square, which is arguably the more interesting case! Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(m\times n\)</span> matrix. We will find an <span class="process-math">\(m\times m\)</span> orthogonal matrix <span class="process-math">\(P\)</span> and <span class="process-math">\(n\times n\)</span> orthogonal matrix <span class="process-math">\(Q\text{,}\)</span> such that <span class="process-math">\(A=P\Sigma_A Q^T\text{,}\)</span> where <span class="process-math">\(\Sigma_A\)</span> is also <span class="process-math">\(m\times n\text{.}\)</span>
</div>
<aside class="aside aside-like" id="aside-11"><div class="para" id="p-1860">If <span class="process-math">\(A\)</span> is symmetric and positive-definite, the singular values of <span class="process-math">\(A\)</span> are just the eigenvalues of <span class="process-math">\(A\text{,}\)</span> and the singular value decomposition is the same as diagonalization.</div></aside><div class="para" id="p-1861">The basis <span class="process-math">\(\{f_1,\ldots, f_n\}\)</span> is an orthonormal basis for <span class="process-math">\(A^TA\text{,}\)</span> and the matrix <span class="process-math">\(Q\)</span> is the matrix whose columns are the vectors <span class="process-math">\(f_i\text{.}\)</span> As a result, <span class="process-math">\(Q\)</span> is orthogonal.</div>
<div class="para logical" id="p-1862">
<div class="para">The matrix <span class="process-math">\(\Sigma_A\)</span> is the same size as <span class="process-math">\(A\text{.}\)</span> First, we list the positive singular values of <span class="process-math">\(A\)</span> in decreasing order:</div>
<div class="displaymath process-math">
\begin{equation*}
\sigma_1\geq \sigma_2\geq \cdots \geq \sigma_k\gt 0\text{.}
\end{equation*}
</div>
<div class="para">Then, we let <span class="process-math">\(D_A = \operatorname{diag}(\sigma_1,\ldots, \sigma_k)\text{,}\)</span> and set</div>
<div class="displaymath process-math">
\begin{equation*}
\Sigma_A = \begin{bmatrix}D_A\amp 0\\0\amp 0\end{bmatrix}\text{.}
\end{equation*}
</div>
<div class="para">That is, we put <span class="process-math">\(D_A\)</span> in the upper-left, and then fill in zeros as needed, until <span class="process-math">\(\Sigma_A\)</span> is the same size as <span class="process-math">\(A\text{.}\)</span>
</div>
</div>
<div class="para" id="p-1863">Next, we compute the vectors <span class="process-math">\(e_i = \frac{1}{\len{Af_i}}Af_i\text{,}\)</span> for <span class="process-math">\(i=1,\ldots, k\text{.}\)</span> As shown in Nicolson, <span class="process-math">\(\{e_1,\ldots, e_r\}\)</span> will be an orthonormal basis for the column space of <span class="process-math">\(A\text{.}\)</span> The matrix <span class="process-math">\(P\)</span> is constructed by extending this to an orthonormal basis of <span class="process-math">\(\R^m\text{.}\)</span>
</div>
<div class="para" id="p-1864">All of this is a lot of work to do by hand, but it turns out that it can be done numerically, and more importantly, <em class="emphasis">efficiently</em>, by a computer. The SymPy library has an <abbr class="initialism">SVD</abbr> algorithm, but it will not be efficient for larger matrices. In practice, most Python users will use the <abbr class="initialism">SVD</abbr> algorithm provided by NumPy; we will stick with SymPy for simplicity and consistency.</div>
<article class="remark remark-like" id="remark-18"><h5 class="heading">
<span class="type">Remark</span><span class="space"> </span><span class="codenumber">4.6.3</span><span class="period">.</span>
</h5>
<div class="para" id="p-1865">The version of the <abbr class="initialism">SVD</abbr> given above is not used in computations, since it tends to be more resource intensive. In particular, it requires us to store more information than necessary: the last <span class="process-math">\(n-r\)</span> rows of <span class="process-math">\(Q\text{,}\)</span> and the last <span class="process-math">\(m-r\)</span> columns of <span class="process-math">\(P\text{,}\)</span> get multiplied by columns/rows of zeros in <span class="process-math">\(\Sigma_A\text{,}\)</span> so we don‚Äôt really need to keep track of these columns.</div> <div class="para" id="p-1866">Instead, most algorithms that you find will give the <span class="process-math">\(r\times r\)</span> diagonal matrix <span class="process-math">\(D_A\text{,}\)</span> consisting of the nonzero singular values, and <span class="process-math">\(P\)</span> will be replaced by the <span class="process-math">\(m\times r\)</span> matrix consisting of its first <span class="process-math">\(r\)</span> columns, while <span class="process-math">\(Q\)</span> gets replaced by the <span class="process-math">\(r\times n\)</span> matrix consisting of its first <span class="process-math">\(r\)</span> rows. The resulting product is still equal to the original matrix.</div> <div class="para" id="p-1867">In some cases, even the matrix <span class="process-math">\(D_A\)</span> is too large, and a decision is made to truncate to some smaller subset of singular values. In this case, the resulting product is no longer equal to the original matrix, but it does provide an approximation. A discussion can be found <a class="external" href="https://en.wikipedia.org/wiki/Singular_value_decomposition#Reduced_SVDs" target="_blank">on Wikipedia</a><a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-14" id="fn-14"><sup>‚Äâ2‚Äâ</sup></a>.</div></article><article class="example example-like" id="example-svd"><h5 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.6.4</span><span class="period">.</span>
</h5>
<div class="para" id="p-1868">Find the singular value decomposition of the matrix <span class="process-math">\(A = \begin{bmatrix}1\amp 1\amp 1\\1\amp 0\amp -1\end{bmatrix}\text{.}\)</span>
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-74" id="solution-74"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-74"><div class="solution solution-like">
<div class="para" id="p-1869">Using SymPy, we get the <a class="external" href="https://docs.sympy.org/latest/modules/matrices/matrices.html#sympy.matrices.matrices.MatrixBase.singular_value_decomposition" target="_blank">condensed SVD</a><a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-15" id="fn-15"><sup>‚Äâ3‚Äâ</sup></a>. First, let‚Äôs check the singular values.</div> <pre class="ptx-sagecell hidden-sagecell-sage" id="sage-84"><script type="text/x-sage">from sympy import Matrix, init_printing
init_printing()
A = Matrix([[1,1,1],[1,0,-1]])
A.singular_values()
</script></pre> <div class="para" id="p-1870">Note that the values are not listed in decreasing order. Now, let‚Äôs ask for the singular value decomposition. The output consists of three matrices; the first line below assigns those matrices to the names <code class="code-inline tex2jax_ignore">P,S,Q</code>.</div> <pre class="ptx-sagecell hidden-sagecell-sage" id="sage-85"><script type="text/x-sage">P,S,Q=A.singular_value_decomposition()
P,S,Q
</script></pre> <div class="para" id="p-1871">Note that the output is the ‚Äúcondensed‚Äù version, which doesn‚Äôt match the exposition above. It also doesn‚Äôt follow the same ordering convention: we‚Äôll need to swap columns in each of the matrices. But it does give us a decomposition of the matrix <span class="process-math">\(A\text{:}\)</span>
</div> <pre class="ptx-sagecell hidden-sagecell-sage" id="sage-86"><script type="text/x-sage">P*S*Q.T
</script></pre> <div class="para logical" id="p-1872">
<div class="para">To match our earlier presentation, we first set <span class="process-math">\(\Sigma_A = \bbm \sqrt{3}\amp 0\amp 0\\0 \amp \sqrt{2}\amp 0\ebm\text{.}\)</span> Next, we need to extend the <span class="process-math">\(3\times 2\)</span> matrix in the output above to a <span class="process-math">\(3\times 3\)</span> matrix. We can do this by choosing any vector orthogonal to the two existing columns, and normalizing. Let‚Äôs use entries <span class="process-math">\(1/\sqrt{6},-2/\sqrt{6},1/\sqrt{6}\text{.}\)</span> Noting that we also need to swap the first two columns (to match the fact that we swapped columns in <span class="process-math">\(\Sigma_A\)</span>), we get the matrix</div>
<div class="displaymath process-math">
\begin{equation*}
Q = \bbm \frac{\sqrt{3}}{3}\amp \frac{\sqrt{2}}{2}\amp \frac{\sqrt{6}}{6}\\
\frac{\sqrt{3}}{3}\amp 0\amp -\frac{\sqrt{6}}{3}\\
\frac{\sqrt{3}}{3}\amp -\frac{\sqrt{2}}{2} \amp \frac{\sqrt{6}}{6}\ebm\text{.}
\end{equation*}
</div>
<div class="para">Let‚Äôs check that it is indeed orthogonal.</div>
</div> <pre class="ptx-sagecell hidden-sagecell-sage" id="sage-87"><script type="text/x-sage">Q = Matrix([
    [sqrt(3)/3,sqrt(2)/2,sqrt(6)/6],
    [sqrt(3)/3,0,-sqrt(6)/3],
    [sqrt(3)/3,-sqrt(2)/2,sqrt(6)/6]])
Q*Q.T
</script></pre> <div class="para logical" id="p-1873">
<div class="para">Finally, we take <span class="process-math">\(P=\bbm 1\amp 0\\0\amp 1\ebm\)</span> (again swapping columns), which is just the identity matrix. We therefore should expect that</div>
<div class="displaymath process-math">
\begin{equation*}
P\Sigma_A Q^T = \Sigma_A Q^T = A\text{.}
\end{equation*}
</div>
<div class="para">Let‚Äôs check.</div>
</div> <pre class="ptx-sagecell hidden-sagecell-sage" id="sage-88"><script type="text/x-sage">S = Matrix([[sqrt(3),0,0],[0,sqrt(2),0]])
S*Q.T
</script></pre> <div class="para" id="p-1874">It worked!</div>
</div></div>
</div></article><div class="para" id="p-1875">The Singular Value Decomposition has a lot of useful appplications, some of which are described in Nicholson‚Äôs book. On a very fundamental level the <abbr class="initialism">SVD</abbr> provides us with information on some of the most essential properties of the matrix <span class="process-math">\(A\text{,}\)</span> and any system of equations with <span class="process-math">\(A\)</span> as its coefficient matrix.</div>
<div class="para logical" id="p-1876">
<div class="para">Recall the following definitions for an <span class="process-math">\(m\times n\)</span> matrix <span class="process-math">\(A\text{:}\)</span>
</div>
<ol class="decimal">
<li id="li-339"><div class="para" id="p-1877">The <dfn class="terminology">rank</dfn> of <span class="process-math">\(A\)</span> is the number of leadning ones in the <abbr class="initialism">RREF</abbr> of <span class="process-math">\(A\text{,}\)</span> which is also equal to the dimension of the column space of <span class="process-math">\(A\)</span> (or if you prefer, the dimension of <span class="process-math">\(\im (T_A)\)</span>).</div></li>
<li id="li-340"><div class="para" id="p-1878">The <dfn class="terminology">column space</dfn> of <span class="process-math">\(A\text{,}\)</span> denoted <span class="process-math">\(\csp(A)\text{,}\)</span> is the subspace of <span class="process-math">\(\R^m\)</span> spanned by the columns of <span class="process-math">\(A\text{.}\)</span> (This is the image of the matrix transformation <span class="process-math">\(T_A\text{;}\)</span> it is also the space of all vectors <span class="process-math">\(\mathbf{b}\)</span> for which the system <span class="process-math">\(A\xx=\mathbf{b}\)</span> is consistent.)</div></li>
<li id="li-341"><div class="para" id="p-1879">The <dfn class="terminology">row space</dfn> of <span class="process-math">\(A\text{,}\)</span> denoted <span class="process-math">\(\operatorname{row}(A)\text{,}\)</span> is the span of the rows of <span class="process-math">\(A\text{,}\)</span> viewed as column vectors in <span class="process-math">\(\R^n\text{.}\)</span>
</div></li>
<li id="li-342"><div class="para" id="p-1880">The <dfn class="terminology">null space</dfn> of <span class="process-math">\(A\)</span> is the space of solutions to the homogeneous system <span class="process-math">\(A\xx=\zer\text{.}\)</span> This is, of course, equal the kernel of the associated transformation <span class="process-math">\(T_A\text{.}\)</span>
</div></li>
</ol>
</div>
<div class="para" id="p-1881">There are some interesting relationships among these spaces, which are left as an exercise.</div>
<article class="exercise exercise-like" id="ex-matrix-factor1"><h5 class="heading">
<span class="type">Exercise</span><span class="space"> </span><span class="codenumber">4.6.5</span><span class="period">.</span>
</h5>
<div class="introduction" id="introduction-32"><div class="para" id="p-1882">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(m\times n\)</span> matrix. Prove the following statements.</div></div>
<article class="task exercise-like" id="ex-mf1a"><h6 class="heading"><span class="codenumber">(a)</span></h6>
<div class="para" id="p-1883"><span class="process-math">\((\operatorname{row}(A))^\bot = \nll(A)\)</span></div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-46" id="hint-46"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-46"><div class="hint solution-like">
<div class="para" id="p-1884">Note that <span class="process-math">\(\vv\in \nll(A)\)</span> if and only if <span class="process-math">\(A\vv=\zer\text{,}\)</span> and <span class="process-math">\(\vv\in(\operatorname{row}(A))^\bot\)</span> if and only if <span class="process-math">\(\vv\cdot \mathbf{r}_i=\zer\)</span> for each row <span class="process-math">\(\mathbf{r}_i\)</span> of <span class="process-math">\(A\text{.}\)</span>
</div> <div class="para" id="p-1885">Note also that <span class="process-math">\((A\vv)^T=\vv^T A^T\)</span> is the (dot) product of <span class="process-math">\(\vv^T\)</span> with each column of <span class="process-math">\(A^T\text{,}\)</span> and each column of <span class="process-math">\(A^T\)</span> is a row of <span class="process-math">\(A\text{.}\)</span>
</div>
</div></div>
</div></article><article class="task exercise-like" id="ex-mf1b"><h6 class="heading"><span class="codenumber">(b)</span></h6>
<div class="para" id="p-1886"><span class="process-math">\((\csp(A))^\bot = \nll(A^T)\)</span></div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-47" id="hint-47"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-47"><div class="hint solution-like"><div class="para" id="p-1887">Notice that <span class="process-math">\(\vv\in \nll(A^T)\)</span> if and only if <span class="process-math">\(A^T\vv=\zer\text{,}\)</span> and that <span class="process-math">\((A^T\vv)^T=\vv^T A\text{.}\)</span> Your reasoning should be similar to that of the previous part.</div></div></div>
</div></article></article><div class="para" id="p-1888">Here‚Äôs the cool thing about the <abbr class="initialism">SVD</abbr>. Let <span class="process-math">\(\sigma_1\geq \sigma_2\geq \cdots \geq \sigma_r\gt 0\)</span> be the positive singular values of <span class="process-math">\(A\text{.}\)</span> Let <span class="process-math">\(\vecq_1,\ldots, \vecq_r,\ldots, \vecq_n\)</span> be the orthonormal basis of eigenvectors for <span class="process-math">\(A^TA\text{,}\)</span> and let <span class="process-math">\(\vecp_1,\ldots, \vecp_r,\ldots, \vecp_m\)</span> be the orthonormal basis of <span class="process-math">\(\R^m\)</span> constructed in the <abbr class="initialism">SVD</abbr> algorithm. Then:</div>
<div class="para logical" id="p-1889"><ol class="decimal">
<li id="li-343"><div class="para" id="p-1890"><span class="process-math">\(\displaystyle \rank(A)=r\)</span></div></li>
<li id="li-344"><div class="para" id="p-1891">
<span class="process-math">\(\vecq_1,\ldots, \vecq_r\)</span> form a basis for <span class="process-math">\(\operatorname{row}(A)\text{.}\)</span>
</div></li>
<li id="li-345"><div class="para" id="p-1892">
<span class="process-math">\(\vecp_1,\ldots, \vecp_r\)</span> form a basis for <span class="process-math">\(\csp(A)\)</span> (and thus, the ‚Äúrow rank‚Äù and ‚Äúcolumn rank‚Äù of <span class="process-math">\(A\)</span> are the same).</div></li>
<li id="li-346"><div class="para" id="p-1893">
<span class="process-math">\(\vecq_{r+1},\ldots, \vecq_n\)</span> form a basis for <span class="process-math">\(\nll(A)\text{.}\)</span> (And these are therefore the basis solutions of <span class="process-math">\(A\xx=\zer\text{!}\)</span>)</div></li>
<li id="li-347"><div class="para" id="p-1894">
<span class="process-math">\(\vecp_{r+1},\ldots, \vecp_m\)</span> form a basis for <span class="process-math">\(\nll(A^T)\text{.}\)</span>
</div></li>
</ol></div>
<div class="para" id="p-1895">If you want to explore this further, have a look at the excellent <a class="external" href="https://www.juanklopper.com/wp-content/uploads/2015/03/III_05_Singular_value_decomposition.html" target="_blank">notebook by Dr. Juan H Klopper</a><a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-16" id="fn-16"><sup>‚Äâ4‚Äâ</sup></a>. The <code class="code-inline tex2jax_ignore">ipynb</code> file can be found <a class="external" href="https://github.com/juanklopper/MIT_OCW_Linear_Algebra_18_06" target="_blank">on his GitHub page</a><a href="" data-knowl="" class="id-ref fn-knowl original" data-refid="hk-fn-17" id="fn-17"><sup>‚Äâ5‚Äâ</sup></a>. In it, he takes you through various approaches to finding the singular value decomposition, using the method above, as well as using NumPy and SciPy (which, for industrial applications, are superior to SymPy).</div></section><section class="subsubsection" id="pars-qr-factor"><h4 class="heading hide-type">
<span class="type">Subsubsection</span> <span class="codenumber">4.6.1.3</span> <span class="title">QR Factorization</span>
</h4>
<div class="para" id="p-1896">Suppose <span class="process-math">\(A\)</span> is an <span class="process-math">\(m\times n\)</span> matrix with independent columns. (Question: for this to happen, which is true ‚Äî <span class="process-math">\(m\geq n\text{,}\)</span> or <span class="process-math">\(n\geq m\text{?}\)</span>)</div>
<div class="para" id="p-1897">A <span class="process-math">\(QR\)</span>-factorization of <span class="process-math">\(A\)</span> is a factorization of the form <span class="process-math">\(A=QR\text{,}\)</span> where <span class="process-math">\(Q\)</span> is <span class="process-math">\(m\times n\text{,}\)</span> with orthonormal columns, and <span class="process-math">\(R\)</span> is an invertible upper-triangular (<span class="process-math">\(n\times n\)</span>) matrix with positive diagonal entries. If <span class="process-math">\(A\)</span> is a square matrix, <span class="process-math">\(Q\)</span> will be orthogonal.</div>
<div class="para logical" id="p-1898">
<div class="para">A lot of the methods we‚Äôre looking at here involve more sophisticated numerical techniques than SymPy is designed to handle. If we wanted to spend time on these topics, we‚Äôd have to learn a bit about the NumPy package, which has built in tools for finding things like polar decomposition and singular value decomposition. However, SymPy does know how to do <span class="process-math">\(QR\)</span> factorization. After defining a matrix <code class="code-inline tex2jax_ignore">A</code>, we can use the command</div>
<pre class="code-display tex2jax_ignore">
          Q, R = A.QRdecomposition()
        </pre>
<div class="para">.</div>
</div>
<pre class="ptx-sagecell sagecell-sage" id="sage-89"><script type="text/x-sage">from sympy import Matrix,init_printing
init_printing()
A = Matrix(3,3,[1,-2,3,3,-1,2,4,2,5])
Q, R = A.QRdecomposition()
A, Q, R
</script></pre>
<div class="para" id="p-1899">Let‚Äôs check that the matrix <span class="process-math">\(Q\)</span> really is orthogonal:</div>
<pre class="ptx-sagecell sagecell-sage" id="sage-90"><script type="text/x-sage">Q**(-1) == Q.T
</script></pre>
<div class="para" id="p-1900">Details of how to perform the QR factorization can be found in Nicholson‚Äôs textbook. It‚Äôs essentially a consequence of performing the Gram-Schmidt algorithm on the columns of <span class="process-math">\(A\text{,}\)</span> and keeping track of our work.</div>
<div class="para" id="p-1901">The calculation above is a symbolic computation, which is nice for understanding what‚Äôs going on. The reason why the <span class="process-math">\(QR\)</span> factorization is useful in practice is that there are efficient numerical methods for doing it (with good control over rounding errors). Our next topic looks at a useful application of the <span class="process-math">\(QR\)</span> factorization.</div></section></section><section class="subsection" id="subsec-compute-eigen"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.6.2</span> <span class="title">Computing Eigenvalues</span>
</h3>
<section class="introduction" id="introduction-33"><div class="para" id="p-1902">Our first method focuses on the dominant eigenvalue of a matrix. An eigenvalue is dominant if it is larger in absolute value than all other eigenvalues. For example, if <span class="process-math">\(A\)</span> has eigenvalues <span class="process-math">\(1,3,-2,-5\text{,}\)</span> then <span class="process-math">\(-5\)</span> is the dominant eigenvalue.</div> <div class="para" id="p-1903">If <span class="process-math">\(A\)</span> has eigenvalues <span class="process-math">\(1,3,0,-4,4\)</span> then there is no dominant eigenvalue. Any eigenvector corresponding to a dominant eigenvalue is called a dominant eigenvector.</div></section><section class="subsubsection" id="pars-power-method"><h4 class="heading hide-type">
<span class="type">Subsubsection</span> <span class="codenumber">4.6.2.1</span> <span class="title">The Power Method</span>
</h4>
<div class="para" id="p-1904">If a matrix <span class="process-math">\(A\)</span> has a dominant eigenvalue, there is a method for finding it (approximately) that does not involve finding and factoring the characteristic polynomial of <span class="process-math">\(A\text{.}\)</span>
</div>
<div class="para logical" id="p-1905">
<div class="para">We start with some initial guess <span class="process-math">\(x_0\)</span> for a dominant eigenvector. We then set <span class="process-math">\(x_{k+1} = Ax_k\)</span> for each <span class="process-math">\(k\geq 0\text{,}\)</span> giving a sequence</div>
<div class="displaymath process-math">
\begin{equation*}
x_0, Ax_0, A^2x_0, A^3x_0,\ldots\text{.}
\end{equation*}
</div>
<div class="para">We expect (for reasons we‚Äôll explain) that <span class="process-math">\(\lVert x_k-x\rVert \to 0\)</span> as <span class="process-math">\(k\to\infty\text{,}\)</span> where <span class="process-math">\(x\)</span> is a dominant eigenvector. Let‚Äôs try an example.</div>
</div>
<pre class="ptx-sagecell sagecell-sage" id="sage-91"><script type="text/x-sage">A = Matrix(2,2,[1,-4,-3,5])
A,A.eigenvects()
</script></pre>
<div class="para" id="p-1906">The dominant eigenvalue is <span class="process-math">\(\lambda = 7\text{.}\)</span> Let‚Äôs try an initial guess of <span class="process-math">\(x_0=\begin{bmatrix}1\\0\end{bmatrix}\)</span> and see what happens.</div>
<pre class="ptx-sagecell sagecell-sage" id="sage-92"><script type="text/x-sage">x0 = Matrix(2,1,[1,0])
L = list()
for k in range(10):
    L.append(A**k*x0)
L
</script></pre>
<div class="para" id="p-1907">We might want to confirm whether that rather large fraction is close to <span class="process-math">\(\frac23\text{.}\)</span> To do so, we can get the computer to divide the numerator by the denominator.</div>
<pre class="ptx-sagecell sagecell-sage" id="sage-93"><script type="text/x-sage">L[9][0]/L[9][1]
</script></pre>
<div class="para" id="p-1908">The above might show you the fraction rather than its decimal approximation. (This may depend on whether you‚Äôre on Sage or Jupyter.) To get the decimal, try wrapping the above in <code class="code-inline tex2jax_ignore">float()</code> (or <code class="code-inline tex2jax_ignore">N</code>, or append with <code class="code-inline tex2jax_ignore">.evalf()</code>).</div>
<div class="para logical" id="p-1909">
<div class="para">For the eigenvalue, we note that if <span class="process-math">\(Ax=\lambda x\text{,}\)</span> then</div>
<div class="displaymath process-math">
\begin{equation*}
\frac{x\cdot Ax}{\lVert x\rVert^2} = \frac{x\cdot (\lambda x)}{\lVert x\rVert^2} = \lambda\text{.}
\end{equation*}
</div>
<div class="para">This leads us to consider the Rayleigh quotients</div>
<div class="displaymath process-math">
\begin{equation*}
r_k = \frac{x_k\cdot x_{k+1}}{\lVert x_k\rVert^2}\text{.}
\end{equation*}
</div>
</div>
<pre class="ptx-sagecell sagecell-sage" id="sage-94"><script type="text/x-sage">M = list()
for k in range(9):
    M.append((L[k].dot(L[k+1]))/(L[k].dot(L[k])))
M
</script></pre>
<div class="para" id="p-1910">We can convert a rational number r to a float using either <code class="code-inline tex2jax_ignore">N(r)</code> or <code class="code-inline tex2jax_ignore">r.evalf()</code>. (The latter seems to be the better bet when working with a list.)</div>
<pre class="ptx-sagecell sagecell-sage" id="sage-95"><script type="text/x-sage">M2 = list()
for k in range(9):
    M2.append((M[k]).evalf())
M2
</script></pre></section><section class="subsubsection" id="pars-qr-algorithm"><h4 class="heading hide-type">
<span class="type">Subsubsection</span> <span class="codenumber">4.6.2.2</span> <span class="title">The QR Algorithm</span>
</h4>
<div class="para" id="p-1911">Given an <span class="process-math">\(n\times n\)</span> matrix <span class="process-math">\(A\text{,}\)</span> we know we can write <span class="process-math">\(A=QR\text{,}\)</span> with <span class="process-math">\(Q\)</span> orthogonal and <span class="process-math">\(R\)</span> upper-triangular. The <span class="process-math">\(QR\)</span>-algorithm exploits this fact. We set <span class="process-math">\(A_1=A\text{,}\)</span> and write <span class="process-math">\(A_1=Q_1R_1\text{.}\)</span>
</div>
<div class="para" id="p-1912">Then we set <span class="process-math">\(A_2 = R_1Q_1\text{,}\)</span> and factor: <span class="process-math">\(A_2=Q_2R_2\text{.}\)</span> Notice <span class="process-math">\(A_2 = R_1Q_1 = Q_1^TA_1Q_1\text{.}\)</span> Since <span class="process-math">\(A_2\)</span> is similar to <span class="process-math">\(A_1\text{,}\)</span> <span class="process-math">\(A_2\)</span> has the same eigenvalues as <span class="process-math">\(A_1=A\text{.}\)</span>
</div>
<div class="para" id="p-1913">Next, set <span class="process-math">\(A_3 = R_2Q_2\text{,}\)</span> and factor as <span class="process-math">\(A_3 = Q_3R_3\text{.}\)</span> Since <span class="process-math">\(A_3 = Q_2^TA_2Q_2\text{,}\)</span> <span class="process-math">\(A_3\)</span> has the same eigenvalues as <span class="process-math">\(A_2\text{.}\)</span> In fact, <span class="process-math">\(A_3 = Q_2^T(Q_1^TAQ_1)Q_2 = (Q_1Q_2)^TA(Q_1Q_2)\text{.}\)</span>
</div>
<div class="para" id="p-1914">After <span class="process-math">\(k\)</span> steps we have <span class="process-math">\(A_{k+1} = (Q_1\cdots Q_k)^TA(Q_1\cdots Q_k)\text{,}\)</span> which still has the same eigenvalues as <span class="process-math">\(A\text{.}\)</span> By some sort of dark magic, this sequence of matrices converges to an upper triangular matrix with eigenvalues on the diagonal!</div>
<div class="para" id="p-1915">Consider the matrix <span class="process-math">\(A = \begin{bmatrix}5&amp;-2&amp;3\\0&amp;4&amp;0\\0&amp;-1&amp;3\end{bmatrix}\)</span>
</div>
<pre class="ptx-sagecell sagecell-sage" id="sage-96"><script type="text/x-sage">A = Matrix(3,3,[5,-2,3,0,4,0,0,-1,3])
A.eigenvals()
</script></pre>
<pre class="ptx-sagecell sagecell-sage" id="sage-97"><script type="text/x-sage">Q1,R1 = A.QRdecomposition()
A2=R1*Q1
A2,Q1,R1
</script></pre>
<div class="para" id="p-1916">Now we repeat the process:</div>
<pre class="ptx-sagecell sagecell-sage" id="sage-98"><script type="text/x-sage">Q2,R2 = A2.QRdecomposition()
A3=R2*Q2
A3.evalf()
</script></pre>
<div class="para" id="p-1917">Do this a few more times, and see what results! (If someone can come up with a way to code this as a loop, let me know!) The diagonal entries should get closer to <span class="process-math">\(5,4,3\text{,}\)</span> respectively, and the <span class="process-math">\((3,2)\)</span> entry should get closer to <span class="process-math">\(0\text{.}\)</span>
</div>
<pre class="ptx-sagecell sagecell-sage" id="sage-99"><script type="text/x-sage"></script></pre>
<pre class="ptx-sagecell sagecell-sage" id="sage-100"><script type="text/x-sage"></script></pre></section></section></section><div class="hidden-content tex2jax_ignore" id="hk-fn-13"><div class="fn"><code class="code-inline tex2jax_ignore">docs.sympy.org/latest/modules/matrices/matrices.html#sympy.matrices.matrices.MatrixEigen.singular_values</code></div></div>
<div class="hidden-content tex2jax_ignore" id="hk-fn-14"><div class="fn"><code class="code-inline tex2jax_ignore">en.wikipedia.org/wiki/Singular_value_decomposition</code></div></div>
<div class="hidden-content tex2jax_ignore" id="hk-fn-15"><div class="fn"><code class="code-inline tex2jax_ignore">docs.sympy.org/latest/modules/matrices/</code></div></div>
<div class="hidden-content tex2jax_ignore" id="hk-fn-16"><div class="fn"><code class="code-inline tex2jax_ignore">www.juanklopper.com/wp-content/uploads/2015/03/III_05_Singular_value_decomposition.html</code></div></div>
<div class="hidden-content tex2jax_ignore" id="hk-fn-17"><div class="fn"><code class="code-inline tex2jax_ignore">github.com/juanklopper/MIT_OCW_Linear_Algebra_18_06</code></div></div>
</div>
<div class="ptx-content-footer">
<a class="previous-button button" href="worksheet-dynamical.html" title="Previous"><span class="icon">&lt;</span><span class="name">Prev</span></a><a class="top-button button" href="#" title="Top"><span class="icon">^</span><span class="name">Top</span></a><a class="next-button button" href="worksheet-svd.html" title="Next"><span class="name">Next</span><span class="icon">&gt;</span></a>
</div></main>
</div>
<div id="ptx-page-footer" class="ptx-page-footer">
<a class="pretext-link" href="https://pretextbook.org" title="PreTeXt"><div class="logo"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="338 3000 8772 6866"><g style="stroke-width:.025in; stroke:black; fill:none"><polyline points="472,3590 472,9732 " style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round; "></polyline><path style="stroke:#000000;stroke-width:126;stroke-linecap:butt;" d="M 4724,9448 A 4660 4660  0  0  1  8598  9259"></path><path style="stroke:#000000;stroke-width:174;stroke-linecap:butt;" d="M 4488,9685 A 4228 4228  0  0  0   472  9732"></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:butt;" d="M 4724,3590 A 4241 4241  0  0  1  8598  3496"></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:round;" d="M 850,3496  A 4241 4241  0  0  1  4724  3590"></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:round;" d="M 850,9259  A 4507 4507  0  0  1  4724  9448"></path><polyline points="5385,4299 4062,8125" style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="8598,3496 8598,9259" style="stroke:#000000;stroke-width:126; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="850,3496 850,9259" style="stroke:#000000;stroke-width:126; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="4960,9685 4488,9685" style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="3070,4582 1889,6141 3070,7700" style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="6418,4582 7600,6141 6418,7700" style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="8976,3590 8976,9732" style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round;"></polyline><path style="stroke:#000000;stroke-width:174;stroke-linecap:butt;" d="M 4960,9685 A 4228 4228  0  0  1  8976  9732"></path></g></svg></div></a><a class="runestone-link" href="https://runestone.academy" title="Runestone Academy"><img class="logo" src="https://runestone.academy/runestone/static/images/RAIcon_cropped.png"></a><a class="mathjax-link" href="https://www.mathjax.org" title="MathJax"><img class="logo" src="https://www.mathjax.org/badge/badge-square-2.png"></a>
</div>
</body>
</html>
